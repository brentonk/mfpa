[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mathematical Foundations of Political Analysis",
    "section": "",
    "text": "Preface\nThese are the course notes for Prof. Brenton Kenkel’s course PSCI 8350 at Vanderbilt University. The course covers the bare essential mathematical techniques needed for applied work in statistics and formal theory in political science.\nThis book is written in Quarto and published on GitHub Pages. You can find the Quarto source files on GitHub.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "logic.html",
    "href": "logic.html",
    "title": "1  Formal Logic and Proofs",
    "section": "",
    "text": "1.1 Sentential logic and truth tables\nWhen you think about math, you probably think about numbers. The majority of the math classes you’ve taken in your life have been about how to manipulate numbers. But don’t panic if you’re the kind of person who grimaces a bit when you have to calculate a tip by hand — your success as a political scientist will have nothing to do with your ability to add or multiply numbers in your head. That’s what we have computers for.\nIn this course, we will approach math from a different angle. Our goal will be to make statements that are provably true. In essence, a statement is provably true if there is a logical defense against any possible objection to the statement. Anyone who follows the rules of deductive logic — the ones we will work through in this first unit of the course — must agree that the statement is true.\nPlenty of things are true in the ordinary sense of the word, yet are not provably true in the mathematical sense. For example, it is true that Joe Biden won the 2020 presidential election. However, the truth of this statement is established through empirical observation, not through logical deduction alone. In other words, at least some defenses against objections to this statement rely on findings of fact. If you say “I don’t think Joe Biden won the 2020 presidential election because I don’t think Joe Biden exists”, I need to convince you that Joe Biden exists, which isn’t a matter of logic alone.\nOn the other hand, the following statement is provably true: “If (a) only one person can win a presidential election, and (b) Joe Biden won the 2020 presidential election, and (c) Joe Biden is not Donald Trump, then (d) Donald Trump did not win the 2020 presidential election.” Once you accept the premises (a), (b), and (c), you have no choice but to reach the conclusion (d). Whether each premise is true is the kind of empirical question that logic alone cannot answer. But logic does tell us that if all these premises are true, then the conclusion (d) has to follow.\nIf you came to graduate school to study politics empirically, at this point you might be wondering why you should care about proving statements in the realm of pure logic. Here’s why I think you should care.\nSentential logic is a set of rules for working with sentences. In this context, a sentence is a statement that is either true or false (it must be one, and it cannot be both). Here are some examples of sentences:\nEach of these is a “sentence”, logically speaking, in that it is true or false. But there are important distinctions among them.\nIn one sense, our goal with formal logic will be to take compound sentences and sort them into these three categories: those that must be true, those that must be false, and those that are indeterminate, whose truth value cannot be deduced by logic alone.\nYou might think that the sentences that must be true — the tautologies — are inherently uninteresting. Certainly no one is going to be surprised that either the tariffs caused the stock market to crash or they didn’t. And yet there are indeed statements that are tautological yet nonobvious on first glance. For example, I was surprised to learn in graduate school that there is no non-dictatorial system for elections with more than two candidates that eliminates incentives for strategic voting. But this statement is indeed a tautology in the formal-logic sense of the word. (If you don’t think the truth of this statement is nonobvious, just try arguing on the Internet with people who think ranked-choice voting will fix elections!)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Formal Logic and Proofs</span>"
    ]
  },
  {
    "objectID": "logic.html#sentential-logic-and-truth-tables",
    "href": "logic.html#sentential-logic-and-truth-tables",
    "title": "1  Formal Logic and Proofs",
    "section": "",
    "text": "“The ‘Liberation Day’ tariffs caused the stock market to crash.”\n“The ‘Liberation Day’ tariffs caused the stock market to crash, or the ‘Liberation Day’ tariffs did not cause the stock market to crash.”\n“The ‘Liberation Day’ tariffs caused the stock market to crash, and the ‘Liberation Day’ tariffs did not cause the stock market to crash.”\n\n\n\nFormal logic by itself cannot help us figure out whether sentence #1 is true or false. That is a matter for empirical study.\nBy contrast, we don’t need to consult the real world to know that sentence #2 is true. We can deduce on the basis of logic alone that sentence #2 is true. We call a compound sentence like this, which must be true regardless of the underlying truth values of the sentences from which it is constructed, a tautology.\nFinally, we also don’t need to consult the real world to know that sentence #3 is false. There is no way for it to be the case that the tariffs both did and did not cause the stock market to crash.\n\n\n\n\n1.1.1 Constructing compound sentences\nIn this chapter, we will use the letters \\(P\\), \\(Q\\), and \\(R\\) to denote sentences. Whenever you see one of these letters, just think: “a thing that can be exactly one of ‘true’ or ‘false’”. For example, \\(P\\) might be the statement “The ‘Liberation Day’ tariffs caused the stock market to crash.”\nWe will build compound sentences using three operators. The first is the not operator, denoted by \\(\\neg P\\). The rules of the “not” operator are simple: \\(\\neg P\\) is true whenever \\(P\\) is false, and \\(\\neg P\\) is false whenever \\(P\\) is true.\nThe second basic operator is and, which connects two sentences, denoted \\(P \\land Q\\). An “and” statement is true whenever both underlying statements are true, and false otherwise.\nThe final basic operator is or, which again connects two sentences, denoted \\(P \\lor Q\\). An “or” statement is true whenever at least one of the underlying statements is true. It is only false when both of the underlying statements are false. In other words, the logical “or” is an “inclusive or” (allowing for the possibility that both are true), not an “exclusive or”.\nAbove we saw the compound sentence “The ‘Liberation Day’ tariffs caused the stock market to crash, or the ‘Liberation Day’ tariffs did not cause the stock market to crash.” If we take \\(P\\) to be the sentence “The ‘Liberation Day’ tariffs caused the stock market to crash”, then the formal statement of our compound sentence is \\(P \\lor \\neg P\\). We want to show that the compound sentence \\(P \\lor \\neg P\\) is a tautology; i.e., the compound sentence is true regardless of whether \\(P\\) is true or false.\nWe will use a truth table to identify the conditions under which a compound sentence is true. To build a truth table for a compound sentence like \\(P \\lor \\neg P\\), the first thing we do is identify the underlying sentences it is built from. In the case of \\(P \\lor \\neg P\\), there’s only one underlying sentence, namely \\(P\\). We begin to write the truth table by enumerating all combinations of truth values of the underlying sentences.\n\n\n\n\\(P\\)\n\n\n\n\ntrue\n\n\nfalse\n\n\n\nNext, we add columns to build up to the compound sentence that we are trying to evaluate. In the example here, we are trying to get from \\(P\\) to \\(P \\lor \\neg P\\). The compound sentence is built from \\(P\\) and \\(\\neg P\\). So we’ll start with \\(P\\), evaluate \\(\\neg P\\), and finally evaluate \\(P \\lor \\neg P\\).\n\n\n\n\\(P\\)\n\\(\\neg P\\)\n\\(P \\lor \\neg P\\)\n\n\n\n\ntrue\n\n\n\n\nfalse\n\n\n\n\n\nWe then fill the columns by moving across the truth table from left to right. We know that \\(\\neg P\\) is false whenever \\(P\\) is true, and vice versa, which lets us fill out the second column.\n\n\n\n\\(P\\)\n\\(\\neg P\\)\n\\(P \\lor \\neg P\\)\n\n\n\n\ntrue\nfalse\n\n\n\nfalse\ntrue\n\n\n\n\nFinally, we know that \\(P \\lor \\neg P\\) is true whenever at least one of \\(P\\) or \\(\\neg P\\) is true, which lets us fill out the third column.\n\n\n\n\\(P\\)\n\\(\\neg P\\)\n\\(P \\lor \\neg P\\)\n\n\n\n\ntrue\nfalse\ntrue\n\n\nfalse\ntrue\ntrue\n\n\n\nWe now see that the compound sentence \\(P \\lor \\neg P\\) is a tautology, as it is always true, regardless of whether the sentence it is built from is true or false.\n\n\n\n\n\n\nApproaching exercises\n\n\n\nTry the exercises yourself, ideally by writing them on paper or in a tablet, before looking at the answers. You learn the most by trying on your own and then checking. (This is exactly how I still do it when I’m working through unfamiliar technical material!)\n\n\n\nExercise 1.1 Use a truth table to show that \\(\\neg (P \\land \\neg P)\\) is a tautology.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nStart by setting up the table with each combination of possible values of the underlying sentences (in this case, just \\(P\\)), then with each sequential step you need to build the final compound sentence.\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(\\neg P\\)\n\\(P \\land \\neg P\\)\n\\(\\neg (P \\land \\neg P)\\)\n\n\n\n\ntrue\n\n\n\n\n\n; false\n\n\n\n\n\n\nThen fill each column across, using the information from the left.\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(\\neg P\\)\n\\(P \\land \\neg P\\)\n\\(\\neg (P \\land \\neg P)\\)\n\n\n\n\ntrue\nfalse\n\n\n\n\nfalse\ntrue\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(\\neg P\\)\n\\(P \\land \\neg P\\)\n\\(\\neg (P \\land \\neg P)\\)\n\n\n\n\ntrue\nfalse\nfalse\n\n\n\nfalse\ntrue\nfalse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(\\neg P\\)\n\\(P \\land \\neg P\\)\n\\(\\neg (P \\land \\neg P)\\)\n\n\n\n\ntrue\nfalse\nfalse\ntrue\n\n\nfalse\ntrue\nfalse\ntrue\n\n\n\n\n\n\n\nThe more simple sentences that your compound sentence is built from, the more rows the truth table will end up having. For example, let’s build a truth table for the compound sentence \\(P \\lor \\neg (P \\land Q)\\). The truth table will now have four rows, one for each combination of true/false for \\(P\\) and \\(Q\\).\n\n\n\n\\(P\\)\n\\(Q\\)\n\n\n\n\ntrue\ntrue\n\n\ntrue\nfalse\n\n\nfalse\ntrue\n\n\nfalse\nfalse\n\n\n\nThen we break down the compound sentence and fill out the rest of the truth table the same way as before.\n\nColumn setupCompleted table\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(Q\\)\n\\(P \\land Q\\)\n\\(\\neg (P \\land Q)\\)\n\\(P \\lor \\neg (P \\land Q)\\)\n\n\n\n\ntrue\ntrue\n\n\n\n\n\ntrue\nfalse\n\n\n\n\n\nfalse\ntrue\n\n\n\n\n\nfalse\nfalse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(Q\\)\n\\(P \\land Q\\)\n\\(\\neg (P \\land Q)\\)\n\\(P \\lor \\neg (P \\land Q)\\)\n\n\n\n\ntrue\ntrue\ntrue\nfalse\ntrue\n\n\ntrue\nfalse\nfalse\ntrue\ntrue\n\n\nfalse\ntrue\nfalse\ntrue\ntrue\n\n\nfalse\nfalse\nfalse\ntrue\ntrue\n\n\n\n\n\n\n\nExercise 1.2 Use a truth table to show that \\((P \\lor Q) \\lor (\\neg P \\land \\neg Q)\\) is a tautology.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSet up the rows:\n\n\n\n\\(P\\)\n\\(Q\\)\n\n\n\n\ntrue\ntrue\n\n\ntrue\nfalse\n\n\nfalse\ntrue\n\n\nfalse\nfalse\n\n\n\nSet up the columns:\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(Q\\)\n\\(P \\lor Q\\)\n\\(\\neg P\\)\n\\(\\neg Q\\)\n\\(\\neg P \\land \\neg Q\\)\n\\((P \\lor Q) \\lor (\\neg P \\land \\neg Q)\\)\n\n\n\n\ntrue\ntrue\n\n\n\n\n\n\n\ntrue\nfalse\n\n\n\n\n\n\n\nfalse\ntrue\n\n\n\n\n\n\n\nfalse\nfalse\n\n\n\n\n\n\n\n\nFill out the table:\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(Q\\)\n\\(P \\lor Q\\)\n\\(\\neg P\\)\n\\(\\neg Q\\)\n\\(\\neg P \\land \\neg Q\\)\n\\((P \\lor Q) \\lor (\\neg P \\land \\neg Q)\\)\n\n\n\n\ntrue\ntrue\ntrue\nfalse\nfalse\nfalse\ntrue\n\n\ntrue\nfalse\ntrue\nfalse\ntrue\nfalse\ntrue\n\n\nfalse\ntrue\ntrue\ntrue\nfalse\nfalse\ntrue\n\n\nfalse\nfalse\nfalse\ntrue\ntrue\ntrue\ntrue\n\n\n\n\n\n\n\nIt’s reasonably simple to double-check your work in a truth table using R. (Or any programming language — they’re all good at this sort of binary logic exercise.) In R, to set up the rows of a truth table, you can use expand.grid() to enumerate all possible true-false combinations.\n\ngrid &lt;- expand.grid(Q = c(TRUE, FALSE), P = c(TRUE, FALSE))\nprint(grid)\n\n      Q     P\n1  TRUE  TRUE\n2 FALSE  TRUE\n3  TRUE FALSE\n4 FALSE FALSE\n\n\n\n\nI put Q first in the R code so that the row order will be the same as in the tables I made by hand above.\nIn R, ! means “not”, & means “and”, and | means “or”. We can use these operators to look at the columns of our truth table.\n\nP &lt;- grid$P\nQ &lt;- grid$Q\ncbind(P, Q, P | !(P & Q))\n\n         P     Q     \n[1,]  TRUE  TRUE TRUE\n[2,]  TRUE FALSE TRUE\n[3,] FALSE  TRUE TRUE\n[4,] FALSE FALSE TRUE\n\n\nYou can also use the all() function to quickly check whether a statement is a tautology.\n\nall(P | !(P & Q)) # is a tautology\n\n[1] TRUE\n\nall(P & Q) # not a tautology\n\n[1] FALSE\n\n\n\nExercise 1.3 Using R, confirm that the compound sentence \\[[(P \\lor Q) \\lor (\\neg R \\lor \\neg S)] \\lor [(\\neg P \\land \\neg Q) \\land (R \\land S)]\\] is a tautology.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\ngrid &lt;- expand.grid(\n  P = c(TRUE, FALSE),\n  Q = c(TRUE, FALSE),\n  R = c(TRUE, FALSE),\n  S = c(TRUE, FALSE)\n)\nP &lt;- grid$P\nQ &lt;- grid$Q\nR &lt;- grid$R\nS &lt;- grid$S\n\n# Break sentence into two parts to keep track of things easier\npart_1 &lt;- (P | Q) | (!R | !S)\npart_2 &lt;- (!P & !Q) & (R & S)\n\n# Confirm tautology\nall(part_1 | part_2)\n\n[1] TRUE\n\n\n\n\n\n\n\n\n1.1.2 “If”, “only if”, and “if and only if”\nIf-then statements work a bit differently in formal logic than in ordinary language. If I told you, “Scream if you see a bear!” and then you screamed, I would run away, having inferred that you saw a bear. However, I didn’t tell you “Don’t scream if you didn’t see a bear.” So in terms of pure logic, there would be no problem with you screaming even if there weren’t a bear — the only way to contradict the command would be to fail to scream when you actually did see a bear.\nIn the realm of formal logic and mathematics, we will be totally pedantic about our if-then statements. If I say “if \\(P\\), then \\(Q\\)”, the only way to falsify my statement is to show me that \\(P\\) is true and \\(Q\\) is false. If \\(P\\) is false, then the statement is true regardless of the truth of \\(Q\\).\n\nDefinition 1.1 The conditional statement “\\(P\\) implies \\(Q\\)” or “if \\(P\\), then \\(Q\\)”, written \\(P \\to Q\\), is logically equivalent to \\(\\neg P \\lor Q\\).\n\nWhen \\(P\\) is known to be false, we say that the statement \\(P \\to Q\\) is vacuously true. Here are some vacuously true statements:\n\nIf 0 = 1, then the moon is made of cheese.\nIf 4 is a prime number, then an asteroid will hit Earth on February 30, 2026.\nIf there is a finite game with no Nash equilibrium, then Professor Brad Smith is handsome and intelligent.\n\nWhile it’s fun to think about vacuous truths, conditional statements are most useful to us when the premise is true. Think about a conditional statement \\(P \\to Q\\) that we know to be true. As an uncontroversial example, let \\(P\\) be “today is Wednesday” and \\(Q\\) be “tomorrow is Thursday”, so that \\(P \\to Q\\) means “if today is Wednesday, then tomorrow is Thursday.” Imagine then we also know that \\(P\\) is true. As it happens, at the time I am writing this paragraph, it is indeed Wednesday. Given that \\(P\\) implies \\(Q\\), and that \\(P\\) is true, it seems logical for me to deduce that \\(Q\\) is true as well. Indeed, this deduction is logical — the name for this type of inference is modus ponens.\nYou don’t have to take the validity of modus ponens on faith. We can translate the rule into a compound sentence, and then we can prove that it is a tautology. In words, the rule is “If \\(P\\) implies \\(Q\\) and \\(P\\) is true, then \\(Q\\) is true.” Equivalently, we could say “If \\((P \\to Q) \\land P\\), then \\(Q\\).” Finally, we come to the most compact (though not the easiest to parse!) statement in Theorem 1.1.\n\nTheorem 1.1 (Modus ponens) \\([(P \\to Q) \\land P] \\to Q\\).\n\n\nProof. We will use a truth table to show that the statement is a tautology.\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(Q\\)\n\\(P \\to Q\\)\n\\((P \\to Q) \\land P\\)\n\\([(P \\to Q) \\land P] \\to Q\\)\n\n\n\n\ntrue\ntrue\ntrue\ntrue\ntrue\n\n\ntrue\nfalse\nfalse\nfalse\ntrue\n\n\nfalse\ntrue\ntrue\nfalse\ntrue\n\n\nfalse\nfalse\ntrue\nfalse\ntrue\n\n\n\n\n\n\n\n\n\n\nNames of mathematical results\n\n\n\nThroughout these notes, you will see mathematical results labeled Theorem, Proposition, Lemma, and Corollary. Anything with one of these names is a formal statement that is provably true, and will usually be accompanied by a proof. None of these types of results is more or less true than the others — the different labels are just to help readers decode the context and importance of each type of result.\n\nTheorem: Reserved for results that are especially big, important, fundamental, general, etc. For example, Theorem 1.1 is a theorem because it is the foundation of logical deduction.\nProposition: A bread-and-butter result. Useful and important enough to care about on its own, but not earth-shaking enough to be a theorem.\nLemma: A result that we don’t necessarily care about on its own, but is a useful building block toward one or more propositions or theorems.\nCorollary: A result that follows almost immediately from some earlier lemma(s), proposition(s), or theorem(s). My general heuristic for calling something a corollary is that it can be proved in two sentences or less, and the proof requires invoking an earlier lemma, proposition, or theorem.\n\n\n\nYou can think of \\(P \\to Q\\) as a statement of a sufficient condition: if \\(P\\) is true, then \\(Q\\) must be true, hence \\(P\\) is “sufficient” to ensure that \\(Q\\) holds. However, this statement says nothing about whether \\(P\\) is a necessary condition for \\(Q\\) — something that must be true in order for \\(Q\\) to be true. Think about the statement “If Marie is a member of the House of Representatives, then Marie is a politician.” Being a member of the House is sufficient to be called a politician, but it is not necessary. We would still call Marie a politician if she were the president, a senator, a yet-unelected candidate for the House, or even the state comptroller.\nIn the same way that the statement \\(P \\to Q\\) gives us a sufficient condition for \\(Q\\), it also gives us a necessary condition for \\(P\\). Remember that the conditional statement \\(P \\to Q\\) turns out to be false when \\(P\\) is true yet \\(Q\\) is false. Hence, an alternative way to verbalize \\(P \\to Q\\) is “\\(P\\) is true only if \\(Q\\) is true,” meaning \\(Q\\) is a necessary — though perhaps insufficient — condition for \\(P\\). Returning to the example above, we could say “Marie is a member of the House of Representatives only if she is a politician.” Being a politician doesn’t necessarily mean she’s a House member, but she certainly cannot be a House member unless she is a politician.\nWe’ve just seen that a sufficient condition (if \\(P\\), then \\(Q\\)) can be translated into a necessary condition (\\(P\\) only if \\(Q\\)). This observation allows us to make the following type of logical deduction:\n\nPremise 1: If Marie is a member of the House of Representatives, then Marie is a politician. (\\(P \\to Q\\))\nPremise 2: Marie is not a politician. (\\(\\neg Q\\))\nConclusion: Marie is not a member of the House of Representatives. (\\(\\neg P\\))\n\nThe line of reasoning here is an example of the deductive rule called modus tollens. If we know that \\(P\\) implies \\(Q\\) and we know that \\(Q\\) is false, we must conclude that \\(P\\) is false as well.\n\nTheorem 1.2 (Modus tollens) \\([(P \\to Q) \\land \\neg Q] \\to \\neg P\\).\n\n\nProof. Try to prove this yourself using a truth table, following the same lines as the proof of Theorem 1.1 above. If you get stuck, check the answer below.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(Q\\)\n\\(P \\to Q\\)\n\\(\\neg Q\\)\n\\((P \\to Q) \\land \\neg Q\\)\n\\(\\neg P\\)\n\\([(P \\to Q) \\land \\neg Q] \\to \\neg P\\)\n\n\n\n\ntrue\ntrue\ntrue\nfalse\nfalse\nfalse\ntrue\n\n\ntrue\nfalse\nfalse\ntrue\nfalse\nfalse\ntrue\n\n\nfalse\ntrue\ntrue\nfalse\nfalse\ntrue\ntrue\n\n\nfalse\nfalse\ntrue\ntrue\ntrue\ntrue\ntrue\n\n\n\nHere’s another way to think about this proof, somewhat anticipating our discussion of proof by contradiction below.\nThe only way for \\([(P \\to Q) \\land \\neg Q] \\to \\neg P\\) to be false would be for \\((P \\to Q) \\land \\neg Q\\) to be true while \\(\\neg P\\) is false (i.e., \\(P\\) is true). There are two paths for \\(P \\to Q\\) to be true: either it’s vacuously true because \\(P\\) is false, or it’s true because \\(P\\) is true and so is \\(Q\\).\nWhen we additionally assume \\(\\neg Q\\) is true, then \\(P \\to Q\\) can only be true vacuously, i.e., because \\(P\\) is false. In other words, whenever \\(P \\to Q\\) and \\(\\neg Q\\) are both true, it must be the case that \\(P\\) is false and thus \\(\\neg P\\) is true. This means there is no path for \\([(P \\to Q) \\land \\neg Q] \\to \\neg P\\) to be falsified, as anytime the premise \\((P \\to Q) \\land \\neg Q\\) is true, the conclusion \\(\\neg P\\) must be true too.\nTherefore, the statement of modus tollens is a tautology.\n\n\n\n\nThe statements \\(P\\) and \\(Q\\) are logically equivalent when \\(P \\to Q\\) and \\(Q \\to P\\). In this case, the truth values of the two statements are linked: either \\(P\\) and \\(Q\\) are both true, or else \\(P\\) and \\(Q\\) are both false. \\(P\\) is a necessary and sufficient condition for \\(Q\\), and \\(Q\\) is a necessary and sufficient condition for \\(P\\). In words, we may use “\\(P\\) if and only if \\(Q\\)” to describe this state of affairs.\n\n\n\n\n\n\nIff\n\n\n\nWriters sometimes use “iff” as a shorthand for “if and only if.” Personally, I use “iff” only if I’m taking notes or writing on the whiteboard, not in journal articles or writing for wider dissemination.\n\n\nAs an example, take the “minimalist conception” of democracy posed by Przeworski (2024, 5): “A regime is democratic if and only if people are free to choose, including to remove, governments.” Let \\(P\\) be the statement “The regime is democratic” and \\(Q\\) be the statement “The regime’s people are free to choose, including to remove, governments.”\n\nThe statement \\(P \\to Q\\) means “The regime is democratic only if its people are free to choose, including to remove, governments” — the people’s ability to remove the government is a necessary condition for democracy.\nThe statement \\(Q \\to P\\) means “The regime is democratic if its people are free to choose, including to remove, governments” — the people’s ability to remove the government is a sufficient condition for democracy.\n\nLogical equivalence means \\(P\\) implies \\(Q\\) and vice versa, so we denote it with the biconditional \\(P \\leftrightarrow Q\\). The statement \\(P \\leftrightarrow Q\\) is true whenever the truth values of \\(P\\) and \\(Q\\) match, and false otherwise. If you’re skeptical, you can use a truth table to confirm that the statement \\((P \\to Q) \\land (Q \\to P)\\) is true exactly when the truth values of \\(P\\) and \\(Q\\) match.\n\nExercise 1.4 Use a truth table to confirm that the statement \\((P \\to Q) \\land (Q \\to P)\\) is true exactly when the truth values of \\(P\\) and \\(Q\\) match.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(Q\\)\n\\(P \\to Q\\)\n\\(Q \\to P\\)\n\\((P \\to Q) \\land (Q \\to P)\\)\n\n\n\n\ntrue\ntrue\ntrue\ntrue\ntrue\n\n\ntrue\nfalse\nfalse\ntrue\nfalse\n\n\nfalse\ntrue\ntrue\nfalse\nfalse\n\n\nfalse\nfalse\ntrue\ntrue\ntrue\n\n\n\n\n\n\n\nAn important logical equivalence, closely related to modus tollens (Theorem 1.2), is the contrapositive: \\(P \\to Q\\) is logically equivalent to \\(\\neg Q \\to \\neg P\\). The contrapositive is more useful in practice than you might expect. When you want to prove that \\(P \\to Q\\), sometimes it’s easier to start with \\(\\neg Q\\) and show that \\(\\neg P\\) must hold than to start with \\(P\\) and show that \\(Q\\) must hold. Even more radically, as we’ll see in Section 1.2.3 below, when you want to prove that \\(P\\) is true, sometimes it’s easiest to start with \\(\\neg P\\) and show that you end up with something known to be false.\n\nExercise 1.5 Use a truth table to confirm that \\(P \\to Q\\) is logically equivalent to \\(\\neg Q \\to \\neg P\\).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(Q\\)\n\\(P \\to Q\\)\n\\(\\neg P\\)\n\\(\\neg Q\\)\n\\(\\neg Q \\to \\neg P\\)\n\\((P \\to Q) \\leftrightarrow (\\neg Q \\to \\neg P)\\)\n\n\n\n\ntrue\ntrue\ntrue\nfalse\nfalse\ntrue\ntrue\n\n\ntrue\nfalse\nfalse\nfalse\ntrue\nfalse\ntrue\n\n\nfalse\ntrue\ntrue\ntrue\nfalse\ntrue\ntrue\n\n\nfalse\nfalse\ntrue\ntrue\ntrue\ntrue\ntrue\n\n\n\n\n\n\n\n\n\n1.1.3 De Morgan’s laws\nWe have to be careful when using negation in combination with the “and” and “or” operators. This is probably easier when we’re working in words than when we’re working with notation, but we need caution either way. For example, let \\(F\\) be the statement “Finland is a democracy” and \\(R\\) be the statement “Russia is a democracy”. There are three ways for the compound statement \\(F \\land R\\) to be false:\n\n\\(F \\land \\neg R\\): Finland is a democracy, but Russia is not.\n\\(\\neg F \\land R\\): Finland is not a democracy, but Russia is.\n\\(\\neg F \\land \\neg R\\): Finland and Russia both are not democracies.\n\nIn other words, if \\(F \\land R\\) is false, then we know at least one of \\(F\\) or \\(R\\) must be false — but without other information, we can’t say which one. In other other words, we can conclude from \\(\\neg (F \\land R)\\) that \\(\\neg F \\lor \\neg R\\). The negation of an “and” statement gives us an “or” statement.\nI’m highlighting this because I don’t want you to be tempted to treat the formal logic operators like addition and multiplication. In the realm of high-school algebra, you might remember that \\[-(f + r) = (-f) + (-r).\\] Yet in the realm of sentential logic, the statement \\(\\neg (F \\land R)\\) is not equivalent to \\(\\neg F \\land \\neg R\\).\nDe Morgan’s laws are a pair of logical equivalences that tell us exactly how to combine negation with “and” and “or.” Before stating them formally, here’s how I think about them informally.\n\nAn “and” statement is strong, since \\(F \\land R\\) means that both underlying statements are true. The negation of an “and” statement must then be weak, because \\(\\neg (F \\land R)\\) only means that at least one of the underlying statements is false.\nAn “or” statement is weak, since \\(F \\lor R\\) only means that at least one of the underlying statements is true. The negation of an “or” statement must then be strong, because \\(\\neg (F \\lor R)\\) means that both underlying statements are false.\nTherefore, the negation of an “and” statement must be an “or” statement, and vice versa.\n\n\nTheorem 1.3 (De Morgan’s laws) \\[\\begin{align*}\n\\neg (P \\land Q) &\\leftrightarrow (\\neg P \\lor \\neg Q) \\\\\n\\neg (P \\lor Q) &\\leftrightarrow (\\neg P \\land \\neg Q)\n\\end{align*}\\]\n\n\nProof. I will prove the first law with a truth table, then leave the second one to you as an exercise.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(Q\\)\n\\(P \\land Q\\)\n\\(\\neg (P \\land Q)\\)\n\\(\\neg P\\)\n\\(\\neg Q\\)\n\\(\\neg P \\lor \\neg Q\\)\n\\(\\neg (P \\land Q) \\leftrightarrow (\\neg P \\lor \\neg Q)\\)\n\n\n\n\ntrue\ntrue\ntrue\nfalse\nfalse\nfalse\nfalse\ntrue\n\n\ntrue\nfalse\nfalse\ntrue\nfalse\ntrue\ntrue\ntrue\n\n\nfalse\ntrue\nfalse\ntrue\ntrue\nfalse\ntrue\ntrue\n\n\nfalse\nfalse\nfalse\ntrue\ntrue\ntrue\ntrue\ntrue\n\n\n\n\n\n\n\n\n\nProof of the second law\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(Q\\)\n\\(P \\lor Q\\)\n\\(\\neg (P \\lor Q)\\)\n\\(\\neg P\\)\n\\(\\neg Q\\)\n\\(\\neg P \\land \\neg Q\\)\n\\(\\neg (P \\lor Q) \\leftrightarrow (\\neg P \\land \\neg Q)\\)\n\n\n\n\ntrue\ntrue\ntrue\nfalse\nfalse\nfalse\nfalse\ntrue\n\n\ntrue\nfalse\ntrue\nfalse\nfalse\ntrue\nfalse\ntrue\n\n\nfalse\ntrue\ntrue\nfalse\ntrue\nfalse\nfalse\ntrue\n\n\nfalse\nfalse\nfalse\ntrue\ntrue\ntrue\ntrue\ntrue",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Formal Logic and Proofs</span>"
    ]
  },
  {
    "objectID": "logic.html#methods-of-proof",
    "href": "logic.html#methods-of-proof",
    "title": "1  Formal Logic and Proofs",
    "section": "1.2 Methods of proof",
    "text": "1.2 Methods of proof\nThe vast majority of proofs you’ll read — and write — will not be in the form of a truth table. The number of rows in the truth table grows exponentially with the number of sentences, making it unwieldy to use truth tables to prove complex claims. For example, it is hard to imagine using a truth table to prove the median voter theorem (Black 1948), an important but relatively simple result as formal theories of politics go.\n\n\n“Grows exponentially” is a phrase with a precise meaning that people often use imprecisely. Here I mean it in the literal sense, as a compound statement built from \\(N\\) underlying sentences requires a truth table with \\(2^N\\) rows. In words, each additional sentence doubles the number of rows in the truth table.\nA proof is written in ordinary language, just with a bit more attention to precision than you might use in other ordinary writing. The goal is to convince the reader of the truth of whatever claim you have made, following the basic rules of logical inference we have established here. In essence, you need to show the reader why any objection to your claim will ultimately fail.\nUse mathematical notation sparingly in proofs. Only use notation when it’s necessary for precision or brevity. In almost all settings, it is much better to write “Let \\(n\\) be an odd number” than to write “Let \\(n \\in \\{2m - 1 \\mid m \\in \\mathbb{N}\\}\\).”\n\n\n\n\n\n\nReading proofs\n\n\n\nI’m deliberately more verbose in the proofs here than in the proofs you’d see in a published paper, or even in most textbooks. The structure of arguments in those venues tends to be the same as the one here, though — they just have a bit less verbiage to hold the reader’s hand.\nIn proofs in (other) textbooks and academic articles, you’ll often see phrases like “It is obvious that…” or “It is straightforward to show that…”. Students — and professors! — understandably find these statements frustrating or alienating, because whatever comes next often does not seem obvious or straightforward at all. But really, “It is obvious that…” is shorthand for:\n\nThe statement that comes next can be proved using mathematical methods that a reader of this document would typically have extensive practice with. (For example, in a textbook about calculus, such methods would include arithmetic and algebra. In a paper in the Journal of Economic Theory, they would include calculus, differential equations, real analysis, and topology.) There aren’t any new tricks or novel arguments to reach this step, just chugging through calculations. You are welcome to do those calculations yourself to check my work, though I expect you won’t find anything particularly edifying along the way. Because space is limited in this book or journal article, I haven’t included all the gory details myself.\n\nWhat if the proof you’re reading says something is obvious or straightforward, but you can’t convince yourself it’s true? After getting out your legal pad and trying to work it out yourself, that’s when you should ask for help. I find myself in this situation often, and as of summer 2025 I’ve found that ChatGPT’s o4-mini-high model gives great explanations when I’m stuck on something mathematical. And throughout your careers here, you can always feel free to ask me or the other methods/formal theory faculty when you’re stuck on something!\nProofs conventionally end with “QED”, \\(\\blacksquare\\), or \\(\\square\\). As of summer 2025, the Quarto software I’m using to write these notes doesn’t insert any of these symbols automatically, so you’ll just have to take the bottom of the box that the proof lives in as my “QED” variant.\n\n\n\n1.2.1 Proving an “if” statement\nLet’s practice writing a plain language proof of a statement about formal logic. The statement I want to prove is called the law of transitivity: if we know that \\(P \\to Q\\) and that \\(Q \\to R\\), then we can conclude that \\(P \\to R\\).\n\nProposition 1.1 (Law of transitivity) Logical implication is transitive: \\([(P \\to Q) \\land (Q \\to R)] \\to (P \\to R)\\).\n\nWe could prove this using a truth table, and in fact the first Google hit for “transitivity of implication” does exactly that. But I want to walk you through how I’d write an ordinary language proof, step by step. I’ll put each step in a blockquote, with explanation thereafter.\n\nSuppose \\(P \\to Q\\) and \\(Q \\to R\\).\n\nThe most common way to kick off a proof of an if-then statement is to state that we will assume the premise (the “if”) is true. That might seem like a weird thing to do when the premise could very well be false. However, remember that in formal logic, the only way to falsify a conditional statement is to show that the conclusion might fail when the premise is true. If the premise is false, then the conditional is (vacuously) true. So to demonstrate the overall truth of the conditional statement, it’s enough for us to show that the conclusion must hold whenever the premise does.\nHaving assumed the premise, where do we go from here? We ultimately need to reach the conclusion that \\(P \\to R\\). To get there, we’re going to use the common trick of breaking the proof into cases. We know that either \\(P\\) is true or \\(P\\) is false (i.e., \\(P \\lor \\neg P\\) is a tautology). Let’s show that either one of these possibilities leads to the conclusion we want, namely that \\(P \\to R\\).\n\n\nAre you skeptical that this trick is logically valid? If so, don’t worry — you’ll prove its logical validity yourself on the problem set.\n\nThere are two cases to consider: when \\(P\\) is true, and when \\(P\\) is false. We will show that \\(P \\to R\\) holds in both cases.\n\nAs you might already know from trying to read proofs, it’s easy for a reader to get lost in the formal logic. So the line above is just an explicit signpost, attempting to signal: “We’re going to break the proof into mutually exhaustive cases, showing that each case leads to our desired conclusion, and thus the conclusion must hold.” It’s kind of like writing comments in your R code — not strictly necessary for the program to work, but very helpful for anyone who’s trying to follow it.\n\nFirst, suppose \\(P\\) is true. Because \\(P\\) and \\(P \\to Q\\) are both true, we conclude by modus ponens that \\(Q\\) is true.\n\nWe’ve started the analysis of the first case here. You can start to see why the cases trick is useful: having assumed initially that \\(P \\to Q\\), and now that \\(P\\) is true as well, we can proceed to \\(Q\\). Here we make that line of logic explicit.\nThere’s also a meta-lesson here about knowing your audience when you write a proof. I’m setting out this proof as an introduction for students without much background in reading or writing math-style proofs. Hence, I’m trying to be detailed and explicit, down to acknowledging that modus ponens is the logical rule I’m using to infer \\(Q\\) from the combination of \\(P \\to Q\\) and \\(P\\). In a proof for an article I were submitting to a journal, I would not bother to say I was using modus ponens; I would assume my readers were familiar with the basic rules of logical inference. That said, when you aren’t sure how to proceed, err on the side of giving details rather than skipping steps.\n\nThen, because \\(Q\\) and \\(Q \\to R\\), we conclude (again by modus ponens) that \\(R\\) is true. Because \\(P\\) and \\(R\\) are both true, the statement \\(P \\to R\\) is true as well.\n\nHere we keep following the line of logic, using our inference about \\(Q\\) in the last step to support an inference of \\(R\\) in this step. We then reach the conclusion we were looking for, namely that when we start with \\(P\\) (in addition to the assumptions of \\(P \\to Q\\) and \\(Q \\to R\\) that we made at the outset of the proof) we get to \\(P \\to R\\).\n\nSecond, suppose \\(P\\) is false. Then it is vacuously true that \\(P \\to R\\).\n\nThe second case is simpler than the last one. (I personally try to arrange my proofs so that the trickier case comes first, under the assumption that readers’ attention is ever-waning, but it’s really a judgment call.) And again we’ve written it up to try to be friendly to the reader. We could have simply written, “Second, \\(\\neg P\\) implies \\(P \\to R\\),” but with just a few more words we make it clear precisely why we’re drawing this conclusion.\n\nAltogether, we have shown that \\(P \\to R\\) whether \\(P\\) is true or false. We conclude that \\(P \\to R\\).\n\nThis is one last little bit of logical signposting, summing up the line of logic that has gotten us to the ultimate conclusion. This might be overkill when the proof is so short, but I’m including it by my own logic that it’s better to do a bit too much hand-holding than a bit too little.\nPutting all of this together to prove Proposition 1.1:\n\nProof. Suppose \\(P \\to Q\\) and \\(Q \\to R\\). There are two cases to consider: when \\(P\\) is true, and when \\(P\\) is false. We will show that \\(P \\to R\\) holds in both cases.\nFirst, suppose \\(P\\) is true. Because \\(P\\) and \\(P \\to Q\\) are both true, we conclude by modus ponens that \\(Q\\) is true. Then, because \\(Q\\) and \\(Q \\to R\\), we conclude (again by modus ponens) that \\(R\\) is true. Because \\(P\\) and \\(R\\) are both true, the statement \\(P \\to R\\) is true as well.\nSecond, suppose \\(P\\) is false. Then it is vacuously true that \\(P \\to R\\).\nAltogether, we have shown that \\(P \\to R\\) whether \\(P\\) is true or false. We conclude that \\(P \\to R\\).\n\n\nExercise 1.6 Write a plain language proof of the modus tollens rule (Theorem 1.2).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYour proof will of course differ from mine, but here’s how I approached it.\nSuppose that \\(P \\to Q\\) is true and that \\(Q\\) is false. We know from Exercise 1.5 that \\(P \\to Q\\) is logically equivalent to the contrapositive \\(\\neg Q \\to \\neg P\\). Then, because we know that \\(\\neg Q\\) and \\(\\neg Q \\to \\neg P\\) are both true, we infer by modus ponens that \\(\\neg P\\) is true. Consequently, we have proved that the conjunction of \\(P \\to Q\\) and \\(\\neg Q\\) implies \\(\\neg P\\).\n\n\n\n\n\nExercise 1.7 Assume \\(a\\) is an integer. Write a plain language proof of the claim that if \\(a^2\\) is even, then \\(a\\) is even. (An integer \\(a\\) is even if it is divisible by 2: there is some integer \\(n\\) such that \\(a = 2 \\times n\\).)\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nI will prove the contrapositive. Assume \\(a\\) is not even, so it is not a factor of 2. Then \\(a^2 = a \\times a\\) also is not a factor of 2 and is not even. We have shown that if \\(a\\) is not even, then \\(a^2\\) is not even; this is equivalent to the claim that if \\(a^2\\) is even, then \\(a\\) is even.\n\n\n\n\n\n\n1.2.2 Proving an “if and only if” statement\nA claim of logical equivalence (\\(P \\leftrightarrow Q\\)) is a claim that two implications hold (\\(P \\to Q\\) and \\(Q \\to P\\)). So the most straightforward way to prove that \\(P\\) and \\(Q\\) are equivalent is to prove each implication individually.\nAs an example, let’s prove that the “and” operator is associative, meaning that \\((P \\land Q) \\land R\\) is logically equivalent to \\(P \\land (Q \\land R)\\). The associative property is convenient because, at a minimum, it lets us kill the parentheses and write \\(P \\land Q \\land R\\).\n\n\nBut be careful: you can’t necessarily change or drop parentheses when you’re using different operators. To wit, \\((P \\land Q) \\lor R\\) is not logically equivalent to \\(P \\land (Q \\lor R)\\).\n\nProposition 1.2 (Associativity of “and”) The “and” operator is associative: \\([(P \\land Q) \\land R] \\leftrightarrow [P \\land (Q \\land R)]\\).\n\n\nProof. We begin by proving that \\((P \\land Q) \\land R\\) implies \\(P \\land (Q \\land R)\\). Suppose it is true that \\((P \\land Q) \\land R\\). Then it must be the case that \\(P \\land Q\\) is true, as is \\(R\\). Because \\(P \\land Q\\) is true, we infer that \\(P\\) and \\(Q\\) are each true as well. Because \\(Q\\) and \\(R\\) are true, \\(Q \\land R\\) is true. Finally, because \\(P\\) and \\(Q \\land R\\) are each true, it is true that \\(P \\land (Q \\land R)\\).\nThe proof that \\(P \\land (Q \\land R)\\) implies \\((P \\land Q) \\land R\\) is similar. Suppose that \\(P \\land (Q \\land R)\\) is true. We infer that \\(P\\) is true and that \\(Q \\land R\\) is true, and from the latter we infer that \\(Q\\) and \\(R\\) are each true. The truth of \\(P\\) and \\(Q\\) gives us \\(P \\land Q\\), which combined with the truth of \\(R\\) gives us \\((P \\land Q) \\land R\\).\n\nOnce again, notice the signposting in the way the proof is written. You want to clearly delineate when you’re proving one direction versus when you’re proving the other. This is particularly important for longer proofs, where a reader might get lost about exactly which logical step you’re working through at any given point. You’ll also notice that the second paragraph explicitly states that the method of proof is similar to the first paragraph. This lets readers know that there’s nothing new going on here, so they can skim or skip if they understood the prior logic (or to read with skepticism if they didn’t buy the prior logic!).\nAnother common way to prove a claim like \\(P \\leftrightarrow Q\\) is to prove that \\(P \\to Q\\) and that \\(\\neg P \\to \\neg Q\\). This is equivalent to the last method of proof, as we know that the contrapositive \\(\\neg P \\to \\neg Q\\) is equivalent to \\(Q \\to P\\). Despite this equivalence in a formal logical sense, sometimes for purposes of writing the proof in plain English it’s easier to approach from this direction.\nThere’s one more way to prove a logical equivalence that’s more concise — but trickier — than the two methods I mentioned above. This third way is what I’ll call the chain of equivalences: to prove that \\(P \\leftrightarrow Q\\), prove that there is some third statement \\(R\\) for which \\(P \\leftrightarrow R\\) and \\(R \\leftrightarrow Q\\). Or add more steps in between if you need: prove that \\(P \\leftrightarrow R\\), that \\(R \\leftrightarrow S\\), that \\(S \\leftrightarrow T\\), and finally that \\(T \\leftrightarrow Q\\). The important thing to keep in mind is that every step along the way must be a full equivalence (“if and only if”), not a mere conditional (just “if” or just “only if”). Usually I end up taking the long way to prove logical equivalences, but it’s a nice treat when I can find a single chain of equivalence that works. For an example of a proof that works this way, see Section 1.2.4 below.\n\n\n1.2.3 Proof by contradiction\nAnother common proof technique, the proof by contradiction, is built around a reductio ad absurdum. We want to prove that some statement \\(P\\) is true. To do so, we show that if \\(P\\) isn’t true, then we end up coming to some absurd conclusion. We infer that \\(P\\) must be true.\nOne of my favorite (silly) proofs by contradiction is the proof that every counting number \\(n = 1, 2, \\ldots\\) is interesting.\n\nProposition 1.3 (not really a proposition) Every natural number \\(n = 1, 2, \\ldots\\) is interesting.\n\n\nProof. We will prove the claim by contradiction. Suppose the claim is false, so there is at least one natural number that is not interesting. By the well-ordering principle, this means there is a number \\(m\\) which is the smallest natural number that is not interesting. However, it is interesting that \\(m\\) is the smallest natural number that is not interesting. We have reached a contradiction, having shown that \\(m\\) is both uninteresting and interesting. Therefore, it must be the case that every natural number is interesting.\n\nA more tedious, but also more famous and important, proof by contradiction is the proof that \\(\\sqrt{2}\\) cannot be expressed as a fraction. In other words, \\(\\sqrt{2}\\) is an irrational number.\n\nProposition 1.4 There is no pair of integers \\(p\\) and \\(q\\) for which \\(\\sqrt{2} = \\frac{p}{q}\\).\n\n\nProof. We will prove the claim by contradiction. Suppose the claim is false, so there is an integer \\(p\\) and an integer \\(q \\neq 0\\) such that \\(\\sqrt{2} = \\frac{p}{q}\\).\nThe first thing we are going to do is remove all common factors of 2 from \\(p\\) and \\(q\\). In other words, we are going to reduce the fraction \\(\\frac{p}{q}\\) until the numerator is odd or the denominator is odd (or both). If \\(p\\) or \\(q\\) is odd, then let \\(a = p\\) and let \\(b = q\\). Otherwise, if \\(p\\) and \\(q\\) are both even, then divide both by 2. Continue this process until at least one of \\(p\\) or \\(q\\) is not divisible by 2, and let \\(a\\) and \\(b\\) be the results. Because we always divided the numerator and the denominator by the same factor, we end up with the same fraction: \\(\\frac{a}{b} = \\frac{p}{q} = \\sqrt{2}\\).\nBecause \\(\\frac{a}{b} = \\sqrt{2}\\), we have \\(\\frac{a^2}{b^2} = 2\\) and thus \\(a^2 = 2 b^2\\). Because \\(b^2\\) is an integer, this means \\(a^2\\) is divisible by 2 and thus is an even number, which in turn means \\(a\\) is an even number (see Exercise 1.7). Therefore, because we constructed \\(a\\) and \\(b\\) so that one of them at most could be even, \\(b\\) must not be an even number.\nBecause \\(a\\) is even and thus divisible by 2, it must be the case that \\(a^2\\) is divisible by 4. This in turn means that \\(a^2 / 2\\) is divisible by 2. But remember that \\(a^2 = 2 b^2\\) and thus \\(b^2 = a^2 / 2\\), so we have that \\(b^2\\) is even. This in turn implies that \\(b\\) must be an even number (again see Exercise 1.7).\nBy assuming that \\(\\sqrt{2}\\) is rational, we have come to the contradictory conclusion that there is an integer that is both even and not even. Therefore, \\(\\sqrt{2}\\) is not rational.\n\nAs we did with modus ponens (Theorem 1.1) and modus tollens (Theorem 1.2), we can use a truth table to establish the logical validity of proof by contradiction. First we need to state the logic behind it in the form of a compound sentence. We want to show that \\(P\\) is true. To do so, we show that if \\(P\\) is false, then we reach some conclusion that we know not to be true. I’m going to represent this with a special sentence \\(F\\), whose truth value is always false. (If you’re not comfortable with this, you could replace \\(F\\) with the negation of a tautology, such as \\(Q \\land \\neg Q\\).) The idea behind proof by contradiction is that if \\(\\neg P\\) implies \\(F\\), then we conclude \\(P\\) is true. Stated formally, the line of logic is \\((\\neg P \\to F) \\to P\\).\n\nTheorem 1.4 (Proof by contradiction) Letting \\(F\\) be a sentence that is always false, \\((\\neg P \\to F) \\to P\\).\n\n\nProof. We can prove the claim using a truth table:\n\n\n\n\n\n\n\n\n\n\n\\(P\\)\n\\(F\\)\n\\(\\neg P\\)\n\\(\\neg P \\to F\\)\n\\((\\neg P \\to F) \\to P\\)\n\n\n\n\ntrue\nfalse\nfalse\ntrue\ntrue\n\n\nfalse\nfalse\ntrue\nfalse\ntrue\n\n\n\nAlternatively, here’s a plain language proof of the claim. Suppose \\(\\neg P \\to F\\). Either this claim is vacuously true, or else \\(\\neg P \\land F\\). Since \\(\\neg P \\land F\\) cannot possibly be true, as \\(F\\) is false, the claim must be vacuously true. Vacuous truth of \\(\\neg P \\to F\\) means that \\(\\neg (\\neg P)\\) is true, which is equivalent to \\(P\\) being true. Therefore, \\(\\neg P \\to F\\) implies that \\(P\\) is true.\n\n\n\n1.2.4 Proof by induction\nEarlier we saw De Morgan’s laws (Theorem 1.3), which tell us that the negation of an “and” statement is an “or” statement, and vice versa. Intuitively, it seems like it should be true that for any number \\(n\\) of statements, \\(P_1, \\ldots, P_n\\), the negation \\(\\neg (P_1 \\land \\cdots \\land P_n)\\) is logically equivalent to \\(\\neg P_1 \\lor \\cdots \\lor \\neg P_n\\). De Morgan’s laws tell us that this holds in the special case \\(n = 2\\). But how can we show that it holds for a conjunction of \\(n = 3\\), or \\(n = 100\\), or \\(n = 10^{10^{10}}\\) statements as well?\nTo prove that De Morgan’s laws extend to a conjunction of any (finite) number of statements, we will write a proof by induction. This is a proof technique designed for the following situation:\n\nWe are dealing with a claim whose precise statement depends on a number \\(n\\). As shorthand to denote “a claim \\(Q\\) whose precise form depends on a number \\(n\\)”, we will write \\(Q(n)\\).\nIn the De Morgan’s law example here, the claim \\(Q(1)\\) is the trivial statement that \\(\\neg P_1 \\leftrightarrow \\neg P_1\\). \\(Q(2)\\) is the De Morgan’s law we already proved, \\(\\neg (P_1 \\land P_2) \\leftrightarrow (\\neg P_1 \\lor \\neg P_2)\\). \\(Q(3)\\) is \\(\\neg (P_1 \\land P_2 \\land P_3) \\leftrightarrow (\\neg P_1 \\lor \\neg P_2 \\lor \\neg P_3)\\). And so on.\nWe want to show that \\(Q(n)\\) is true for all numbers \\(n = 1, 2, 3, \\ldots\\), and so on infinitely.\nIn the De Morgan’s law example, we could definitely use a truth table to prove the statement for a reasonably small \\(n\\), like 3 or 4. But even once we get to \\(n = 10\\), we’re talking about a truth table with 1,024 rows. That seems like overkill to prove a claim that intuitively seems like it ought to be true.\n\nA proof by induction breaks the seemingly infinite task of proving \\(Q(n)\\) for all \\(n\\) into just two steps. First, in the base step, we prove that the claim \\(Q(n)\\) is true for \\(n = 1\\). In the example here, \\(Q(1)\\) is just the statement that \\(\\neg P_1 \\leftrightarrow \\neg P_1\\), which of course is true. That establishes the base step.\nSecond, in the induction step, we prove that for any number \\(k\\), if \\(Q(k)\\) is true, then \\(Q(k + 1)\\) is true. In combination, the base step and the induction step establish that every \\(Q(n)\\) must be true. The induction step proves that \\(Q(1) \\to Q(2)\\), and the base step proves that \\(Q(1)\\) is true. Hence, by modus ponens, \\(Q(2)\\) is true. The induction step proves that \\(Q(2) \\to Q(3)\\), so again by modus ponens, \\(Q(3)\\) is true. We can follow this chain of logic up to any \\(n\\) that we want.\nThe induction step is usually the trickier part of the proof. Let’s work through the induction step for our claim about De Morgan’s law.\n\nProof. We need to show that \\(Q(k)\\) implies \\(Q(k + 1)\\). To do that, as in a typical proof of a conditional statement, we will begin by assuming \\(Q(k)\\) is true, i.e., that \\[\\neg (P_1 \\land \\cdots \\land P_k) \\leftrightarrow (\\neg P_1 \\lor \\cdots \\lor \\neg P_k).\\] Our goal is to show that \\(Q(k + 1)\\) is true, i.e., that \\[\\neg (P_1 \\land \\cdots \\land P_k \\land P_{k+1}) \\leftrightarrow (\\neg P_1 \\lor \\cdots \\lor \\neg P_k \\lor \\neg P_{k+1}).\\] We could separately prove each side of this implication, but we can also use a chain of equivalences.\nBy the associativity of the “and” operator, we have \\[\\neg (P_1 \\land \\cdots \\land P_k \\land P_{k+1}) \\leftrightarrow \\neg [(P_1 \\land \\cdots \\land P_k) \\land P_{k+1}].\\] By De Morgan’s laws, we have \\[\\neg [(P_1 \\land \\cdots \\land P_k) \\land P_{k+1}] \\leftrightarrow [\\neg (P_1 \\land \\cdots \\land P_k) \\lor \\neg P_{k+1}].\\] By our assumption that \\(Q(k)\\) is true, we have \\[[\\neg (P_1 \\land \\cdots \\land P_k) \\lor \\neg P_{k+1}] \\leftrightarrow [(\\neg P_1 \\lor \\cdots \\lor \\neg P_k) \\lor \\neg P_{k+1}].\\] Finally, by the associativity of the “or” operator, we have \\[[(\\neg P_1 \\lor \\cdots \\lor \\neg P_k) \\lor \\neg P_{k+1}] \\leftrightarrow (\\neg P_1 \\lor \\cdots \\lor \\neg P_k \\lor \\neg P_{k+1}).\\] Following the chain of equivalences, we have \\[\\neg (P_1 \\land \\cdots \\land P_k \\land P_{k+1}) \\leftrightarrow (\\neg P_1 \\lor \\cdots \\lor \\neg P_k \\lor \\neg P_{k+1}),\\] establishing the induction step.\n\n\nExercise 1.8 Use a proof by induction to prove that \\(2^n \\geq n + 1\\) for every counting number \\(n = 1, 2, \\ldots\\).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFor the base step, we must show that \\(2^1 \\geq 1 + 1\\). This holds because \\(2^1 = 2 = 1 + 1\\).\nFor the induction step, we must show that if \\(2^k \\geq k + 1\\), then \\(2^{k+1} \\geq (k + 1) + 1\\). Suppose \\(2^k \\geq k + 1\\). By definition, \\(2^{k+1} = 2 \\times 2^k\\). We have assumed that \\(2^k \\geq k + 1\\), which implies that \\(2 \\times 2^k \\geq 2 \\times (k + 1)\\). Because \\(k \\geq 0\\), we have \\(2 \\times (k + 1) \\geq (k + 1) + 1\\). Putting this all together, we have \\[2^{k+1} = 2 \\times 2^k \\geq 2 \\times (k + 1) \\geq (k + 1) + 1,\\] proving the induction step.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Formal Logic and Proofs</span>"
    ]
  },
  {
    "objectID": "logic.html#concept-review",
    "href": "logic.html#concept-review",
    "title": "1  Formal Logic and Proofs",
    "section": "1.3 Concept review",
    "text": "1.3 Concept review\n\nConceptual orderAlphabetical order\n\n\n\nProvably true\n\nA statement whose truth can be defended against all challenges, using only rules of logical inference.\n\nSentence\n\nIn formal logic, a statement that must be either true or false, and cannot be both.\n\nSentential logic\n\nA set of rules for deducing the truth of compound sentences.\n\nNegation\n\nAn operation on a single sentence that flips the truth value of the sentence, denoted \\(\\neg P\\). \\(P\\) true means \\(\\neg P\\) is false, and \\(P\\) false means \\(\\neg P\\) is true.\n\nAnd\n\nAn operation on two sentences that indicates whether both are true, denoted \\(P \\land Q\\).\n\nOr\n\nAn operation on two sentences that indicates whether at least one is true, denoted \\(P \\lor Q\\).\n\nTautology\n\nA compound sentence that is always true, regardless of the truth value of the sentences from which it is constructed. For example, \\(P \\lor \\neg P\\) (“\\(P\\) is true, or \\(P\\) is not true”) is a tautology.\n\nTruth table\n\nAn algorithm for determining the truth value of compound sentences. Each row is a unique combination of truth values of the simple sentences from which the compound is formed, and each column is a component of the compound sentence you are trying to evaluate.\n\nConditional\n\nAn if-then statement, written in formal logic as \\(P \\to Q\\), treated as the equivalent of \\(\\neg P \\lor Q\\).\n\nNecessary condition\n\n\\(Q\\) is a necessary condition for \\(P\\) when \\(Q\\) has to be true whenever \\(P\\) is true. The conditional \\(P \\to Q\\) means that \\(Q\\) is necessary for \\(P\\).\n\nSufficient condition\n\n\\(P\\) is a sufficient condition for \\(Q\\) when \\(P\\) being true guarantees that \\(Q\\) is true. The conditional \\(P \\to Q\\) means that \\(P\\) is sufficient for \\(Q\\).\n\nVacuously true\n\nA conditional statement \\(P \\to Q\\) that is true because its premise is known to be false, such as “If 0 = 1, then Peter Bils lives in a pineapple under the sea.”\n\nModus ponens\n\nThe logical rule that if \\(P\\) is true and \\(P \\to Q\\) is true, then we can infer that \\(Q\\) is true.\n\nModus tollens\n\nThe logical rule that if \\(\\neg Q\\) is true and \\(P \\to Q\\) is true, then we can infer that \\(\\neg P\\) is true.\n\nLogical equivalence\n\n\\(P\\) and \\(Q\\) are logically equivalent when \\(P \\to Q\\) and \\(Q \\to P\\). Logical equivalence holds when the truth values of the statements match — both are true or both are false.\n\nBiconditional\n\nThe statement \\(P \\leftrightarrow Q\\), meaning \\(P\\) and \\(Q\\) are logically equivalent.\n\nContrapositive\n\nThe translation of the statement \\(P \\to Q\\) into the logically equivalent statement \\(\\neg Q \\to \\neg P\\).\n\nDe Morgan’s laws\n\nConceptually, the idea that the negation of an “and” statement is an “or” statement, and vice versa. Formally, the logical equivalences \\(\\neg (P \\land Q) \\leftrightarrow \\neg P \\lor \\neg Q\\) and \\(\\neg (P \\lor Q) \\leftrightarrow \\neg P \\land \\neg Q\\).\n\nProof by contradiction\n\nA proof where we show that \\(P\\) is true by proving that \\(\\neg P\\) implies something impossible.\n\nProof by induction\n\nA proof technique used when (a) we have a claim that depends on a number \\(n\\) and (b) we want to prove it’s true for every \\(n = 1, 2, 3, \\ldots\\). In the base step, we show that the claim is true for \\(n = 1\\). In the induction step, we assume the truth of the claim for \\(n = k\\), and we show that this implies the truth of the claim for \\(n = k + 1\\).\n\n\n\n\n\nAnd\n\nAn operation on two sentences that indicates whether both are true, denoted \\(P \\land Q\\).\n\nBiconditional\n\nThe statement \\(P \\leftrightarrow Q\\), meaning \\(P\\) and \\(Q\\) are logically equivalent.\n\nConditional\n\nAn if-then statement, written in formal logic as \\(P \\to Q\\), treated as the equivalent of \\(\\neg P \\lor Q\\).\n\nContrapositive\n\nThe translation of the statement \\(P \\to Q\\) into the logically equivalent statement \\(\\neg Q \\to \\neg P\\).\n\nDe Morgan’s laws\n\nConceptually, the idea that the negation of an “and” statement is an “or” statement, and vice versa. Formally, the logical equivalences \\(\\neg (P \\land Q) \\leftrightarrow \\neg P \\lor \\neg Q\\) and \\(\\neg (P \\lor Q) \\leftrightarrow \\neg P \\land \\neg Q\\).\n\nLogical equivalence\n\n\\(P\\) and \\(Q\\) are logically equivalent when \\(P \\to Q\\) and \\(Q \\to P\\). Logical equivalence holds when the truth values of the statements match — both are true or both are false.\n\nModus ponens\n\nThe logical rule that if \\(P\\) is true and \\(P \\to Q\\) is true, then we can infer that \\(Q\\) is true.\n\nModus tollens\n\nThe logical rule that if \\(\\neg Q\\) is true and \\(P \\to Q\\) is true, then we can infer that \\(\\neg P\\) is true.\n\nNecessary condition\n\n\\(Q\\) is a necessary condition for \\(P\\) when \\(Q\\) has to be true whenever \\(P\\) is true. The conditional \\(P \\to Q\\) means that \\(Q\\) is necessary for \\(P\\).\n\nNegation\n\nAn operation on a single sentence that flips the truth value of the sentence, denoted \\(\\neg P\\). \\(P\\) true means \\(\\neg P\\) is false, and \\(P\\) false means \\(\\neg P\\) is true.\n\nOr\n\nAn operation on two sentences that indicates whether at least one is true, denoted \\(P \\lor Q\\).\n\nProof by contradiction\n\nA proof where we show that \\(P\\) is true by proving that \\(\\neg P\\) implies something impossible.\n\nProof by induction\n\nA proof technique used when (a) we have a claim that depends on a number \\(n\\) and (b) we want to prove it’s true for every \\(n = 1, 2, 3, \\ldots\\). In the base step, we show that the claim is true for \\(n = 1\\). In the induction step, we assume the truth of the claim for \\(n = k\\), and we show that this implies the truth of the claim for \\(n = k + 1\\).\n\nProvably true\n\nA statement whose truth can be defended against all challenges, using only rules of logical inference.\n\nSentence\n\nIn formal logic, a statement that must be either true or false, and cannot be both.\n\nSentential logic\n\nA set of rules for deducing the truth of compound sentences.\n\nSufficient condition\n\n\\(P\\) is a sufficient condition for \\(Q\\) when \\(P\\) being true guarantees that \\(Q\\) is true. The conditional \\(P \\to Q\\) means that \\(P\\) is sufficient for \\(Q\\).\n\nTautology\n\nA compound sentence that is always true, regardless of the truth value of the sentences from which it is constructed. For example, \\(P \\lor \\neg P\\) (“\\(P\\) is true, or \\(P\\) is not true”) is a tautology.\n\nTruth table\n\nAn algorithm for determining the truth value of compound sentences. Each row is a unique combination of truth values of the simple sentences from which the compound is formed, and each column is a component of the compound sentence you are trying to evaluate.\n\nVacuously true\n\nA conditional statement \\(P \\to Q\\) that is true because its premise is known to be false, such as “If 0 = 1, then Peter Bils lives in a pineapple under the sea.”\n\n\n\n\n\n\n\n\n\nBlack, Duncan. 1948. “On the Rationale of Group Decision-Making.” Journal of Political Economy 56 (1): 23–34.\n\n\nPrzeworski, Adam. 2024. “Who Decides What Is Democratic?” Journal of Democracy 35 (3): 5–16.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Formal Logic and Proofs</span>"
    ]
  },
  {
    "objectID": "set_theory.html",
    "href": "set_theory.html",
    "title": "2  Set Theory",
    "section": "",
    "text": "2.1 What are sets and why do we care?\nSeemingly every book on “higher math” — the kind of math you encounter after the intro calculus sequence in college — starts with a discussion of set theory. There are some deep mathematical reasons to begin this way, which you can read about on Wikipedia or, for the especially high-minded, the Stanford Encyclopedia of Philosophy. To summarize it very loosely: although most people think of math as being about numbers, most important mathematical statements (including those about numbers!) are ultimately actually rooted in the properties of sets.\nI’m putting set theory before our study of numbers-type math for reasons that are related, but more prosaic.\nAll right, so what is a set? Precisely because sets are so foundational, that turns out to be quite a sticky question to answer rigorously, so we will content ourselves with a non-rigorous definition.\nWhen we want to say briefly that \\(a\\) is an element of the set \\(A\\), we write \\(a \\in A\\). It is typical to use capital letters to denote sets and lowercase letters to denote their elements, though sometimes it is convenient or necessary to break this convention.\nAlthough sets aren’t just for numbers, there are a few sets of numbers that come up so often that we have special names for them. These are listed in Table 2.1.\nWhat if you wanted to define \\(A\\) as the set of natural numbers that are greater than 1000? Well, you could — and often should — simply write, “Let \\(A\\) be the set of natural numbers that are greater than 1000.” Don’t fall into the trap of equating rigor with fancy notation. If ordinary language can clearly communicate what you mean, use it.\nThat said, there are times when ordinary language is too cumbersome or imprecise to describe the contents of a set. Maybe there are a lot of conditions on the set you’re defining, or maybe the condition involves a finicky formula that’s hard to put into words. In these cases, it is common to use set-builder notation, for example \\[A = \\{x \\in \\mathbb{N} \\mid x &gt; 1000\\}.\\] You would read this as “\\(A\\) is the set of natural numbers \\(x\\) such that \\(x\\) is greater than 1000”.\nOr what if we wanted to define \\(B\\) as the set of values we obtain by taking a natural number and dividing it in half? We could write this in set-builder notation as \\[B = \\{x \\in \\mathbb{R} \\mid x = \\frac{n}{2} \\: \\text{for some $n \\in \\mathbb{N}$}\\}.\\] But we’ll often use the following shorthand to write this a bit less cumbersomely: \\[B = \\{\\frac{n}{2} \\mid n \\in \\mathbb{N}\\}.\\] Again, none of these, including the verbal description of \\(B\\) at the start of the paragraph, is the “right” way to denote the set. What’s best is whatever gets the point across clearly to your intended audience. Thinking about the audience is key — you might want to write the exact same mathematical object in a different way in your undergraduate lecture notes than in a manuscript you’re submitting to Political Analysis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Set Theory</span>"
    ]
  },
  {
    "objectID": "set_theory.html#what-are-sets-and-why-do-we-care",
    "href": "set_theory.html#what-are-sets-and-why-do-we-care",
    "title": "2  Set Theory",
    "section": "",
    "text": "Set theory gives us a lot of our mathematical “language”.\n\nMany of the definitions of day-to-day tools in calculus and linear algebra are stated in terms of sets and operations on sets.\nIn political science research, we use mathematical notation to concisely-yet-precisely summarize quantitative concepts. This notation often involves sets and operations on sets, so we need to get familiar if we want to be fluent in the “language” of math.\n\nSet theory gives us some nice examples of mathematical statements that are relatively easy to prove, making it a convenient as we get more practice writing proofs.\n\n\n\nDefinition 2.1 (Sets and elements) A set is a collection of objects, which we call the elements of the set. The notation \\[A = \\{1, 2, 4, 8\\}\\] is equivalent to saying “\\(A\\) is the set whose elements are 1, 2, 4, and 8.”\n\n\n\n\n\n\n\n\nSets aren’t just for numbers\n\n\n\nA set may consist of objects besides numbers. It is coherent to say “let \\(P\\) be the set of people who have been US presidents”, so that \\[P = \\{\\text{George Washington}, \\text{John Adams}, \\ldots, \\text{Donald Trump}\\}.\\]\n\n\n\n\n\n\nTable 2.1: Notable sets of numbers\n\n\n\n\n\n\n\n\n\n\nName\nNotation\nDefinition\n\n\n\n\nNatural numbers\n\\(\\mathbb{N}\\)\nThe counting numbers: 1, 2, 3, … and so on indefinitely. (Some textbooks treat 0 as a natural number, but usually not.)\n\n\nIntegers\n\\(\\mathbb{Z}\\)\nThe whole numbers: …, -2, -1, 0, 1, 2, …\n\n\nRational numbers\n\\(\\mathbb{Q}\\)\nNumbers that can be expressed as a quotient (hence the symbol \\(\\mathbb{Q}\\)) of integers, \\(\\frac{a}{b}\\), where \\(a \\in \\mathbb{Z}\\), \\(b \\in \\mathbb{Z}\\), and \\(b \\neq 0\\).\n\n\nReal numbers\n\\(\\mathbb{R}\\)\nEvery number on the number line, including irrational numbers like \\(\\sqrt{2}\\) and \\(\\pi\\).\n\n\nClosed interval\n\\([a, b]\\)\nEvery real number between \\(a\\) and \\(b\\), including \\(a\\) and \\(b\\) themselves.\n\n\nOpen interval\n\\((a, b)\\)\nEvery real number between \\(a\\) and \\(b\\), not including \\(a\\) and \\(b\\) themselves.\n\n\n\n\n\n\n\n\n\n\nI always use the vertical bar \\(\\mid\\) when writing in set-builder notation, but sometimes you will see people use the colon \\(:\\) instead. These are just different conventions with no differences in underlying meaning.\n\n\nExercise 2.1 Use set-builder notation to describe the following sets:\n\nEvery integer that is a multiple of 7.\nEvery natural number that is odd.\nEvery rational number between 0 and 1, including 0 and 1 themselves.\n\n\n\n\n\n\n\nAnswers\n\n\n\n\n\n\n\\(\\{7z \\mid z \\in \\mathbb{Z}\\}\\). (An integer that is a multiple of 7 is just some other integer multiplied by 7. For example, you can think of \\(-35\\) as \\(7 \\times -5\\).)\n\\(\\{2n - 1 \\mid n \\in \\mathbb{N}\\}\\).\n\\(\\{x \\in [0, 1] \\mid x \\in \\mathbb{Q}\\}\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Set Theory</span>"
    ]
  },
  {
    "objectID": "set_theory.html#fundamental-operations-on-sets",
    "href": "set_theory.html#fundamental-operations-on-sets",
    "title": "2  Set Theory",
    "section": "2.2 Fundamental operations on sets",
    "text": "2.2 Fundamental operations on sets\n\n2.2.1 Subsets and equality\nWhen we’re dealing with numbers, we compare them in terms of their values. 40 is greater than 38, which in turn is greater than 10. With sets, we make comparisons in terms of their elements — namely, whether all of the elements of one are contained in another.\n\nDefinition 2.2 (Subset) The set \\(A\\) is a subset of the set \\(B\\), denoted \\(A \\subseteq B\\), if every element of \\(A\\) is an element of \\(B\\).\n\n\n\n\n\n\n\nInclusion \\(\\in\\) versus subset \\(\\subseteq\\)\n\n\n\n\\(A \\subseteq B\\) and \\(A \\in B\\) have very different meanings. \\(A \\subseteq B\\) means “every element of \\(A\\) is also an element of \\(B\\)”. \\(A \\in B\\) means “the set \\(A\\) is, itself, an element of \\(B\\)”. When you’re talking about sets, you usually mean the first of these, not the second.\nIf you mess up and use the wrong notation, your readers will probably still ultimately figure out what you mean — but it’ll take a bit longer for them than if you’d used the right notation. So it’s in your best interest to use the right notation for much the same reason as it’s in your best interest to use proper spelling and grammar.\n\n\nYou probably won’t be surprised to learn that subsets are like nesting dolls: if \\(A\\) is a subset of \\(B\\), then it is also a subset of any other set that \\(B\\) is a subset of. I’m bringing up this seemingly obvious fact mainly because it’ll give us a nice first statement about set theory to prove. Not to mention that some seemingly obvious things turn out not to be true at all — which is one of the reasons it’s important to prove our mathematical claims.\n\nProposition 2.1 (Transitivity of subset) If \\(A \\subseteq B\\) and \\(B \\subseteq C\\), then \\(A \\subseteq C\\).\n\n\nProof. We need to show that every element of \\(A\\) is also an element of \\(C\\). To do that, we will take an “arbitrary” element of \\(A\\) — a mathematical object that we know nothing about, other than that it is an element of \\(A\\) — and show that it is an element of \\(C\\). To that end, let \\(a\\) be any element of \\(A\\). Because \\(a \\in A\\) and \\(A \\subseteq B\\), it follows that \\(a \\in B\\). Because \\(a \\in B\\) and \\(B \\subseteq C\\), it follows that \\(a \\in C\\). Because the element \\(a\\) was chosen arbitrarily, we have shown that every element of \\(A\\) is an element of \\(C\\), and therefore \\(A \\subseteq C\\).\n\n\n\n\n\n\n\nNote 2.1: Proving a “for all” claim\n\n\n\nThe proof of Proposition 2.1 gets into some formal logic that we didn’t explicitly cover in Chapter 1. The proof relies on the fact that the proposition can be stated this way:\n\nPremise 1: For all \\(a \\in A\\), \\(a \\in B\\). (i.e., \\(A \\subseteq B\\))\nPremise 2: For all \\(b \\in B\\), \\(b \\in C\\). (i.e., \\(B \\subseteq C\\))\nConclusion: For all \\(a \\in A\\), \\(a \\in C\\). (i.e., \\(A \\subseteq C\\))\n\nThe method I used in the proof of Proposition 2.1 is the standard way to prove a “for all” statement. Suppose we are trying to prove a statement of the variety “for all \\(x \\in X\\), \\(P(x)\\) is true,” where \\(P(x)\\) is some sentence about \\(x\\). A proof like that typically starts with “Take an arbitrary \\(x \\in X\\),” meaning we are assuming we know nothing about \\(x\\) besides that it is a member of \\(X\\). From there, we use what we know about \\(X\\) to show that \\(P(x)\\) is indeed true.\nYou need to be very careful with negations of “for all” statements. We can falsify the statement “for all \\(x \\in X\\), \\(P(x)\\) is true” by finding a single element of \\(X\\) for which \\(P(x)\\) is false. Hence, the negation of “for all \\(x \\in X\\), \\(P(x)\\) is true” is not “for all \\(x \\in X\\), \\(P(x)\\) is false.” Instead, the correct negation is “there exists an \\(x \\in X\\) for which \\(P(x)\\) is false.”\nFYI, in case it comes up in other things you read, the symbol \\(\\forall\\) means “for all” and the symbol \\(\\exists\\) means “there exists.” I might write these on the whiteboard sometimes to save space, but I almost never use them in academic writing.\n\n\nIntuitively, two sets are equal if they have the same elements. One of the annoying-but-ultimately-good things about math is that we have to be precise about statements like “they have the same elements”. Does \\(\\{1, 2, 3\\}\\) equal \\(\\{3, 2, 1\\}\\)? Does \\(\\{a, b, c\\}\\) equal \\(\\{a, a, b, b, c, c\\}\\)? The answer to both of these questions turns out to be “yes” — but why? It comes down to the formal definition of set equality, which we state as each set being a subset of the other.\n\nDefinition 2.3 (Set equality) The sets \\(A\\) and \\(B\\) are equal, denoted \\(A = B\\), if \\(A \\subseteq B\\) and \\(B \\subseteq A\\).\n\nWe can again make an analogy to how we compare numbers. If \\(a\\) and \\(b\\) are numbers, then we have \\(a = b\\) precisely when both \\(a \\leq b\\) and \\(b \\leq a\\).\nNow let’s return to the question of whether \\(\\{1, 2, 3\\} = \\{3, 2, 1\\}\\). First we show that \\(\\{1, 2, 3\\} \\subseteq \\{3, 2, 1\\}\\):\n\n\\(1 \\in \\{3, 2, 1\\}\\) ✅\n\\(2 \\in \\{3, 2, 1\\}\\) ✅\n\\(3 \\in \\{3, 2, 1\\}\\) ✅\n\nAnd then we show that \\(\\{3, 2, 1\\} \\subseteq \\{1, 2, 3\\}\\):\n\n\\(3 \\in \\{1, 2, 3\\}\\) ✅\n\\(2 \\in \\{1, 2, 3\\}\\) ✅\n\\(1 \\in \\{1, 2, 3\\}\\) ✅\n\nYou can generalize the logic here to show that a set is the same no matter what order we write the elements in. I’ll also leave it to you to show that repetition of an element is immaterial to the membership of a set, so that (for example) \\(\\{a, b, c\\} = \\{a, a, b, b, c, c\\}\\).\nJust like equality of numbers, equality of sets is transitive: if one set is equal to another, which in turn is equal to some third set, then the first is equal to the third as well.\n\nCorollary 2.1 (Transitivity of set equality) If \\(A = B\\) and \\(B = C\\), then \\(A = C\\).\n\nBy following the template provided by the proof of Proposition 2.1, you should be able to prove this result yourself. If you’re having trouble getting started, one good principle to keep in mind when writing a proof is to take stock of all the “knowns” that might be relevant and have already been defined or proved. For this question, relevant facts would include the definition of set equality (Definition 2.3) and the transitivity of the subset operation (Proposition 2.1).\n\nExercise 2.2 Prove Corollary 2.1.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe need to show that if \\(A = B\\) and \\(B = C\\), then \\(A \\subseteq C\\) and \\(C \\subseteq A\\). By the definition of set equality, if \\(A = B\\) and \\(B = C\\), then \\(A \\subseteq B\\) and \\(B \\subseteq C\\). Proposition 2.1 then implies that \\(A \\subseteq C\\).\nAgain by the definition of set equality, if \\(C = B\\) and \\(B = A\\), then \\(C \\subseteq B\\) and \\(B \\subseteq A\\). Proposition 2.1 then implies that \\(C \\subseteq A\\).\nWe have shown that if \\(A = B\\) and \\(B = C\\), then \\(A \\subseteq C\\) and \\(C \\subseteq A\\), so by definition \\(A = C\\).\n(In the second paragraph, I implicitly relied on the commutativity of set equality, i.e., that if \\(A = B\\), then \\(B = A\\). That’s another thing you can prove yourself at this point if you’re skeptical!)\n\n\n\n\n\n\n2.2.2 The Venn diagram operations\nWe want to be able to talk about combinations of sets. Once again, a bit of mathematical notation will help us quickly convey exactly what we mean. If I say “the set of presidents and vice presidents”, do I mean all of the people who have served in either role, or only those who have served in both? We know Richard Nixon and Joe Biden are in it either way, but what about Barack Obama? Mathematically speaking, we need to be sure if we are talking about the union or the intersection of the sets of presidents and vice presidents.\n\nDefinition 2.4 (Union and intersection) The union of the sets \\(A\\) and \\(B\\), denoted \\(A \\cup B\\), is the set of elements that are in \\(A\\), in \\(B\\), or both: \\[A \\cup B = \\{x \\mid x \\in A \\text{ or } x \\in B\\}.\\] The intersection of the sets \\(A\\) and \\(B\\), denoted \\(A \\cap B\\), is the set of elements that are in both \\(A\\) and \\(B\\): \\[A \\cap B = \\{x \\mid x \\in A \\text{ and } x \\in B\\}.\\]\n\n\n\n\nFigure 2.1: Union and intersection of sets.\n\n\n\n\n\n\n\nUnion: \\(A \\cup B\\)\n\n\n\n\n\n\n\n\n\nIntersection: \\(A \\cap B\\)\n\n\n\n\n\n\n\n\n\n\n\nHey, the union operator \\(\\cup\\) looks a lot like the logical “or” operator \\(\\lor\\), and the intersection operator \\(\\cap\\) looks a lot like the logical “and” operator \\(\\land\\). I wonder if that’s a coincidence?\nFor example, let \\(P\\) be the set of presidents, and \\(Q\\) be the set of vice presidents. Because Barack Obama was president but not vice president, he belongs to the union of these sets, but not the intersection: \\[\\begin{gather}\n\\text{Barack Obama} \\in P \\cup Q, \\\\\n\\text{Barack Obama} \\notin P \\cap Q.\n\\end{gather}\\] Naturally, more people have been president or vice president than have been both president and vice president. In mathematical terms, the intersection \\(P \\cap Q\\) is a subset of the union \\(P \\cup Q\\). This turns out to be a general property of sets, not just of American national officeholders.\n\nProposition 2.2 \\(A \\cap B \\subseteq A \\subseteq A \\cup B\\).\n\n\nProof. There are two claims to prove here. The first is that \\(A \\cap B \\subseteq A\\). To prove this, take any element \\(x \\in A \\cap B\\). By definition of the intersection, it must be the case that \\(x \\in A\\). Therefore, \\(A \\cap B \\subseteq A\\).\nThe second claim to prove is that \\(A \\subseteq A \\cup B\\). To prove this, take any element \\(x \\in A\\). By definition of the union, \\(x \\in A \\cup B\\). Therefore, \\(A \\subseteq A \\cup B\\).\n\nWhat if we wanted to talk about the set of people who have been president, but not vice president? We can formulate this using the set difference.\n\nDefinition 2.5 (Set difference) The set difference between sets \\(A\\) and \\(B\\), denoted \\(A \\setminus B\\), is the set of elements that are in \\(A\\) and not in \\(B\\): \\[A \\setminus B = \\{a \\in A \\mid a \\notin B\\}.\\]\n\n\n\n\nFigure 2.2: Set differences.\n\n\n\n\n\n\n\n\\(A \\setminus B\\)\n\n\n\n\n\n\n\n\n\n\\(B \\setminus A\\)\n\n\n\n\n\n\n\n\n\nJoe Biden was both a vice president and a president. Barack Obama was only president, never a vice president. Aaron Burr was only vice president, never president. Therefore, we have the following set memberships:\n\n\n\n\n\n\n\n\n\n\n\n\nOld guy\n\\(P\\)\n\\(Q\\)\n\\(P \\cap Q\\)\n\\(P \\cup Q\\)\n\\(P \\setminus Q\\)\n\\(Q \\setminus P\\)\n\n\n\n\nJoe Biden\nx\nx\nx\nx\n\n\n\n\nBarack Obama\nx\n\n\nx\nx\n\n\n\nAaron Burr\n\nx\n\nx\n\nx\n\n\n\n\nExercise 2.3 Using the union, intersection, and the set difference, find a way to denote the set of elements that are in exactly one of \\(A\\) and \\(B\\), but not both.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\((A \\cup B) \\setminus (A \\cap B)\\).\n\n\n\n\nNo one who has been the president of the United States has also been the prime minister of the United Kingdom. If we were to let \\(M\\) denote the set of people who have been prime minister, then the intersection \\(P \\cap M\\) would be a set that contains … nothing? Yes, indeed, a set may contain nothing. We have a special name for the set with nothing in it — the empty set.\n\nDefinition 2.6 (Empty set) The empty set is the set containing no elements, denoted \\(\\emptyset\\).\n\nUsing this notation, a concise way to say “no one has been both the US president and the UK prime minister” would be \\(P \\cap M = \\emptyset\\). We say two sets are disjoint when their intersection is empty.\n\nExercise 2.4 Prove the following properties of the empty set:\n\n\\(A \\cup \\emptyset = A\\).\n\\(A \\cap \\emptyset = \\emptyset\\).\n\n\n\n\n\n\n\nAnswers\n\n\n\n\n\n\nWe know from Proposition 2.2 that \\(A \\subseteq A \\cup \\emptyset\\), so we only need to prove that \\(A \\cup \\emptyset \\subseteq A\\). To this end, take any element \\(x \\in A \\cup \\emptyset\\). By definition of the union, it must be the case that \\(x \\in A\\) or that \\(x \\in \\emptyset\\). The second of these is impossible, so it must be the case that \\(x \\in A\\). As \\(x\\) was chosen arbitrarily, this proves that \\(A \\cup \\emptyset \\subseteq A\\). Finally, because \\(A \\subseteq A \\cup \\emptyset\\) and \\(A \\cup \\emptyset \\subseteq A\\), we have \\(A \\cup \\emptyset = A\\).\nWe know from Proposition 2.2 that \\(A \\cap \\emptyset \\subseteq \\emptyset\\). If there were an element \\(x \\in A \\cap \\emptyset\\), then it would follow from the definition of intersection that \\(x \\in \\emptyset\\). But that cannot be the case, as \\(\\emptyset\\) is the set with no elements. Therefore, there is no element \\(x\\) included in \\(A \\cap \\emptyset\\). By definition, then \\(A \\cap \\emptyset = \\emptyset\\).\n\n\n\n\n\n\n\n2.2.3 Complements and De Morgan’s laws\nThe set difference \\(A \\setminus B\\) is the set of everything in \\(A\\) that’s not in \\(B\\). But what if we simply wanted the set of everything that’s not in \\(B\\), whether it’s in \\(A\\) or not? Once we can properly define this type of set, we will call it the complement of \\(B\\).\nBefore we can do that, we need to be clear about what “everything” is. For example, again taking \\(P\\) to be the set of people who have been the US president, it seems clear enough that \\[\\text{Aaron Burr} \\in \\{x \\mid x \\notin P\\}.\\] But would we say that the number 3 is also an element of this set? What about the chemical formula H\\(_2\\)O or the human gene CNR1? If nothing else, it doesn’t seem to be very useful to say that these are not people who have been president, true as that may be.\nTo have a useful working definition of “everything not in this set”, we are going to assume there’s a set \\(U\\) that contains the universe of objects we might be interested in. The appropriate choice of universal set depends on the context for what we want to do. Most commonly, if we are talking about numbers that lie along the typical number line, our universal set might be the real line, \\(\\mathbb{R}\\). Or if we are talking about who has and has not held particular political positions, our universal set might be the set of all people who have ever lived.\nOnce we have settled on the universe of objects we care about, it’s simple to define the complement of a set.\n\nDefinition 2.7 (Complement) The complement of the set \\(A\\), denoted \\(A^c\\), is the set of all elements in the universe that are not in \\(A\\), i.e., \\(A^c = U \\setminus A\\).\n\n\n\n\nFigure 2.3: Set differences.\n\n\n\n\n\n\n\n\\(A^c\\)\n\n\n\n\n\n\n\n\n\n\\(B^c\\)\n\n\n\n\n\n\n\n\n\nYou don’t often see the universal set explicitly specified in mathematical writing, other than textbook set theory treatments like what you’re reading right now. I assume this is because most mathematical writers follow the same conventions I do:\n\nThe appropriate definition of a universal set should be clear from the context. For example, if all of the mathematical objects discussed are real numbers and sets of real numbers, then \\(U = \\mathbb{R}\\).\nIf the context is not clear enough for there to be a natural choice of universal set (e.g., you’re talking about sets of radically different types of objects), then use explicit set differences when needed rather than taking complements of sets.\n\nTaking our universe as the set of all people, let’s think about the complement of the union of sets of everyone who’s been a president or vice president, \\((P \\cup Q)^c\\). Anyone who’s been a president or a vice president is an element of \\(P \\cup Q\\). Therefore, if someone is not an element of \\(P \\cup Q\\), that tells us that the person has never been president and has never been vice president. In other words, that person belongs to both \\(P^c\\) and \\(Q^c\\), and thus also to their intersection \\(P^c \\cap Q^c\\). This is an illustration of a very useful pair of set properties called De Morgan’s laws.\n\nTheorem 2.1 (De Morgan’s laws)  \n\n\\((A \\cup B)^c = A^c \\cap B^c\\).\n\\((A \\cap B)^c = A^c \\cup B^c\\).\n\n\n\n\n\nFigure 2.4: De Morgan’s laws.\n\n\n\n\n\n\n\n\\((A \\cup B)^c = A^c \\cap B^c\\)\n\n\n\n\n\n\n\n\n\n\\((A \\cap B)^c = A^c \\cup B^c\\)\n\n\n\n\n\n\n\n\n\n\n\nHey, these look a lot like the De Morgan’s laws for formal logic (Theorem 1.3)! I wonder if that’s a coincidence?\n\nProof. I’ll prove the first law, and leave the second to you as Exercise 2.5. First we have to prove that \\((A \\cup B)^c \\subseteq A^c \\cap B^c\\). To this end, take any \\(x \\in (A \\cup B)^c\\), so that \\(x \\notin A \\cup B\\). By definition of the union, this implies \\(x \\notin A\\), hence \\(x \\in A^c\\). By the same token, \\(x \\notin B\\), hence \\(x \\in B^c\\). Because \\(x \\in A^c\\) and \\(x \\in B^c\\), we have \\(x \\in A^c \\cap B^c\\). As \\(x\\) was chosen arbitrarily, this shows that \\((A \\cup B)^c \\subseteq A^c \\cap B^c\\).\nNext, to complete the proof of equality, we have to prove that \\(A^c \\cap B^c \\subseteq (A \\cup B)^c\\). To this end, take any \\(x \\in A^c \\cap B^c\\). By definition of the intersection, \\(x \\in A^c\\), hence \\(x \\notin A\\). By the same token, \\(x \\in B^c\\), hence \\(x \\notin B\\). Because \\(x \\notin A\\) and \\(x \\notin B\\), we have \\(x \\notin A \\cup B\\) and thus \\(x \\in (A \\cup B)^c\\). As \\(x\\) was chosen arbitrarily, this shows that \\(A^c \\cap B^c \\subseteq (A \\cup B)^c\\).\n\n\nExercise 2.5 Prove that \\((A \\cap B)^c = A^c \\cup B^c\\).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe steps are the same as in the proof of the first part above, so I’ll be a bit briefer about them.\nTake any \\(x \\in (A \\cap B)^c\\). Because \\(x \\notin A \\cap B\\), it must be the case that \\(x \\in A^c\\) or \\(x \\in B^c\\). If \\(x \\in A^c\\), then \\(x \\in A^c \\cup B^c\\). Otherwise, if \\(x \\notin A^c\\), then \\(x \\in B^c\\) and thus \\(x \\in A^c \\cup B^c\\). Either way, we have \\(x \\in A^c \\cup B^c\\). Consequently, \\((A \\cap B)^c \\subseteq A^c \\cup B^c\\).\nNow take any \\(x \\in A^c \\cup B^c\\). It must be the case that \\(x \\in A^c\\) or \\(x \\in B^c\\). If \\(x \\in A^c\\), then \\(x \\notin A\\), hence \\(x \\notin A \\cap B\\), hence \\(x \\in (A \\cap B)^c\\). Otherwise, if \\(x \\notin A^c\\), then \\(x \\in B^c\\), hence \\(x \\notin B\\), hence \\(x \\notin A \\cap B\\), hence \\(x \\in (A \\cap B)^c\\). Either way, we have \\(x \\in (A \\cap B)^c\\). Consequently, \\(A^c \\cup B^c \\subseteq (A \\cap B)^c\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Set Theory</span>"
    ]
  },
  {
    "objectID": "set_theory.html#functions",
    "href": "set_theory.html#functions",
    "title": "2  Set Theory",
    "section": "2.3 Functions",
    "text": "2.3 Functions\nEvery US president took office at some recognizable point in time. George Washington’s first term began in 1789. Grover Cleveland’s first term began in 1893. Barack Obama’s first term began in 2009. I could go on, but you get the point. For every president, there is exactly one year when they became president for the first time.\nWhat we’ve done here is associate each president, an element of set \\(P\\) as we’ve been calling it, with a natural number, an element of \\(\\mathbb{N}\\). “The year that a given president took office” is what we call a function, which we might say “maps” one set into another. The notation \\(f : A \\to B\\) is a bit of mathematical shorthand that means “\\(f\\) is a rule that takes each element of \\(A\\) and associates it with an element of \\(B\\)”. For any element \\(a \\in A\\), we write \\(f(a)\\) to stand for the element of \\(B\\) that the function associates \\(a\\) with. When a function maps \\(A\\) into \\(B\\), we call \\(A\\) the domain and \\(B\\) the codomain.\nTo continue the example, let \\(y : P \\to \\mathbb{N}\\) (verbally: “\\(y\\) is a function that maps the set of presidents into the set of natural numbers”) be the function that associates each president with the year they first took office. Then we have \\(y(\\text{George Washington}) = 1789\\), \\(y(\\text{Grover Cleveland}) = 1893\\), and so on. The domain of this function is the set of presidents, \\(P\\), and the codomain is the set of natural numbers, \\(\\mathbb{N}\\).\nSome associations between sets are not functions. When we’re thinking about the set of presidents, \\(P\\), you might be tempted to think about a function that associates each president with their vice president. However, no such function exists, for two reasons.\n\nA function associates every element of its domain with an element of the codomain. However, some presidents had no vice president. For example, Andrew Johnson, who assumed the presidency after Abraham Lincoln’s assassination, never had a vice president.\nA function associates each element of the domain with exactly one element of the codomain. However, some presidents have had multiple vice presidents. For example, both Spiro Agnew and Gerald Ford served as vice president to Richard Nixon.\n\nIn mathematical terms, we would call the president-and-their-vice-president(s-if-any) assocation a relation. Any function is a relation, but many relations are not functions. There are lots of cool things to study about relations, but I cannot say in good faith that you must know these cool things, so that is all I will say about relations.\n\nExercise 2.6 Come up with a function that maps the set of presidents, \\(P\\), into the set of vice presidents, \\(Q\\). Convince yourself that it satisfies the key requirement of a function — that every element in \\(P\\) is associated with one, and exactly one, element in \\(Q\\).\n\n\n\n\n\n\nOne answer\n\n\n\n\n\nI propose the function \\(f : P \\to Q\\) defined so that \\(f(p) = \\text{Joe Biden}\\) for every president \\(p \\in P\\). This rule associates every president with a vice president, so it is a function.\nThis might seem like a dumb example, but it meets the criteria that I set out, making it a valid answer. Math is legalistic in this way: the question asked for a function \\(f : P \\to Q\\), I provided a function \\(f : P \\to Q\\), and therefore I got the answer right. So if you’re here in a political science PhD program because your law school dreams didn’t quite work out, take comfort in knowing that you can still get to be a legalistic jackass when you’re working in the world of math.\n\n\n\n\n\n2.3.1 One-to-one and onto functions\nAs you saw in Exercise 2.6, there is nothing in the definition of a function to suggest that every element of the domain must be associated with a different element of the codomain. Some functions do have this additional property, and we call those functions one-to-one.\n\nDefinition 2.8 (One-to-one) A function \\(f : A \\to B\\) is one-to-one, also called injective, if \\(f(a) \\neq f(a')\\) for all distinct elements \\(a \\in A\\) and \\(a' \\in A\\).\n\n\n\n\n\n\nFigure 2.5: A function that is one-to-one, but not onto.\n\n\n\n\n\n\n\n\nThe function \\(y : P \\to \\mathbb{N}\\) that we discussed earlier, mapping presidents into the year that they first took office, is not one-to-one. William Henry Harrison took office in March 1841, famously gave a lengthy speech in poor weather, caught cold, and died a month later. His vice president, John Tyler, took office in April 1841. In terms of the function we defined, \\[y(\\text{William Henry Harrison}) = y(\\text{John Tyler}) = 1841.\\] Because these are two different presidents with the same function value, \\(y\\) is not one-to-one.\nYou also saw in Exercise 2.6 that a function need not reach every element of its codomain. In fact, if the domain has fewer elements than the codomain — such as with the sets of presidents \\(P\\) and vice presidents \\(Q\\), where at the time of writing there have been 45 presidents and 50 vice presidents — it would be impossible for the function to reach every element of the codomain. In the special case where a function does reach every element of the codomain, we turn a preposition into an adjective and say the function is onto.\n\nDefinition 2.9 (Onto) A function \\(f : A \\to B\\) is onto, also called surjective, if for every element \\(b \\in B\\) there is some element \\(a \\in A\\) such that \\(f(a) = b\\).\n\n\n\n\n\n\nFigure 2.6: A function that is onto, but not one-to-one.\n\n\n\n\n\n\n\n\nWe have already seen that the function that maps presidents into the first year they took office is not one-to-one. It is not onto either. Consider 1999, the year The Matrix came out and inspired legions of nerds (like me…) to make green-on-black their default color theme for computing. 1999 is a natural number, or \\(1999 \\in \\mathbb{N}\\) if you want to be formal about it, and yet no president took office for the first time then; Bill Clinton, who had first taken office in 1993, was the president the entire year. We have found a number \\(n \\in \\mathbb{N}\\) such that \\(y(p) \\neq n\\) for all presidents \\(p \\in P\\), meaning \\(y\\) is not onto.\nFunctions that are both one-to-one and onto, which we call bijections, are special. What makes them special is that they can be reversed, or inverted in the language of mathematics. I like to think of a bijection as creating a “buddy system” between its domain and a codomain. Think about a bijection \\(f\\) that maps elements of (domain) \\(A\\) into (codomain) \\(B\\), so we’d write \\(f : A \\to B\\). Then for every element \\(a\\) of \\(A\\), there is exactly one element \\(b\\) of \\(B\\) such that \\(f(a) = b\\). And for every element \\(b\\) of \\(B\\), there is exactly one element \\(a\\) of \\(A\\) such that \\(f(a) = b\\). If the function weren’t one-to-one, then there’d be at least one \\(a \\in A\\) with multiple matches in \\(B\\). If it weren’t onto, then there’d be at least one \\(b \\in B\\) with no matches in \\(A\\).\n\nDefinition 2.10 (Bijection and inverse) A function \\(f : A \\to B\\) is a bijection if it is both one-to-one and onto.\nEvery bijective function has an inverse function, \\(f^{-1} : B \\to A\\). For every pair of elements \\(a \\in A\\) and \\(b \\in B\\), we have \\(f^{-1}(b) = a\\) if and only if \\(f(a) = b\\).\n\n\n\n\nFigure 2.7: A function that is both one-to-one and onto.\n\n\n\n\n\n\n\nA bijection…\n\n\n\n\n\n\n\n\n\n\n\n…and its inverse.\n\n\n\n\n\n\n\n\n\nFigure 2.7 illustrates the buddy system property of a bijection. Each element of \\(A\\) has exactly one buddy in \\(B\\), and each element of \\(B\\) has exactly one buddy in \\(A\\). For finite sets like the ones in the illustration, you can probably convince yourself that they’d have to have the same number of elements in order for this kind of buddy system to be viable. All I’ll say here for infinite sets is that it gets weirder; read the optional Section 2.3.2 below if you want to peek into the weirdness.\nWe’ll conclude our main discussion of functions with one more proof. If you look at Figure 2.7, you’ll see that the inverse of \\(f\\) is one-to-one and onto. This is not just an accidental feature of the illustration; it’s a general feature of the inverse function of a bijection. If you’re not convinced, here’s a proof. (And if you are convinced—shouldn’t you have asked for proof instead of just taking my word?)\n\nProposition 2.3 (The inverse of a bijection is a bijection) If \\(f\\) is a bijection, then its inverse \\(f^{-1}\\) is a bijection.\n\n\nProof. Assume \\(f : A \\to B\\) is a bijection. To prove the proposition, we need to show that \\(f^{-1} : B \\to A\\) is both one-to-one and onto.\nTo show that \\(f^{-1}\\) is one-to-one, we need to show that \\(f^{-1}(b) \\neq f^{-1}(b')\\) for any distinct elements \\(b \\in B\\) and \\(b' \\in B\\). To accomplish this, take any pair of distinct \\(b \\in B\\) and \\(b' \\in B\\). (By distinct, we mean that \\(b \\neq b'\\).) Because \\(f\\) is onto, there is an \\(a \\in A\\) such that \\(f(a) = b\\) and an \\(a' \\in A\\) such that \\(f(a') = b'\\). As \\(b\\) and \\(b'\\) are distinct, we must have \\(a \\neq a'\\); otherwise, we would have \\(f(a) = f(a')\\) and thus \\(b = b'\\). Meanwhile, by definition of the inverse function, \\(f^{-1}(b) = a\\) and \\(f^{-1}(b') = a'\\). Putting this together with the fact that \\(a \\neq a'\\), we have \\(f^{-1}(b) \\neq f^{-1}(b')\\). As \\(b\\) and \\(b'\\) were chosen arbitrarily, this proves that \\(f^{-1}(b) \\neq f^{-1}(b')\\) for any distinct \\(b \\in B\\) and \\(b' \\in B\\), which means \\(f^{-1}\\) is one-to-one.\nTo show that \\(f^{-1}\\) is onto, we need to show that for every element \\(a \\in A\\), there is an element \\(b \\in B\\) such that \\(f^{-1}(b) = a\\). To accomplish this, take any element \\(a \\in A\\). There is an element \\(b \\in B\\) such that \\(f(a) = b\\). By definition of the inverse function, \\(f^{-1}(b) = a\\). As \\(a\\) was chosen arbitrarily, this proves that for every \\(a \\in A\\) there is some \\(b \\in B\\) such that \\(f^{-1}(b) = a\\), which means \\(f^{-1}\\) is onto.\n\n\n\n2.3.2 An optional digression into cardinality and infinities\nThis section contains material that is not strictly necessary, but which I find edifying and hope you will too.\nThe cardinality of a set, loosely speaking, is the number of elements in the set. We write \\(|A|\\) to denote the cardinality of a set \\(A\\). For a finite set, this loose definition is exact — the cardinality of a finite set is simply its size. For example, if \\(A = \\{1.1, 2.2, 4.4\\}\\), then \\(|A| = 3\\).\nIt gets more complicated once we start dealing with infinite sets. You might think that \\(|A| = \\infty\\) for infinite sets. But you would be wrong, because it turns out some infinities are bigger than others. The goal of this section is to show you why.\nFirst we need to define what it means for two sets to have the same cardinality. With finite sets, this is simple — they have the same number of elements. To extend this to infinite sets, we will rely on bijections. We will say that two sets have the same cardinality if we can set up a buddy system between the two of them.\n\nDefinition 2.11 (Equal cardinality) The sets \\(A\\) and \\(B\\) have the same cardinality, denoted \\(|A| = |B|\\), if there is a bijective function that maps \\(A\\) into \\(B\\).\n\nIt is obvious enough that this definition “works” for finite sets. Consider the sets \\(A = \\{\\text{Coke}, \\text{Pepsi}, \\text{Mountain Dew}\\}\\) and \\(B = \\{10, 17, 27\\}\\). We know just from looking at these sets that \\(|A| = |B| = 3\\). To prove that the formal definition is satisfied, it’s easy enough to produce a bijection between them, such as the function \\(f : A \\to B\\) defined by \\[\n\\begin{aligned}\nf(\\text{Coke}) &= 10, \\\\\nf(\\text{Pepsi}) &= 17, \\\\\nf(\\text{Mountain Dew}) &= 27.\n\\end{aligned}\n\\]\nIn a way, it is easier to prove that two sets have equal cardinality than to prove that they don’t. To prove that \\(|A| = |B|\\), we just need to find one bijection between them. But to prove that \\(|A| \\neq |B|\\), we need to show that every function between them is not a bijection.\n\nExercise 2.7 Consider the sets \\[\n\\begin{aligned}\nA &= \\{\\text{Coke}, \\text{Pepsi}, \\text{Mountain Dew}\\}, \\\\\nB &= \\{10, 17\\}, \\\\\nC &= \\{10, 17, 27, 42\\}.\n\\end{aligned}\n\\] Using the formal definition of equal cardinality, prove that \\(|A| \\neq |B|\\) and \\(|A| \\neq |C|\\).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo prove the first claim, we must show that there is no bijection mapping \\(A\\) into \\(B\\) — or vice versa (remember from Proposition 2.3 that if there is a bijection from \\(A\\) into \\(B\\), then there is also a bijection from \\(B\\) into \\(A\\)). We can easily show that there is no onto function mapping \\(B\\) into \\(A\\). Consider any function \\(f : B \\to A\\) such that \\(f(b) = \\text{Coke}\\) for some \\(b \\in B\\) and \\(f(b') = \\text{Pepsi}\\) for some \\(b' \\in B\\). Then we must have either \\(b = 10\\) and \\(b' = 17\\), or else \\(b = 17\\) and \\(b' = 10\\). Either way, there is no \\(b'' \\in B\\) such that \\(f(b'') = \\text{Mountain Dew}\\). Therefore, there is no onto function, and thus no bijection, mapping \\(B\\) into \\(A\\). We conclude that \\(|A| \\neq |B|\\).\nThe proof that \\(|A| \\neq |C|\\) follows almost the same steps. You just need to show that there is no onto function mapping \\(A\\) into \\(C\\).\n\n\n\n\nOur definition of equal cardinality operates totally intuitively with finite sets. It is not so intuitive with infinite sets. Let \\(\\mathbb{N}_E\\) stand for the set of even natural numbers, so that \\[\\mathbb{N}_E = \\{2n \\mid n \\in \\mathbb{N}\\} = \\{2, 4, 6, \\ldots\\}.\\] It sure looks like \\(\\mathbb{N}_E\\) is “smaller” than \\(\\mathbb{N}\\). After all, every even natural number is a natural number, yet not every natural number is an even natural number (for example, 1). In mathematical notation, \\(\\mathbb{N}_E \\subseteq \\mathbb{N}\\) and \\(\\mathbb{N} \\nsubseteq \\mathbb{N}_E\\). Nonetheless, these two sets turn out to have the same cardinality.\n\nExample 2.1 (Naturals and even naturals have same cardinality) Consider the function \\(f : \\mathbb{N} \\to \\mathbb{N}_E\\) defined by \\(f(n) = 2n\\). To see that \\(f\\) is one-to-one, observe that if \\(n \\neq n'\\), then \\(f(n) = 2n \\neq 2n' = f(n')\\). To see that \\(f\\) is onto, take any even natural number \\(e \\in \\mathbb{N}_E\\). By definition of an even natural number, there exists a natural number \\(n\\) such that \\(2n = e\\). Therefore, \\(f(n) = e\\). As \\(e\\) was chosen arbitrarily, this means that for every \\(e \\in \\mathbb{N}_E\\) there is an \\(n \\in \\mathbb{N}\\) such that \\(f(n) = e\\), and thus \\(f\\) is onto. We have shown that \\(f\\) is a bijection, so \\(|\\mathbb{N}| = |\\mathbb{N}_E|\\).\n\n\n\n\n\n\nThis result is one hint at the weirdness of infinite sets. A more vivid way to describe the weirdness is the metaphor of Hilbert’s Hotel. Imagine a hotel with infinitely many rooms, one for each natural number. A traveler arrives at the hotel, only to find out every room is full. She starts to walk out the door, when the manager tells her, “Don’t worry, we can make room.” He tells the occupant of room 1 to move to room 2, whose occupant goes to room 3, whose occupant goes to room 4, and so on, with the guest of each room \\(n\\) being moved to room \\(n + 1\\). The new arrival can now move into room 1, even though the hotel was full when she arrived and no one has checked out.\nIf you buy that Hilbert’s Hotel can accommodate one additional guest even when it’s full, then you will probably agree that it could take any finite number of new guests. If \\(m\\) guests arrive, have the guest in each room \\(n\\) move to room \\(n + m\\). What is more surprising is that Hilbert’s Hotel can also accommodate an infinite number of new guests. The logic is an application of Example 2.1. For each current guest in room \\(n\\), have them move to room \\(2n - 1\\). Now all of the even rooms are empty, and we can put the first new guest in our infinite sequence of new arrivals into room 2, the second into room 4, and so on. This seems crazy. It is crazy. Infinite quantities behave in strange ways, and we will go astray if we try to apply the rules of ordinary numbers to infinities.\n\n\nWe can make it even crazier if we want. Suppose an infinite number of trains arrive, each of which contains an infinite number of guests. Because the set of all pairs of natural numbers has the same cardinality as the set of natural numbers, it turns out that the ostensibly full hotel can accommodate this infinity-upon-infinity of new guests too.\nWe’ve seen that there are as many natural numbers as there are even natural numbers. This result might lead you to think that all infinite sets have the same cardinality. In fact, that’s not the case. Some infinities are bigger than others. For example, the cardinality of the real numbers is greater than the cardinality of the natural numbers.\n\n\nIs there any set whose cardinality is in between these two? Mathematicians literally, and famously, cannot decide.\nTo see why there are more real numbers than natural numbers, we will sketch out the diagonal argument from the 19th century mathematician Georg Cantor. (It’s a sketch because there are some nagging details that we will ignore. For example, we are ignoring the possibility of two different decimal expansions corresponding to the same number, as is the case with 0.1 and 0.099999\\(\\cdots\\).) Remember that two sets have equal cardinality if there is a bijection that maps one into the other. So to prove that the cardinalities of the natural numbers \\(\\mathbb{N}\\) and the real numbers \\(\\mathbb{R}\\) are different, we will show that no function \\(f : \\mathbb{N} \\to (0, 1)\\) can be onto, and thus no bijection meeting the definition of equal cardinality may exist.\nTake any function \\(f : \\mathbb{N} \\to (0, 1)\\). This function associates each natural number \\(n = 1, 2, \\ldots\\) with a real number between 0 and 1 (not inclusive). We want to show that there is a real number \\(x \\in [0, 1]\\) outside the range of \\(f\\), i.e., \\(f(n) \\neq x\\) for all \\(n \\in \\mathbb{N}\\). To see how we’re going to do this, let’s imagine lining up each \\(f(n)\\) and taking their decimal expansion.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(n\\)\n\\(f(n)\\)\ndigit 1\ndigit 2\ndigit 3\ndigit 4\ndigit 5\n…\n\n\n\n\n1\n0.04052…\n0\n4\n0\n5\n2\n…\n\n\n2\n0.65077…\n6\n5\n0\n7\n7\n…\n\n\n3\n0.97986…\n9\n7\n9\n8\n6\n…\n\n\n4\n0.57433…\n5\n7\n4\n3\n3\n…\n\n\n5\n0.09802…\n0\n9\n8\n0\n2\n…\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\n\n\n\n\nWe want to find an \\(x\\) that is not equal to any \\(f(n)\\). We can construct this by ensuring that the \\(n\\)’th decimal of \\(x\\) differs from the \\(n\\)’th decimal of each \\(f(n)\\).\n\n\n\n\\(n\\)\n\\(f(n)\\)\n\\(n\\)’th digit of \\(f(n)\\)\n\\(n\\)’th digit of \\(x\\)\n\n\n\n\n1\n0.04052…\n0\n1\n\n\n2\n0.65077…\n5\n6\n\n\n3\n0.97986…\n9\n0\n\n\n4\n0.57433…\n3\n4\n\n\n5\n0.09802…\n2\n3\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\nBy constructing \\(x\\) this way, we ensure that there is no \\(n\\) where \\(f(n)\\) equals \\(x\\), because we know that it differs in at least one decimal place from every single \\(f(n)\\). This means there is no onto function that maps from the natural numbers into \\((0, 1)\\), and therefore no onto function that maps from the natural numbers into the real numbers, and therefore these sets have different cardinalities. In other words, there is more than one infinity!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Set Theory</span>"
    ]
  },
  {
    "objectID": "set_theory.html#concept-review",
    "href": "set_theory.html#concept-review",
    "title": "2  Set Theory",
    "section": "2.4 Concept review",
    "text": "2.4 Concept review\n\nConceptual orderAlphabetical order\n\n\n\nSet theory\n\nThe study of sets and their properties. A key logical foundation for much of the rest of mathematics.\n\nSet\n\nInformally, a collection of objects (not necessarily numbers). A set \\(S\\) with elements \\(a\\), \\(b\\), and \\(c\\) is written \\(S = \\{a, b, c\\}\\).\n\nElement\n\nA member of a set. We write \\(a \\in A\\) to mean “\\(a\\) is an element of the set \\(A\\).”\n\nSet-builder notation\n\nA way to describe a set without explicitly enumerating all of its elements. For example, \\(\\{a \\in A \\mid a &gt; 3\\}\\) means “The set of all elements of \\(A\\) that are greater than 3.\n\nSubset\n\nWhen all of the elements of the set \\(A\\) are also elements of the set \\(B\\), we say that \\(A\\) is a subset of \\(B\\), written \\(A \\subseteq B\\).\n\nUnion\n\nThe union of the sets \\(A\\) and \\(B\\), denoted \\(A \\cup B\\), is the set of all elements that are in at least one of \\(A\\) or \\(B\\).\n\nIntersection\n\nThe intersection of the sets \\(A\\) and \\(B\\), denoted \\(A \\cap B\\), is the set of all elements that are in both \\(A\\) and \\(B\\).\n\nSet difference\n\nThe set difference between \\(A\\) and \\(B\\), denoted \\(A \\setminus B\\), is the set of all elements that are in \\(A\\) and are not in \\(B\\).\n\nEmpty set\n\nThe set containing no elements, denoted \\(\\emptyset\\).\n\nDisjoint sets\n\nTwo sets are disjoint if they have no elements in common, or equivalently if their intersection is the empty set.\n\nUniverse\n\nThe set of everything that could conceivably be in the sets we’re talking about. The relevant universe is highly dependent on the specific context, and ought to be inferable from context clues if not explicitly stated.\n\nComplement\n\nThe complement of a set \\(A\\), denoted \\(A^c\\), is the set of all elements in the relevant universe that are not elements of \\(A\\).\n\nDe Morgan’s laws\n\nRules for taking the complement of a union or an intersection of sets. The complement of a union is the intersection of the individual complements, and the complement of an intersection is the union of the individual complements.\n\nFunction\n\nA rule that associates each element in one set (the domain) with a single element in another set (the codomain). We write \\(f : A \\to B\\) to denote a function \\(f\\) with domain \\(A\\) and codomain \\(B\\).\n\nDomain\n\nThe set that a function “acts on”. If \\(f\\) is a function whose domain is \\(A\\), then \\(f(a)\\) is defined for every element \\(a \\in A\\).\n\nCodomain\n\nThe set that a function “maps into”. If \\(f\\) is a function whose domain is \\(A\\) and whose codomain is \\(B\\), then \\(f(a)\\) is an element of \\(B\\) for every element \\(a \\in A\\).\n\nOne-to-one\n\nA function is one-to-one if it associates each element of the domain with a distinct element of the codomain: if \\(a \\neq a'\\), then \\(f(a) \\neq f(a')\\).\n\nInjective\n\nAnother name for one-to-one.\n\nOnto\n\nA function is onto if it maps at least one element of the domain to every element of the codomain: for all \\(b\\) in the codomain, there is a domain element \\(a\\) such that \\(f(a) = b\\).\n\nSurjective\n\nAnother name for onto.\n\nBijection\n\nA function that is both one-to-one (injective) and onto (surjective).\n\nInverse function\n\nThe reverse of a function, denoted \\(f^{-1}\\), where \\(f^{-1}(b) = a\\) if and only if \\(f(a) = b\\). Only exists for functions that are bijective (one-to-one and onto).\n\nCardinality\n\nThe cardinality of a set \\(A\\), denoted \\(|A|\\), is the number of elements in the set if it is finite. It gets more complicated if the set is infinite.\n\n\n\n\n\nBijection\n\nA function that is both one-to-one (injective) and onto (surjective).\n\nCardinality\n\nThe cardinality of a set \\(A\\), denoted \\(|A|\\), is the number of elements in the set if it is finite. It gets more complicated if the set is infinite.\n\nCodomain\n\nThe set that a function “maps into”. If \\(f\\) is a function whose domain is \\(A\\) and whose codomain is \\(B\\), then \\(f(a)\\) is an element of \\(B\\) for every element \\(a \\in A\\).\n\nComplement\n\nThe complement of a set \\(A\\), denoted \\(A^c\\), is the set of all elements in the relevant universe that are not elements of \\(A\\).\n\nDe Morgan’s laws\n\nRules for taking the complement of a union or an intersection of sets. The complement of a union is the intersection of the individual complements, and the complement of an intersection is the union of the individual complements.\n\nDisjoint sets\n\nTwo sets are disjoint if they have no elements in common, or equivalently if their intersection is the empty set.\n\nDomain\n\nThe set that a function “acts on”. If \\(f\\) is a function whose domain is \\(A\\), then \\(f(a)\\) is defined for every element \\(a \\in A\\).\n\nElement\n\nA member of a set. We write \\(a \\in A\\) to mean “\\(a\\) is an element of the set \\(A\\).”\n\nEmpty set\n\nThe set containing no elements, denoted \\(\\emptyset\\).\n\nFunction\n\nA rule that associates each element in one set (the domain) with a single element in another set (the codomain). We write \\(f : A \\to B\\) to denote a function \\(f\\) with domain \\(A\\) and codomain \\(B\\).\n\nInjective\n\nAnother name for one-to-one.\n\nIntersection\n\nThe intersection of the sets \\(A\\) and \\(B\\), denoted \\(A \\cap B\\), is the set of all elements that are in both \\(A\\) and \\(B\\).\n\nInverse function\n\nThe reverse of a function, denoted \\(f^{-1}\\), where \\(f^{-1}(b) = a\\) if and only if \\(f(a) = b\\). Only exists for functions that are bijective (one-to-one and onto).\n\nOne-to-one\n\nA function is one-to-one if it associates each element of the domain with a distinct element of the codomain: if \\(a \\neq a'\\), then \\(f(a) \\neq f(a')\\).\n\nOnto\n\nA function is onto if it maps at least one element of the domain to every element of the codomain: for all \\(b\\) in the codomain, there is a domain element \\(a\\) such that \\(f(a) = b\\).\n\nSet\n\nInformally, a collection of objects (not necessarily numbers). A set \\(S\\) with elements \\(a\\), \\(b\\), and \\(c\\) is written \\(S = \\{a, b, c\\}\\).\n\nSet difference\n\nThe set difference between \\(A\\) and \\(B\\), denoted \\(A \\setminus B\\), is the set of all elements that are in \\(A\\) and are not in \\(B\\).\n\nSet theory\n\nThe study of sets and their properties. A key logical foundation for much of the rest of mathematics.\n\nSet-builder notation\n\nA way to describe a set without explicitly enumerating all of its elements. For example, \\(\\{a \\in A \\mid a &gt; 3\\}\\) means “The set of all elements of \\(A\\) that are greater than 3.\n\nSubset\n\nWhen all of the elements of the set \\(A\\) are also elements of the set \\(B\\), we say that \\(A\\) is a subset of \\(B\\), written \\(A \\subseteq B\\).\n\nSurjective\n\nAnother name for onto.\n\nUnion\n\nThe union of the sets \\(A\\) and \\(B\\), denoted \\(A \\cup B\\), is the set of all elements that are in at least one of \\(A\\) or \\(B\\).\n\nUniverse\n\nThe set of everything that could conceivably be in the sets we’re talking about. The relevant universe is highly dependent on the specific context, and ought to be inferable from context clues if not explicitly stated.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Set Theory</span>"
    ]
  },
  {
    "objectID": "sequences_series.html",
    "href": "sequences_series.html",
    "title": "3  Sequences and Series",
    "section": "",
    "text": "3.1 Motivating example: Incumbent advantage\nI’m going to propose an extremely (overly!) simple model of incumbent party advantage in legislative elections, ask a very simple question of the model, and show that it leads us into having to do an addition of infinitely many terms.\nHere’s the model. There is a legislative seat that is contested every election cycle. In each election, the incumbent party wins with probability \\(p\\) and loses with probability \\(1 - p\\), where \\(0 &lt; p &lt; 1\\). These elections are independent in the statistical sense, in that the probability of winning is \\(p\\) in each cycle, regardless of what has happened before. The question is: given \\(p\\), how many more terms would we expect the incumbent party to hold the seat, on average?\nOur goal here is to calculate the expected value, \\[\\begin{align}\n\\MoveEqLeft{}\n\\sum_{T = 0}^\\infty T \\cdot \\Pr(\\text{term length} = T) \\\\\n&= 0 \\cdot \\Pr(\\text{term length} = 0)\n+ 1 \\cdot \\Pr(\\text{term length} = 1) \\\\\n&\\quad + 2 \\cdot \\Pr(\\text{term length} = 2)\n+ 3 \\cdot \\Pr(\\text{term length} = 3) + \\cdots\n\\end{align}\\]\nGiven any term length \\(T\\), there’s a nonzero, though probably quite small, probability that the incumbent party will stay in office at least \\(T\\) terms. This means we’ll need to add together infinitely many numbers to calculate the expected term length. How can we even do that? Won’t we just end up with infinity at the end?\nLet’s get more specific about what we need to calculate here.\nYou might be starting to notice that there’s a certain structure here. The probability that the incumbent party lasts \\(T\\) more terms in office is \\[\\underbrace{p \\times p \\times \\cdots \\times p}_{\\text{$T$ times}} \\times (1 - p) = p^T (1 - p).\\] This means the expected value we are trying to calculate is \\[\n\\sum_{T = 0}^\\infty T \\cdot \\Pr(\\text{term length} = T)\n= \\sum_{T = 0}^\\infty T p^T (1 - p).\n\\]\nLet’s head to the computer to look at the components of this sum. Sadly we can’t look at all of the infinitely many components, so let’s just go up to \\(T = 40\\). We will look at the case where \\(p = 0.75\\). First, for each length up to 40 terms, let’s look at the probability that the terms lasts that long.\nFigure 3.1\nAccording to this model, if \\(p = 0.75\\), then the probability that the incumbent party stays in power for 20 or more consecutive terms is negligible. But this is only part of the expected value calculation. To calculate the expected value, we multiply the probability of each possible term length by the term length itself. So let’s multiply the probabilities from the last figure by the corresponding term length to see the individual components in the expected value calculation.\nFigure 3.2\nTerm lengths of 3 or 4 end up with the highest weights in the expected value calculation, once we weight the probability of each term length by the number of terms it represents. Perhaps more importantly for our purposes, even after we multiply the probabilities by term length, we see that the values get very close to 0 around \\(T = 30\\) or so. If this weren’t the case — i.e., if there were some nonzero floor on the expected value components — then the sum we’re trying to calculate, \\(\\sum_{T=0}^\\infty T p^T (1 - p)\\), would necessarily be infinite.\nFinally, let’s see what we get when we add up the expected value components up to each \\(T\\). These finite calculations can’t tell us what the infinite sum would equal, but we’ll see that they give us a pretty good idea.\nFigure 3.3\nIt sure looks like our infinite sum tops out at 3. At this point, if I had to guess, I’d guess that the expected term length is 3 when \\(p = 0.75\\). How can we say that with certainty instead of just guessing based on the eyeball test? Is there a formula that will let us calculate the expected term length for any value of the term-by-term retention probability \\(p\\)? By the end of this chapter, we’ll have a mathematical foundation to answer these questions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sequences and Series</span>"
    ]
  },
  {
    "objectID": "sequences_series.html#sec-sequences-motivation",
    "href": "sequences_series.html#sec-sequences-motivation",
    "title": "3  Sequences and Series",
    "section": "",
    "text": "Summation notation\n\n\n\nDon’t remember what \\(\\sum\\) means? Don’t panic! It’s the summation symbol, which we use when we’re adding many things together. For example, think about summing up the square of every number from 1 to 39. We could write that as \\[1^2 + 2^2 + \\cdots + 38^2 + 39^2.\\] A shorter way to write that, with the added advantage of leaving absolutely no ambiguity about precisely what we’re summing up, would be with the summation symbol: \\[\\sum_{n=1}^{39} n^2.\\] More generally, the notation \\(\\sum_{n=k}^K x_n\\) stands for the sum \\(x_k + x_{k+1} + \\cdots + x_{K - 1} + x_K\\). The notation \\(\\sum_{n=k}^\\infty x_n\\) stands for a sum of infinitely many terms, \\(x_k + x_{k+1} + x_{k+2} + \\cdots\\) and so on indefinitely.\n\n\n\n\n\nThe probability that the incumbent party has 0 more terms is the probability of losing the election immediately, namely \\(1 - p\\).\nThe probability of exactly one more term is the probability of winning the election this term and then losing the next one, namely \\(p \\times (1 - p)\\).\nThe probability of exactly two more terms is the probability of winning this election and the next one, then losing the one after that, namely \\(p \\times p \\times (1 - p)\\).\nThe probability of exactly three more terms is the probability of winning the next three elections but losing the one after that, namely \\(p \\times p \\times p \\times (1 - p)\\).\n\n\n\n\nYou may be wondering why this formula applies to the \\(T = 0\\) case too. It applies because \\(p^0 = 1\\) for any nonzero number \\(p\\). Therefore, when \\(T = 0\\), we have \\(p^T (1 - p) = 1 - p\\), the probability that the incumbent party loses office immediately.\n\n\n\nIf you want to see the R code that generates these figures, go to the Quarto source code for these lecture notes on GitHub.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sequences and Series</span>"
    ]
  },
  {
    "objectID": "sequences_series.html#sec-logarithms",
    "href": "sequences_series.html#sec-logarithms",
    "title": "3  Sequences and Series",
    "section": "3.2 Logarithms",
    "text": "3.2 Logarithms\n\n3.2.1 Definition of a logarithm\nBefore getting into trickier questions about infinite sums, let’s try to answer a simpler question about the underlying probabilities. We’ve already seen that the probability of lasting exactly \\(T\\) consecutive terms is \\(p^T (1 - p)\\). What if we wanted to reverse that? For example, what if we wanted to find the lowest term length with a 1% or less chance of occurring?\nWe could solve this problem by “brute force”: run the calculation for each successive term length \\(T\\) until we get to the number we’re looking for. Here’s some R code that uses a repeat loop — repeating the same steps over and over, until we explicitly tell the loop to break — to implement the brute force method.\n\np &lt;- 0.75  # retention probability each term\nq &lt;- 0.01  # probability of term length we're looking for\n\nT &lt;- 1     # starting value for term length\nrepeat {\n  # Calculate probability of lasting T terms\n  prob &lt;- p^T * (1 - p)\n\n  # If less than or equal to desired probability, stop repeating\n  if (prob &lt;= q)\n    break\n\n  # Otherwise, add a term and repeat\n  T &lt;- T + 1\n}\n\n# Show the result\nprint(T)\n\n[1] 12\n\n\nThe brute force method works, but it’s inelegant and scales poorly. It would be nice if there were a formula to answer our question. Luckily, there is one! We just have to use a logarithm, which is essentially the reverse of an exponent.\n\nDefinition 3.1 (Logarithm) For any positive number \\(a\\) and any positive number \\(b \\neq 1\\), we say that \\(x = \\log_b a\\) (pronounced “\\(x\\) is the logarithm, base \\(b\\), of \\(a\\)”) if and only if \\(b^x = a\\).\n\nHere are a few examples of logarithms in action.\n\nBecause \\(2^3 = 2 \\times 2 \\times 2 = 8\\), we have \\(\\log_2 8 = 3\\). In words, 3 is the base-2 logarithm of 8.\nBecause \\(10^{-2} = \\frac{1}{10^2} = \\frac{1}{100} = 0.01\\), we have \\(\\log_{10} 0.01 = -2\\). In words, -2 is the base-10 logarithm of 0.01.\nBecause \\(64^{1/2} = \\sqrt{64} = 8\\), we have \\(\\log_{64} 8 = 1/2\\). In words, 1/2 is the base-64 logarithm of 8.\n\nUsing a logarithm, we can now more elegantly solve our “first consecutive term length whose probability is \\(q\\) or less” problem. We are looking for the term length \\(T\\) for which \\[p^T (1 - p) \\leq q.\\] Equivalently, after dividing each side of the above equation by \\(1 - p\\), we are looking for the term length \\(T\\) for which \\[p^T = \\frac{q}{1 - p}.\\] We can now solve for \\(T\\) by taking the logarithm: \\[T = \\log_p \\left(\\frac{q}{1 - p}\\right).\\]\nLet’s use this formula to redo the example we solved by brute force earlier. Based on what we saw from the brute force solution, we should expect the formula to spit out a number between 11 and 12.\n\nlog(q / (1 - p), base = p)\n\n[1] 11.189\n\n\n\n\n3.2.2 Properties of exponents and logarithms\nLogarithms comes up surprisingly often in mathematical writing and in statistical programming, even in contexts where we’re not solving equations of the form \\(a^x = b\\). They’re useful because of their helpful properties, some of which we’ll now review.\nLogarithm of a product. You might remember that \\(b^{y + z} = b^y \\times b^z\\). As an example to make this more concrete, think about \\(2^5\\): \\[\n2^5 = 2^{2 + 3} = \\underbrace{2 \\times 2}_{2^2} \\times \\underbrace{2 \\times 2 \\times 2}_{2^3} = 2^2 \\times 2^3.\n\\]\nThis fact about exponents is the basis for an extremely helpful property of logarithms: the logarithm of a product is the sum of the logarithms.\n\nProposition 3.1 (Logarithm of a product) For any positive numbers \\(y\\) and \\(z\\) and any positive number \\(b \\neq 1\\), \\[\\log_b (y \\times z) = \\log_b y + \\log_b z.\\]\n\n\nProof. By the definition of the logarithm and the property of products of exponents, \\[\nb^{\\log_b y + \\log_b z} = b^{\\log_b y} \\times b^{\\log_b z} = y \\times z.\n\\] Therefore, again by the definition of the logarithm, \\(\\log_b (y \\times z) = \\log_b y + \\log_b z\\).\n\nThis property of logarithms is highly useful in both statistical computing and in calculus. In the statistical context, suppose you need to calculate the probability of some very large number of independent events, resulting in a calculation that looks like \\[p_1 \\times p_2 \\times \\cdots \\times p_N,\\] where \\(N\\) is some huge number. (For one thing, calculations like this are central to maximum likelihood estimation.) It turns out that computers are not so good at multiplying a lot of very small numbers together. At a certain point, as in the following example, the computer can’t distinguish the product from 0.\n\n# Randomly sample a bunch of numbers each close to 1/100\nsize &lt;- 500\ntiny_numbers &lt;- runif(size, min = 0.009, max = 0.011)\n\n# double check there are no zeroes here\nsummary(tiny_numbers)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.009001 0.009465 0.009909 0.009940 0.010380 0.010998 \n\n# prod() to multiply all numbers in a vector together\nprod(tiny_numbers)\n\n[1] 0\n\n# not just rounding: R thinks the product is zero!\nprod(tiny_numbers) == 0\n\n[1] TRUE\n\n\nBecause addition is easier for computers than multiplication, we can get a more accurate answer by converting our multiplication problem into an addition problem. Using Proposition 3.1, we know that for any positive base \\(b \\neq 1\\), \\[\\log_b (p_1 \\times p_2 \\times \\cdots \\times p_N) = \\log_b p_1 + \\log_b p_2 + \\cdots + \\log_b p_N.\\] Let’s use a base of \\(b = 10\\), since then we can interpret our result in terms of decimal places.\n\n# Convert each number to its base-10 log\nlogged_numbers &lt;- log(tiny_numbers, base = 10)\n\n# sum() to add all numbers in a vector together\nsum(logged_numbers)\n\n[1] -1001.661\n\n\nNow we have a much more accurate calculation: the product of the 500 small numbers we randomly drew is \\(10^{-1001.661}\\).\nLogarithm of a power. Again thinking about exponents, you might remember that \\((b^y)^z = b^{y \\times z}\\). For example, think about \\(5^6\\): \\[5^6 = 5^{3 \\times 2} = \\underbrace{5 \\times 5 \\times 5}_{5^3} \\times \\underbrace{5 \\times 5 \\times 5}_{5^3} = (5^3)^2.\\] This property of exponents delivers us another helpful property of logarithms: the log of \\(y\\) to the \\(z\\)’th power is \\(z\\) times the log of \\(y\\). Or, as I think of it, logarithms turn powers into coefficients.\n\nProposition 3.2 (Logarithm of a power) For any positive number \\(y\\), any number \\(z\\), and any positive base \\(b \\neq 1\\), \\[\\log_b (y^z) = z \\log_b y.\\]\n\n\nProof. By the definition of the logarithm and the property of powers of exponents, \\[b^{z \\log_b y} = (b^{\\log_b y})^z = y^z.\\] Therefore, again by the definition of the logarithm, \\(\\log_b (y^z) = z \\log_b y\\).\n\nLogarithm of a ratio. We saw in Proposition 3.1 that logarithms turn multiplication problems into addition problems. For similar reasons, they turn division problems into subtraction problems.\n\nProposition 3.3 (Logarithm of a ratio) For any positive number \\(y\\), any positive number \\(z\\), and any positive base \\(b \\neq 1\\), \\[\\log_b \\left(\\frac{y}{z}\\right) = \\log_b y - \\log_b z.\\]\n\nYou’ve already got the tools you need to prove this one yourself, so I’m leaving the proof as an exercise for you.\n\nExercise 3.1 Prove Proposition 3.3. (Hint: use both of the two previous properties of logarithms, Proposition 3.1 and Proposition 3.2.)\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe ratio \\(\\frac{y}{z}\\) is equivalent to the product \\(y \\times z^{-1}\\). Therefore, Proposition 3.1 implies \\[\\log_b \\left(\\frac{y}{z}\\right) = \\log_b (y \\times z^{-1}) = \\log_b y + \\log_b (z^{-1}).\\] Furthermore, Proposition 3.2 gives us \\(\\log_b (z^{-1}) = - \\log_b z\\). We conclude that \\[\\log_b \\left(\\frac{y}{z}\\right) = \\log_b y + \\log_b (z^{-1}) = \\log_b y - \\log_b z.\\]\n\n\n\n\nLogarithm of 1. The number 1 is special. Perhaps you recall the mathematical rule that \\(b^0 = 1\\) for any positive number \\(b\\). It follows immediately that the logarithm of 1 is always 0, regardless of which base we are working with.\n\nProposition 3.4 (Logarithm of 1) For any positive base \\(b \\neq 1\\), \\[\\log_b 1 = 0.\\]\n\nLet’s go back to this rule that \\(b^0 = 1\\) for any positive number \\(b\\). The mathematical expression \\(b^0\\) is confusing. We typically think of \\(b^x\\) as meaning “multiply \\(b\\) together \\(x\\) times.” How can we multiply \\(b\\) together 0 times? What does that even mean?\nI’m sure someone out there has a deep explanation of why it makes sense for \\(b^0\\) to equal 1. But I’m a mathematical pragmatist. What I know is that our rule that \\(b^{x + y} = b^x \\times b^y\\) would completely break down if \\(b^0\\) had any value other than 1. For example, imagine instead that we had \\(b^0 = 42\\) for some base \\(b\\). Well, then, our usual rule about exponents of sums would give us \\[\nb = b^1 = b^{0 + 1} = b^0 \\times b^1 = 42 b.\n\\] That can’t be right! The only sensible way forward is to assume \\(b^0 = 1\\). I don’t lose any sleep over not having some kind of physical or visual intuition why this is the case, because I know that it’s the only way to handle powers of 0 that doesn’t cause other important things to break.\nSometimes you’ll run into things like this in mathematics. It’s different for everyone. Some people get hung up on the “imaginary” number \\(i = \\sqrt{-1}\\), which I’m happy to tell you basically never comes up in the work political scientists do. Others get hung up on the idea of spaces with more than 3 dimensions, which very much do come up in the work we do. Heck, I know people who are skeptical of the idea of negative numbers because they can’t visualize them.\nWhenever I run into one of these things that I can’t directly visualize or comprehend with a physical analogy, I instead try to think about its role in the mathematical system I’m working with. I can’t “see” why \\(b^0 = 1\\), but I know that it ensures \\(b^{x + y} = b^x \\times b^y\\). I can’t “picture” the imaginary number \\(i\\), but I know that it lets us solve algebraic equations like \\(x^2 + 4 = 0\\). I definitely can’t “visualize” a linear function through 631-dimensional space, yet while I was writing these notes my computer was estimating a regression model with 631 parameters. Don’t feel like you have to be able to picture every mathematical rule or object — it’s enough just to understand how it helps you solve a particular problem.\nBase changes and the natural logarithm. Suppose we know that the base-2 logarithm of 16 is 4, i.e., \\(\\log_2 16 = 4\\). What, if anything, does this tell us about the base-8 logarithm of 16?\nIt turns out that there’s a pretty handy formula to change a logarithm from one base to another. To change the base-\\(b\\) logarithm of \\(y\\) to a base-\\(c\\) logarithm, we just rescale it by the base-\\(b\\) logarithm of \\(c\\).\n\nProposition 3.5 (Logarithm base changes) For any positive number \\(y\\) and any positive bases \\(b \\neq 1\\) and \\(c \\neq 1\\), \\[\\log_c y = \\frac{\\log_b y}{\\log_b c}.\\]\n\n\nProof. Using the definition of a logarithm twice and the properties of exponents once, we have \\[\ny = c^{\\log_c y} = (b^{\\log_b c})^{\\log_c y} = b^{(\\log_b c) \\times (\\log_c y)}.\n\\] Therefore, again by the definition of a logarithm, \\[\\log_b y = (\\log_b c) \\times (\\log_c y).\\] We obtain the proposition by dividing both sides by \\(\\log_b c\\).\n\nNow we can calculate the base-8 logarithm of 16. Since \\(2^4 = 16\\), we know that \\(\\log_2 16 = 4\\). And since \\(2^3 = 8\\), we know that \\(\\log_2 8 = 3\\). Therefore, using Proposition 3.5, we have \\[\\log_8 16 = \\frac{\\log_2 16}{\\log_2 8} = \\frac{4}{3}.\\]\nIn a sense, the upshot of Proposition 3.5 is that it doesn’t matter what base we use — the value of the logarithm scales up or down with the value of the base, but the shape of the curve is the same regardless, as illustrated in Figure 3.4. So if we’re doing something like logging a variable in a linear regression, our results will be substantively the same regardless of which logarithmic base we use. Since the choice of base doesn’t substantively affect our findings, we should choose whatever base is most convenient for interpretation.\n\n\n\n\n\nFigure 3.4\n\n\n\n\n\n\n\n\nThis figure shows three common choices of base for the logarithm. You are probably familiar with the numbers 2 and 10. You might be less familiar with the number \\(e\\), aka Euler’s number, which is equal to roughly 2.718 and comes up repeatedly in high-end math. This number is important enough that we call the base-\\(e\\) logarithm the natural logarithm. For now, I’m going to ask you to trust me that \\(e\\) is important — you’ll be able to see the reasoning a bit better once we get to calculus.\nIn these notes, when I write \\(\\log y\\) without an explicit base, I mean the natural logarithm of \\(y\\). Similarly, the log() function in R takes the natural logarithm if you don’t specify a base. If you want to take a base-\\(e\\) exponent in R, use the exp() function.\n\n\n\n\n\n\nlog versus ln\n\n\n\nIn other contexts, including high school math (if my early-2000s experience still holds), people use \\(\\ln\\) to mean the natural logarithm and \\(\\log\\) to mean the base-10 algorithm. ChatGPT tells me that engineers are also fond of this usage. But in political science, economics, and statistics writing, as well as in the overwhelming majority of math textbooks at the college level and beyond, \\(\\log\\) means the natural logarithm.\n\n\nProposition 3.5 tells us why it’s mostly harmless to just use the natural logarithm for everything. If for some reason you ever need to convert a natural logarithm to a different base, you can just use the formula \\[\\log_b y = \\frac{\\log y}{\\log b}.\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sequences and Series</span>"
    ]
  },
  {
    "objectID": "sequences_series.html#sec-sequences-limits",
    "href": "sequences_series.html#sec-sequences-limits",
    "title": "3  Sequences and Series",
    "section": "3.3 Sequences and limits",
    "text": "3.3 Sequences and limits\nIn terms of our motivating example, we’ve used the logarithm to find the term length \\(T\\) that corresponds to a particular probability of lasting that long, \\(p^T (1 - p)\\). Looking at Figure 3.1, it seems like these probabilities get closer and closer to 0 as \\(T\\) increases, though they never quite hit 0 exactly. Is there a way we can say that more precisely? For that, we’ll need to learn about sequences and their limits.\nA sequence is an infinite, ordered list of numbers. We write \\(\\{x_n\\}\\) to denote the sequence \\(x_1, x_2, x_3, \\ldots\\), with \\(x_n\\) standing for the \\(n\\)’th entry in the sequence. Unlike with sets, order and repetition matter in a sequence. For example, the sequence \\(0, 1, 0, 1, \\ldots\\) is distinct from the sequence \\(1, 0, 1, 0, \\ldots\\) and the sequence \\(0, 0, 1, 1, 0, 0, 1, 1, \\ldots\\).\n\n\n\n\n\n\nSequences vs. sets\n\n\n\nBecause we use curly brackets to denote both sequences and sets, there are some cases where it can be confusing to distinguish a single-element set from a sequence. The main context clue to look for is the presence of an index subscript: for example, \\(\\{3\\}\\) isn’t a sequence because there’s no index variable. By the same token, it would be cruel and unusual for a mathematical writer to use \\(\\{x_n\\}\\) to mean “the set whose sole element is \\(x_n\\)” rather than “the sequence \\(x_1, x_2, \\ldots\\).” If you ever want to send a very strong signal that something is a sequence, you may use a subscript to explicitly call out the index, using the notation \\(\\{x_n\\}_{n=1}^\\infty\\). Or, you know, you can just say “the sequence \\(\\{x_n\\}\\).” Words are helpful!\n\n\nA sequence is ordered, in that it is sensible to talk about the first or tenth or 1,052,402nd element of a sequence. Additionally, any sequence we’ll talk about for now will consist of elements that are all real numbers. (I’ll let you know if and when we’re dealing with sequences of other types of mathematical object.) Putting these two facts together, you can also think of a sequence as a function that maps the set of natural numbers, \\(\\mathbb{N}\\), into the set of real numbers, \\(\\mathbb{R}\\).\n\n3.3.1 Definition of a limit\nThink about the sequence \\(1, \\frac{1}{2}, \\frac{1}{3}, \\frac{1}{4}, \\ldots\\). To denote this formally, let \\(\\{x_n\\}\\) be the sequence where each \\(x_n = \\frac{1}{n}\\). The further we go along this sequence, the closer the values get to 0 — though we never quite get all the way there. Indeed, we would say the limit of the sequence is 0, which we’d denote by writing \\(\\lim_{n \\to \\infty} x_n = 0\\) or, more simply, \\(\\{x_n\\} \\to 0\\).\n\n\n\n\n\n\n\n\n\nWhat we need now is a precise mathematical notion of “getting closer and closer.” The infinite nature of a sequence makes this tricky. We can’t follow the sequence and see that it ends at 0, because the sequence has no end! To get around this issue, mathematicians use what I think of as a “challenge-response” definition of a limit. Here’s what I mean by that. Suppose I have a sequence \\(\\{x_n\\}\\) and claim that its limit is a number \\(x\\).\n\nYou challenge me by picking a number \\(\\epsilon &gt; 0\\). Think of this as you saying “I need you to show me that once we get far enough along the sequence, every value is within \\(\\epsilon\\) of your supposed limit.”\nI respond to the challenge by identifying an index \\(N\\) after which the sequence values are as close as you demand. In particular, I need to show you that \\(x - \\epsilon &lt; x_n &lt; x + \\epsilon\\) for all indices \\(n \\geq N\\).\n\nMy claimed limit is true if and only if I can conjure up a valid response to any \\(\\epsilon &gt; 0\\) that you might pick. The formal definition of a limit puts this process in precise mathematical terms.\n\nDefinition 3.2 (Finite limit) The sequence \\(\\{x_n\\}\\) has a limit of \\(x \\in \\mathbb{R}\\) if the following condition is satisfied: for any real number \\(\\epsilon &gt; 0\\), we can identify an index \\(N\\) such that \\(|x_n - x| &lt; \\epsilon\\) for all \\(n \\geq N\\). The sequence is convergent if and only if \\(\\lim_{n \\to \\infty} x_n = x\\) for some finite number \\(x\\).\n\nA sequence cannot have two distinct limits. If the sequence \\(\\{x_n\\}\\) is getting ever closer to \\(x\\) as \\(n\\) increases, it cannot also be getting ever closer to some other number \\(x'\\). We won’t go all the way through a proof of this claim, but here’s the basics of how it would work. Letting \\(d\\) stand for half the distance between the limit \\(x\\) and some other number \\(x'\\), we know from the formal definition of a limit that after a certain point, every \\(x_n\\) lies between \\(x - d\\) and \\(x + d\\). This in turn means that every \\(x_n\\) from this point onward is at least \\(d\\) away from \\(x'\\), meaning that \\(x'\\) cannot possibly be the limit of the sequence — there is no valid response to the challenge where \\(\\epsilon = d\\).\nIt can be tricky to use the formal definition (Definition 3.2) to prove that some number is indeed the limit of a specified sequence. Even if you can “see” that some sequence is getting ever closer to its limit, how can you show that the precise formal definition is satisfied? To make the challenge-response process a bit more concrete, let’s apply it to the problem of showing that \\(\\lim_{n \\to \\infty} 1/n = 0\\).\n\nExample 3.1 We want to prove that \\(\\lim_{n \\to \\infty} 1/n = 0\\). To do so, we must show that for any choice of a number \\(\\epsilon &gt; 0\\), we can find an index \\(N\\) such that \\(-\\epsilon &lt; 1/n &lt; \\epsilon\\) for all \\(n \\geq N\\).\nYou can think about this as a “for all” claim: namely, that for all \\(\\epsilon &gt; 0\\), there is an index \\(N\\) that meets the requirement above. So to prove it, we will follow the method laid out in Note 2.1 in the previous chapter. That is, we will take an “arbitrary” \\(\\epsilon &gt; 0\\) — a number \\(\\epsilon\\) that we know nothing about, besides that it’s greater than 0 — and prove that we can find an index \\(N\\) that meets the requirement.\nProof: Take an arbitrary \\(\\epsilon &gt; 0\\). Because \\(\\epsilon &gt; 0\\), the fraction \\(1/\\epsilon\\) is finite and positive (though perhaps very large). Let \\(N\\) be any integer greater than \\(1/\\epsilon\\). For any \\(n \\geq N\\), we have \\[\\frac{1}{n} \\leq \\frac{1}{N} &lt; \\frac{1}{1/\\epsilon} = \\epsilon.\\] Combined with the fact that \\(1/n &gt; 0 &gt; -\\epsilon\\) for all \\(n\\), we have shown that there exists an index \\(N\\) such that \\(-\\epsilon &lt; 1/n &lt; \\epsilon\\) for all \\(n \\geq N\\). Because \\(\\epsilon\\) was chosen arbitrarily, this completes the proof that \\(\\lim_{n \\to \\infty} 1/n = 0\\).\n\n\n\nIt would be reasonable to be skeptical about the (critical!) step in Example 3.1 where I assert the existence of an integer greater than \\(1/\\epsilon\\). If you are indeed skeptical in this way, don’t worry — the Archimedean property of the real numbers guarantees it. (And if you weren’t skeptical, perhaps you should have been?)\nWe can use a similar proof to show that the sequence of term length probabilities in our motivating example, \\(\\{p^T (1 - p)\\}_{T = 1}^\\infty\\), has a limit of 0. To do that, we’ll need to use logarithms.\n\nExample 3.2 We want to prove that \\(\\lim_{T \\to \\infty} p^T (1 - p) = 0\\). To do so, we must show that for any choice of a number \\(\\epsilon &gt; 0\\), we can find an index \\(N\\) such that \\(-\\epsilon &lt; p^T (1 - p) &lt; \\epsilon\\) for all \\(T \\geq N\\).\nProof: Take an arbitrary \\(\\epsilon &gt; 0\\). Because \\(0 &lt; p &lt; 1\\), the value \\(p^T\\) decreases with \\(T\\) as long as \\(T \\geq 1\\). So the tricky part is to show that we can find some term length such that \\(p^T (1 - p) &lt; \\epsilon\\), or equivalently that \\(p^T &lt; \\frac{\\epsilon}{1 - p}\\). We know from the definition of the logarithm that \\(\\log_p \\frac{\\epsilon}{1 - p}\\) is the solution to the equation \\(p^x = \\frac{\\epsilon}{1 - p}\\). This gives us precisely what we need to meet the formal definition of a limit.\nLet \\(N\\) be any integer greater than \\(\\log_p \\left(\\frac{\\epsilon}{1 - p}\\right)\\). For any \\(T \\geq N\\), we have \\[p^T (1 - p) \\leq p^N (1 - p) &lt; p^{\\log_p \\left(\\frac{\\epsilon}{1 - p}\\right)} (1 - p) = \\left(\\frac{\\epsilon}{1 - p}\\right) (1 - p) = \\epsilon.\\] Combined with the fact that \\(-\\epsilon &lt; 0 &lt; p^T (1 - p)\\) for all \\(T\\), we have shown that there exists an index \\(N\\) such that \\(-\\epsilon &lt; p^T (1 - p) &lt; \\epsilon\\) for all \\(T \\geq N\\). Because \\(\\epsilon\\) was chosen arbitrarily, this completes the proof that \\(\\lim_{T \\to \\infty} p^T (1 - p) = 0\\).\n\nAs an exercise to get some practice with the formal definition of a limit, I’ll have you prove a reasonably simple claim. If we have a constant sequence, so that \\(x_n = c\\) for every index \\(n\\), then the limit of this sequence is \\(c\\).\n\nExercise 3.2 (Limit of a constant sequence) Let \\(c\\) be a constant real number. Prove that if \\(x_n = c\\) for all \\(n\\), then \\(\\{x_n\\} \\to c\\).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe must prove that for every \\(\\epsilon &gt; 0\\), there is an index \\(N\\) such that \\(c - \\epsilon &lt; x_n &lt; c + \\epsilon\\). To this end, take an arbitrary \\(\\epsilon &gt; 0\\). For all \\(n \\geq 1\\), we have \\(x_n = c\\) and therefore \\(c - \\epsilon &lt; x_n &lt; c + \\epsilon\\). We have thus shown that \\(N = 1\\) is a valid response to any \\(\\epsilon &gt; 0\\) challenge, thereby proving that \\(\\{x_n\\} \\to c\\).\n\n\n\n\nNot every sequence is convergent. We call a sequence divergent if it is not convergent. One reason that a sequence might be divergent is that the values in the sequence increase (or decrease) without bound. For example, the sequence \\(1, 2, 3, \\ldots\\) is divergent, as are the sequences \\(-1, -2, -3, \\ldots\\) and \\(1, -1, 2, -2, 3, -3, \\ldots\\). In fact, it turns out that a necessary condition for a sequence to converge is that the sequence be bounded.\n\nDefinition 3.3 (Bounded sequence) We say the sequence \\(\\{x_n\\}\\) is bounded if there is a finite number \\(B\\) such that \\(-B \\leq x_n \\leq B\\) for all indices \\(n\\).\n\n\nProposition 3.6 (Convergent implies bounded) If \\(\\{x_n\\}\\) is convergent, then it is bounded.\n\n\nProof. Suppose the sequence \\(\\{x_n\\}\\) is convergent, and let \\(x\\) denote its limit. According to the formal definition of a limit (Definition 3.2), there is an index \\(N\\) such that \\(x - 1 &lt; x_n &lt; x + 1\\) for all indices \\(n \\geq N\\). Let \\(B_{\\text{left}}\\) be the lowest value in the finite set \\(\\{x_1, \\ldots, x_N, x - 1\\}\\), and let \\(B_{\\text{right}}\\) be the greatest value in the finite set \\(\\{x_1, \\ldots, x_N, x + 1\\}\\). Then, let \\(B\\) be whichever of \\(|B_{\\text{left}}|\\) and \\(|B_{\\text{right}}|\\) is greater. For every index \\(n\\), we have \\[-B \\leq B_{\\text{left}} \\leq x_n \\leq B_{\\text{right}} \\leq B,\\] so \\(\\{x_n\\}\\) is bounded.\n\nAn equivalent statement would be the contrapositive, “If \\(\\{x_n\\}\\) is not bounded, then it is not convergent.” That’s a useful fact in practice. If you observe that a sequence is unbounded, you can stop looking for a finite limit — it can’t have one.\nProposition 3.6 is an “if” statement, not an “if and only if.” Just as every zebra is a mammal but not every mammal is a zebra, every convergent sequence is bounded but not every bounded sequence is convergent. The next exercise asks you to think of an example.\n\nExercise 3.3 (Bounded does not imply convergent) Come up with an example of a bounded sequence that is not convergent.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere are many examples of convergent sequences that are not bounded, but the simplest one I can think of is \\(0, 1, 0, 1, \\ldots\\), i.e., the sequence \\(\\{x_n\\}\\) where each \\[\nx_n = \\begin{cases}\n0 & \\text{if $n$ is odd}, \\\\\n1 & \\text{if $n$ is even}.\n\\end{cases}\n\\] To prove that \\(\\{x_n\\}\\) is not convergent, I will just rule out every number as a potential limit for it.\n\nNo \\(x \\neq 0\\) may be the limit of \\(\\{x_n\\}\\). To see why, take any \\(x \\neq 0\\). To show that \\(x\\) is not the limit, we need to find a “challenge” value \\(\\epsilon\\) for which there is no valid response.\nI claim that \\(\\epsilon = |x|\\) is this type of unmeetable challenge. To show that the challenge cannot be met, we need to show that at any point in the sequence, we can find a value there or further along that is at least \\(\\epsilon\\) away from \\(x\\). To do this, take any index \\(n\\). Then either \\(x_n = 0\\) or \\(x_{n+1} = 0\\), meaning that either \\(|x_n - x| \\geq \\epsilon\\) or \\(|x_{n+1} - x| \\geq \\epsilon\\). Therefore, \\(x\\) cannot be a limit of the sequence.\nNo \\(x \\neq 1\\) may be the limit of \\(\\{x_n\\}\\) either. The logic here is the same as in the previous step — just take any \\(x \\neq 1\\) and show that the challenge with \\(\\epsilon = |x - 1|\\) cannot succeed.\nThe first step leaves \\(x = 0\\) as the only possible limit, but the second step rules that out too. Therefore, \\(\\{x_n\\}\\) has no limit.\n\n\n\n\n\nAny sequence that is bounded and divergent must oscillate (go up and down and up and down and …) as in my answer to Exercise 3.3. A monotone sequence, in which the values always increase (every \\(x_{n+1} \\geq x_n\\)) or always decrease (every \\(x_{n+1} \\leq x_n\\)), always converges if it is bounded. This fact about monotone sequences is important enough in the study of calculus that I will state it as a theorem. However, I will skip over proving it, as the proof relies on some real analysis concepts that we don’t have the bandwidth to cover in this course.\n\nTheorem 3.1 (Monotone Convergence Theorem) If \\(\\{x_n\\}\\) is bounded and monotone, then it is convergent.\n\nThe Monotone Convergence Theorem tells us that particular sequences have a finite limit, but doesn’t say what that limit is. For example, think again about the sequence of the incumbent party serving \\(T\\) more consecutive terms in our running example, \\(\\{p^T (1 - p)\\}_{T = 1}^\\infty\\). Because \\(p^T\\) decreases with the number of terms \\(T\\), this sequence is monotone. And because \\(0 \\leq p^T (1 - p) \\leq 1 - p\\) for all \\(T\\), it is bounded. We can therefore infer from the Monotone Convergence Theorem that this sequence is convergent, as we indeed saw above in Example 3.2. However, to go from “this sequence has a limit” to “this sequence’s limit is 0,” we needed more than the Monotone Convergence Theorem alone would give us.\n\n\n3.3.2 Infinite limits\nTo sum up where we are so far, here’s what we know about the relationship between boundedness, monotonicity, and the convergence of a sequence.\n\nBounded and monotone ⇒ definitely convergent\nBounded and not monotone ⇒ maybe convergent, maybe not\nUnbounded ⇒ definitely divergent\n\nAlthough every unbounded sequence is divergent, there are still some distinctions we can draw among them.\n\nIf the values of the sequence are always going higher, then we would say it has a limit of \\(\\infty\\). The sequence \\(\\{n\\} = 1, 2, 3, \\ldots\\) is an example.\nIf the values of the sequence are always going lower, then we would say it has a limit of \\(-\\infty\\). The sequence \\(\\{-n^2\\} = -1, -4, -9, \\ldots\\) is an example.\nAn unbounded sequence can still oscillate and have no limit. The sequence \\(\\{(-1)^n n\\} = -1, 2, -3, 4, \\ldots\\) is an example.\n\nOur formal definition of an infinite limit has a challenge-response structure similar to the definition of a finite limit (Definition 3.2). Here the “challenge” is not an \\(\\epsilon\\) very close to 0, but instead a \\(y\\) that’s very large in magnitude. We need to show that if we go far enough along the sequence, the magnitude of the elements \\(x_n\\) is always larger than whatever challenge has been mustered.\n\nDefinition 3.4 (Infinite limit) For a sequence \\(\\{x_n\\}\\), we say that \\(\\{x_n\\} \\to \\infty\\) if the following condition is satisfied: for any real number \\(a\\), we can identify an index \\(N\\) such that \\(x_n &gt; a\\) for all \\(n \\geq N\\). Similarly, we say that \\(\\{x_n\\} \\to -\\infty\\) if for any real number \\(a\\), we can identify an index \\(N\\) such that \\(x_n &lt; a\\) for all \\(n \\geq N\\).\n\nAs an example to apply this definition, think about the sequence of squares, \\(\\{n^2\\} = 1, 4, 9, \\ldots\\). To show that this sequence has a limit of \\(\\infty\\), consider any “challenge” of \\(a \\geq 0\\). Given such a challenge, let \\(N\\) be any integer larger than \\(\\sqrt{a}\\). Then for all elements past this index (\\(n \\geq N\\)), we have \\[x_n \\geq x_N = N^2 \\geq \\sqrt{a}^2 = a.\\] We have shown that every challenge can be met, and therefore \\(\\lim_{n \\to \\infty} n^2 = \\infty\\).\n\nExercise 3.4 For each of the following unbounded sequences, use Definition 3.4 to prove the stated claim about its limit.\n\nThe sequence \\(\\{-\\sqrt{n}\\} = -1, -\\sqrt{2}, -\\sqrt{3}, \\ldots\\) has a limit of \\(-\\infty\\).\nThe sequence \\(1, 0, 3, 0, 5, 0, 7, 0, \\ldots\\) (\\(x_n = n\\) if \\(n\\) is odd, \\(x_n = 0\\) if \\(n\\) is even) has no limit.\nThe “three steps forward, one step back” sequence \\(1, 0, 3, 2, 5, 4, 7, 6, 9, 8, \\ldots\\) (\\(x_n = n\\) if \\(n\\) is odd, \\(x_n = n - 2\\) if \\(n\\) is even) has a limit of \\(\\infty\\).\n\n\n\n\n\n\n\nAnswers\n\n\n\n\n\n\nConsider any challenge \\(a\\), and let \\(N\\) be any integer greater than \\(a^2\\). For all \\(n \\geq N\\), we have \\[x_n \\leq x_N = -\\sqrt{N} \\leq -\\sqrt{a^2} \\leq -|a| \\leq a.\\] Because every challenge can be met, we conclude that \\(\\lim_{n \\to \\infty} -\\sqrt{n} = -\\infty\\).\nTo rule out a limit of \\(\\infty\\), consider the challenge \\(a = 1\\). For any index \\(N\\), let \\(n\\) be an even number greater than or equal to \\(N\\). Then we have \\(x_n = 0 &lt; a\\). As there is no valid response to the \\(a = 1\\) challenge, we conclude that \\(\\{x_n\\}\\) cannot have a limit of \\(\\infty\\). To rule out a limit of \\(-\\infty\\), it is sufficient to observe that the sequence is bounded from below (specifically, every \\(x_n \\geq 0\\)).\nConsider any challenge \\(a\\), and let \\(N\\) be any integer greater than \\(a + 2\\). For all odd indices \\(n \\geq N\\), we have \\[x_n = n \\geq N \\geq a + 2 &gt; a.\\] For all even indices \\(n \\geq N\\), we have \\[x_n = n - 2 \\geq N - 2 \\geq a.\\] Therefore, \\(N\\) is a valid response to the challenge of \\(a\\). Because every challenge can be met, we conclude that \\(\\lim_{n \\to \\infty} x_n = \\infty\\).\n\n\n\n\n\n\n\n3.3.3 Properties of limits\nDon’t worry if the formal definition of a limit (Definition 3.2) seems daunting and cumbersome to use. In practice, most of the time that you end up dealing with limits, you won’t have to explicitly deal with the challenge-response structure. Instead, you can use helpful properties of limits to calculate the limit of a sequence.\nSay we have three convergent sequences: a “lower” sequence \\(\\{\\ell_n\\} \\to \\ell\\), an “upper” sequence \\(\\{u_n\\} \\to u\\), and a sequence \\(\\{x_n\\} \\to x\\) that always falls in between the other two after a certain point. The limit of the middle sequence must then lie in between the limits of the other two sequences, as illustrated in the graph below.\n\n\n\n\n\n\n\n\n\nWhen we’re thinking about limits, it doesn’t matter that the first few terms of the middle sequence are actually outside of the bounding sequences. We can slice any finite number of terms off of the front end of a sequence, and it makes no difference to the limiting behavior of that sequence. All we need is that \\(\\ell_n \\leq x_n \\leq u_n\\) for every index \\(n\\) after a certain point, even if this inequality fails to hold for some smaller indices.\n\nProposition 3.7 Assume that \\(\\{\\ell_n\\}\\) and \\(\\{u_n\\}\\) are convergent sequences with limits \\(\\ell\\) and \\(u\\) respectively. Additionally, assume there is a sequence \\(\\{x_n\\}\\) and an index \\(M\\) such that \\(\\ell_n \\leq x_n \\leq u_n\\) for all \\(n \\geq M\\).\n\nIf \\(\\{x_n\\}\\) is convergent with limit \\(x\\), then \\(\\ell \\leq x \\leq u\\).\nIf \\(\\ell = u\\), then \\(\\{x_n\\}\\) is guaranteed to be convergent, and it has the same limit. (This claim is sometimes called the “squeeze theorem” for sequences.)\n\n\n\nProof. To prove claim (a), assume \\(\\{x_n\\} \\to x\\). We will prove that \\(x \\geq \\ell\\); the proof that \\(x \\leq u\\) is analogous (i.e., you can prove it yourself by following the same steps as we do here, with minimal substitutions).\nTo prove that \\(x \\geq \\ell\\), we will use a proof by contradiction. Suppose, for the sake of such a proof, that instead \\(x &lt; \\ell\\). Let \\(\\delta\\) denote half the distance between \\(x\\) and \\(\\ell\\), so that \\(\\delta = (\\ell - x) / 2\\). Because \\(\\{x_n\\} \\to x\\), there is an index \\(N_1\\) such that \\(x - \\delta &lt; x_n &lt; x + \\delta\\) for all \\(n \\geq N_1\\). Additionally, because \\(\\{\\ell_n\\} \\to \\ell\\), there is an index \\(N_2\\) such that \\(\\ell - \\delta &lt; \\ell_n &lt; \\ell + \\delta\\) for all \\(n \\geq N_2\\). But together these imply that \\(x_n &lt; \\ell_n\\) for all \\(n \\geq \\max\\{N_1, N_2\\}\\): specifically, for all such \\(n\\), we have \\[\n\\begin{aligned}\nx_n &&lt; x + \\delta \\\\\n&= x + \\frac{\\ell - x}{2} \\\\\n&= \\frac{x}{2} + \\frac{\\ell}{2} \\\\\n&= \\ell - \\frac{\\ell - x}{2} \\\\\n&= \\ell - \\delta \\\\\n&&lt; \\ell_n.\n\\end{aligned}\n\\] This finding contradicts our assumption that \\(\\ell_n \\leq x_n\\) for all \\(n \\geq M\\). Therefore, we conclude that \\(x \\geq \\ell\\).\nTo prove claim (b), assume \\(\\ell = u\\). Take an arbitrary \\(\\epsilon &gt; 0\\). Because \\(\\{\\ell_n\\} \\to \\ell\\), there is an index \\(N_1\\) such that \\(\\ell - \\epsilon &lt; \\ell_n &lt; \\ell + \\epsilon\\) for all \\(n \\geq N_1\\). Similarly, there is an index \\(N_2\\) such that \\(\\ell - \\epsilon &lt; u_n &lt; \\ell + \\epsilon\\) for all \\(n \\geq N_2\\). Let \\(N\\) be the greatest value among \\(M\\), \\(N_1\\), and \\(N_2\\). For all \\(n \\geq N\\), we have \\[\\ell - \\epsilon &lt; \\ell_n \\leq x_n \\leq u_n &lt; \\ell + \\epsilon,\\] and thus \\(\\ell - \\epsilon &lt; x_n &lt; \\ell + \\epsilon\\). Because \\(\\epsilon\\) was chosen arbitrarily, we conclude that \\(\\{x_n\\} \\to \\ell\\).\n\nThe squeeze theorem is particularly helpful because it lets us calculate limits without having to use the ugly formal definition. You’ll apply this yourself in the next exercise.\n\nExercise 3.5 Use Proposition 3.7 to show that \\(\\lim_{n \\to \\infty} \\frac{1}{n + 1} = 0\\). (Hint: We’ve already shown that \\(\\lim_{n \\to \\infty} \\frac{1}{n} = 0\\).)\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe constant sequence \\(0, 0, 0, \\ldots\\) has a limit of \\(0\\), as does the sequence \\(\\{\\frac{1}{n}\\}\\). We have \\(0 \\leq \\frac{1}{n + 1} \\leq \\frac{1}{n}\\) for all indices \\(n\\), so part b of Proposition 3.7 implies \\(\\{\\frac{1}{n + 1}\\} \\to 0\\) as well.\n\n\n\n\nAlso helpfully, when we combine convergent sequences using the ordinary operations of arithmetic — addition, subtraction, multiplication, and division — we can combine their limits in the same way. Perhaps more than anything else, this is the set of properties I use to do the work in calculating limits.\n\nProposition 3.8 (Arithmetic properties of limits) Let \\(\\{x_n\\}\\) and \\(\\{y_n\\}\\) be convergent sequences, with limits \\(x\\) and \\(y\\) respectively.\n\nFor any constant \\(c\\), \\(\\{c x_n\\} \\to c x\\).\n\\(\\{x_n + y_n\\} \\to x + y\\).\n\\(\\{x_n - y_n\\} \\to x - y\\).\n\\(\\{x_n y_n\\} \\to xy\\).\nIf \\(y \\neq 0\\), \\(\\{x_n / y_n\\} \\to x/y\\).\n\n\n\nProof. The proof is long and tedious, so I have hidden it in collapsible boxes.\n\n\n\n\n\n\nPart (a): Constant multiple of sequence\n\n\n\n\n\nWe need to prove that for all \\(\\epsilon &gt; 0\\), there is an index \\(N\\) such that \\(|c x_n - c x| &lt; \\epsilon\\) for all \\(n \\geq N\\). To this end, take an arbitrary \\(\\epsilon &gt; 0\\). Because \\(\\{x_n\\} \\to x\\), there is an \\(N\\) such that \\(|x_n - x| &lt; \\epsilon / |c|\\) for all \\(n \\geq N\\). This in turn implies that \\[|c x_n - c x| = |c (x_n - x)| = |c| |x_n - x| &lt; |c| \\cdot \\frac{\\epsilon}{|c|} = \\epsilon\\] for all \\(n \\geq N\\). We have shown that there is a valid response to any \\(\\epsilon &gt; 0\\) challenge, and thus \\(\\{c x_n\\} \\to cx\\).\n\n\n\n\n\n\n\n\n\nPart (b): Sum of sequences\n\n\n\n\n\nThe proof here relies on the triangle inequality: for any real numbers \\(a\\) and \\(b\\), \\[|a + b| \\leq |a| + |b|.\\] If you’re ever having trouble proving something that involves absolute values, the triangle inequality can often help you get a foothold.\nWe need to prove that for all \\(\\epsilon &gt; 0\\), there is an index \\(N\\) such that \\(|(x_n + y_n) - (x + y)| &lt; \\epsilon\\) for all \\(n \\geq N\\). To this end, take an arbitrary \\(\\epsilon &gt; 0\\). Because \\(\\{x_n\\} \\to x\\), there is an \\(N_x\\) such that \\(|x_n - x| &lt; \\epsilon / 2\\) for all \\(n \\geq N_x\\). Similarly, there is an \\(N_y\\) such that \\(|y_n - y| &lt; \\epsilon / 2\\) for all \\(n \\geq N_y\\). Let \\(N\\) be the greater of \\(N_x\\) and \\(N_y\\). Then for all indices \\(n \\geq N\\), we have \\[|(x_n + y_n) - (x + y)| = |(x_n - x) + (y_n - y)| \\leq |x_n - x| + |y_n - y| &lt; \\frac{\\epsilon}{2} + \\frac{\\epsilon}{2} = \\epsilon.\\] We have shown that there is a valid response to any \\(\\epsilon &gt; 0\\) challenge, and thus \\(\\{x_n + y_n\\} \\to x + y\\).\n\n\n\n\n\n\n\n\n\nPart (c): Difference of sequences\n\n\n\n\n\nWe have \\(x_n - y_n = x_n + (-1) y_n\\), so the claim follows from parts (a) and (b): \\[\\lim_{n \\to \\infty} (x_n - y_n) = \\lim_{n \\to \\infty} [x_n + (-1) y_n]  = \\lim_{n \\to \\infty} x_n + (-1) \\lim_{n \\to \\infty} y_n  = x + (-1) y = x - y.\\]\n\n\n\n\n\n\n\n\n\nPart (d): Product of sequences\n\n\n\n\n\nWe need to prove that for all \\(\\epsilon &gt; 0\\), there is an index \\(N\\) such that \\(|x_n y_n - x y| &lt; \\epsilon\\) for all \\(n \\geq N\\). To this end, take an arbitrary \\(\\epsilon &gt; 0\\). Because \\(\\{y_n\\} \\to y\\), there is an \\(N_1\\) such that \\(y - 1 &lt; y_n &lt; y + 1\\) for all \\(n \\geq N_1\\). Let \\(Y\\) denote the greater of \\(|y - 1|\\) and \\(|y + 1|\\). Because \\(\\{x_n\\} \\to x\\), there is an \\(N_2\\) such that \\(|x_n - x| &lt; \\frac{\\epsilon}{2 Y}\\) for all \\(n \\geq N_2\\). Finally, because \\(\\{y_n \\to y\\}\\), there is an \\(N_3\\) such that \\(|y_n - y| &lt; \\frac{\\epsilon}{2 |x|}\\) for all \\(n \\geq N_3\\).\nLet \\(N\\) denote the greatest value among \\(N_1\\), \\(N_2\\), and \\(N_3\\). For any \\(n \\geq N\\), we have \\[\n\\begin{aligned}\n|x_n y_n - x y|\n&= |x_n y_n - x y_n + x y_n - x y | \\\\\n&= |(x_n - x) y_n + x (y_n - y)| \\\\\n&\\leq |(x_n - x) y_n| + |x (y_n - y)| \\\\\n&= |x_n - x| |y_n| + |x| |y_n - y| \\\\\n&&lt; \\frac{\\epsilon}{2 Y} \\cdot Y + |x| \\cdot \\frac{\\epsilon}{2 |x|} \\\\\n&= \\epsilon.\n\\end{aligned}\n\\] We have shown that there is a valid response to any \\(\\epsilon &gt; 0\\) challenge, and thus \\(\\{x_n y_n\\} \\to x y\\).\nNote 1: If you are confused by the first inequality here, see the discussion of the triangle inequality in the proof of the previous part.\nNote 2: If \\(x = 0\\), then we can’t cancel the product of \\(|x|\\) with \\(\\frac{\\epsilon}{2 |x|}\\) as in the last step above. However, in that case, the second term of the sum is always 0, so the conclusion that \\(|x_n y_n - x y| &lt; \\epsilon\\) for all \\(n \\geq N\\) still holds.\n\n\n\n\n\n\n\n\n\nPart (e): Ratio of sequences\n\n\n\n\n\nAssume \\(y \\neq 0\\).\nWe will first prove that \\(\\{1 / y_n\\} \\to 1 / y\\). To this end, take an arbitrary \\(\\epsilon &gt; 0\\). Because \\(\\{y_n\\} \\to y\\) and \\(y \\neq 0\\), there is an \\(N_1\\) such that \\(|y_n - y| &lt; \\frac{\\epsilon |y|^2}{2}\\) for all \\(n \\geq N_1\\), and there is an \\(N_2\\) such that \\(\\frac{|y|}{2} &lt; |y_n| &lt; \\frac{3 |y|}{2}\\) for all \\(n \\geq N_2\\). Let \\(N\\) denote the greater of \\(N_1\\) and \\(N_2\\). For any \\(n \\geq N\\), we have \\[\n\\begin{aligned}\n\\left|\\frac{1}{y_n} - \\frac{1}{y}\\right|\n&= \\left|\\frac{y}{y y_n} - \\frac{y_n}{y y_n}\\right| \\\\\n&= \\left|\\frac{y - y_n}{y y_n}\\right| \\\\\n&= \\frac{|y - y_n|}{|y| |y_n|} \\\\\n&&lt; \\frac{\\epsilon |y|^2 / 2}{|y| |y_n|} \\\\\n&= \\frac{\\epsilon |y| / 2}{|y_n|} \\\\\n&&lt; \\frac{\\epsilon |y| / 2}{|y| / 2} \\\\\n&= \\epsilon.\n\\end{aligned}\n\\] We have shown that there is a valid response to any \\(\\epsilon &gt; 0\\) challenge, so \\(\\{1/y_n\\} \\to \\{1/y\\}\\).\nWe can now prove the claim using our result from part (c): \\[\n\\left\\{\\frac{x_n}{y_n}\\right\\}\n= \\left\\{x_n \\cdot \\frac{1}{y_n}\\right\\}\n\\to x \\cdot \\frac{1}{y}\n= \\frac{x}{y}.\n\\]\n\n\n\n\nThe next exercise has you apply these properties to characterize a few limits without having to use the formal definition. Of course, you can always verify that the formal definition works too. But when you can use the properties from Proposition 3.8, the proof of your limit typically ends up more concise and easier to read.\n\nExercise 3.6  \n\nShow that \\(\\lim_{n \\to \\infty} \\frac{1}{n^2} = 0\\).\nShow that \\(\\lim_{n \\to \\infty} \\frac{1000}{n} = 0\\).\nShow that \\(\\lim_{n \\to \\infty} \\frac{n}{n + 1} = 1\\).\n\n\n\n\n\n\n\nAnswers\n\n\n\n\n\n\nBecause \\(\\lim_{n \\to \\infty} \\frac{1}{n} = 0\\), we have \\[\\lim_{n \\to \\infty} \\frac{1}{n^2} = \\lim_{n \\to \\infty} \\left(\\frac{1}{n} \\cdot \\frac{1}{n}\\right) = \\left(\\lim_{n \\to \\infty} \\frac{1}{n}\\right) \\cdot \\left(\\lim_{n \\to \\infty} \\frac{1}{n}\\right) = 0 \\cdot 0 = 0.\\]\nBecause \\(\\lim_{n \\to \\infty} \\frac{1}{n} = 0\\), we have \\[\\lim_{n \\to \\infty} \\frac{1000}{n} = \\lim_{n \\to \\infty} \\left(1000 \\cdot \\frac{1}{n}\\right) = 1000 \\cdot \\lim_{n \\to \\infty} \\frac{1}{n} = 1000 \\cdot 0 = 0.\\]\nWe showed above in Exercise 3.2 that \\(\\lim_{n \\to \\infty} 1 = 1\\), and we showed in Exercise 3.5 that \\(\\lim_{n \\to \\infty} \\frac{1}{n + 1} = 0\\). Therefore, we have \\[\\lim_{n \\to \\infty} \\frac{n}{n + 1} = \\lim_{n \\to \\infty} \\left(1 - \\frac{1}{n + 1}\\right) = \\lim_{n \\to \\infty} 1 - \\lim_{n \\to \\infty} \\frac{1}{n + 1} = 1 - 0 = 1.\\]\n\n\n\n\n\nNow let’s use the squeeze theorem in combination with the other helpful properties of limits to prove an important step for our eventual solution to the motivating example about expected term length. We’ve already seen that the probability of lasting \\(T\\) terms, \\(p^T (1 - p)\\), tends toward 0 as \\(T\\) increases. But what about when we weight each probability by the term length in question, as we do when calculating an expected value? We saw some suggestive evidence in Figure 3.2 that \\(T p^T (1 - p)\\) also has a limit of 0 as \\(T\\) becomes larger and larger. How can we prove that?\n\nExample 3.3 We want to show that \\(\\lim_{T \\to \\infty} T p^T (1 - p) = 0\\) for any \\(p\\) satisfying \\(0 &lt; p &lt; 1\\). In theory we could do this with the formal definition (Definition 3.2), but in practice it’s hard to characterize the \\(N\\) that meets any given \\(\\epsilon\\) challenge. So we will go about this a different way.\nThe meat of the problem is to prove that \\(\\lim_{T \\to \\infty} T p^T = 0\\). Once we’ve done that, we can use the constant multiple rule from Proposition 3.8 to show that \\(\\lim_{T \\to \\infty} T p^T (1 - p) = 0\\) as well. We know that \\(0 \\leq T p^T\\) for all \\(T\\). So if we can find a sequence \\(\\{x_T\\}\\) that has a limit of 0, and where \\(T p^T \\leq x_T\\) after a certain point, then we can use the squeeze theorem (Proposition 3.7) to conclude that \\(\\{T p^T\\} \\to 0\\).\nTo construct the sequence we need, let \\(q\\) be any number that satisfies \\(p &lt; q &lt; 1\\). Using the properties from Proposition 3.8, we have \\[\n\\lim_{T \\to \\infty} \\left(1 + \\frac{1}{T}\\right) p\n= \\left(1 + \\lim_{T \\to \\infty} \\frac{1}{T}\\right) p\n= p.\n\\] Therefore, there is an index \\(S\\) such that \\((1 + \\frac{1}{T}) p &lt; q\\) for all \\(T \\geq S\\).\nTo apply the squeeze theorem, we will use the sequence \\(\\{q^{T - S} \\cdot S p^S\\}_{T=1}^\\infty\\). Because \\(S p^S\\) is a constant and \\(\\{q^T\\} \\to 0\\), we have \\(\\{q^{T - S} \\cdot S p^S\\} \\to 0\\) as well. Additionally, I claim that \\(T p^T \\leq q^{T - S} \\cdot S p^S\\) for all \\(T \\geq S\\). I will prove this via induction (Section 1.2.4).\n\nFor the base step, I must prove that the claim is true for \\(T = S\\). This holds trivially: \\[S p^S = 1 \\cdot S p^S = q^0 \\cdot S p^S = q^{S - S} \\cdot S p^S.\\]\nFor the induction step, I must show that if the claim is true for some \\(T \\geq S\\), then it is also true for \\(T + 1\\). So assume that \\(T p^T \\leq q^{T - S} \\cdot S p^S\\). Then we have \\[\n\\begin{aligned}\n(T + 1) p^{T + 1}\n&= T \\left(1 + \\frac{1}{T}\\right) p^{T + 1} \\\\\n&= T \\cdot \\underbrace{\\left(1 + \\frac{1}{T}\\right) p}_{\\mathclap{\\text{$&lt; q$ because $T \\geq S$}}} \\cdot p^T \\\\\n&&lt; q \\cdot T p^T \\\\\n&\\leq q \\cdot q^{T-S} \\cdot S p^S \\\\\n&= q^{(T + 1) - S} \\cdot S p^S.\n\\end{aligned}\n\\]\n\nAltogether, we have that \\[0 \\leq T p^T \\leq q^{T - S} \\cdot S p^S\\] for all \\(T \\geq S\\). Because the outer terms each go to 0 as \\(T \\to \\infty\\), we conclude from the squeeze theorem that \\(\\{T p^T\\} \\to 0\\) as well. It then follows from the constant multiple rule that \\(\\{T p^T (1 - p)\\} \\to 0\\) as well.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sequences and Series</span>"
    ]
  },
  {
    "objectID": "sequences_series.html#series",
    "href": "sequences_series.html#series",
    "title": "3  Sequences and Series",
    "section": "3.4 Series",
    "text": "3.4 Series\nWe almost have everything we need to answer our original question: if the incumbent party retains power each term with probability \\(p\\), what is the expected number of terms it will remain in office? We have already seen that the answer to this question will involve the infinite sum \\[\\sum_{T=0}^\\infty T \\cdot \\Pr(\\text{term length} = T) = \\sum_{T=0}^\\infty T p^T (1 - p).\\] But how do we calculate an infinite sum, or series, like this one?\nThe key to solving the problem is to think of an infinite sum as the limit of finite sums. It may be daunting to think about adding infinitely many numbers together, but it is much easier to think about adding up a finite (if perhaps very large) quantity of them. In particular, we will work with the sequence of partial sums, each of which is the sum of the first \\(n\\) terms of the series. If this sequence has a limit, then we identify that limit with the value of the series.\n\nDefinition 3.5 (Series as a limit of partial sums) A series is an infinite sum of terms, written like \\(\\sum_{k=1}^\\infty a_k\\). The \\(n\\)’th partial sum is the sum of the first \\(n\\) terms in the series, \\(\\sum_{k=1}^n a_k\\). If the sequence of partial sums, \\(\\{\\sum_{k=1}^n a_k\\}_{n=1}^\\infty\\), has a limit (finite or infinite), we say that \\[\\sum_{k=1}^\\infty a_k = \\lim_{n \\to \\infty} \\sum_{k=1}^n a_k.\\] If the limit exists and is finite, we call the series convergent.\n\nPossibly the most famous example of a convergent series is the geometric series, a sum of powers of a fraction between 0 and 1. For any number \\(q\\) between 0 and 1, we have \\[1 + q + q^2 + \\cdots = \\sum_{k=0}^\\infty q^k = \\frac{1}{1 - q}.\\] This calculation comes up in our motivating example here, where we multiply the retention probability \\(p\\) with itself repeatedly to calculate the probability of lasting \\(T\\) terms. Let’s work through the logic that shows that the series actually comes out to \\(\\frac{1}{1 - q}\\).\n\n\nYou might notice that the geometric series is a bit different than what we wrote in Definition 3.5, as we start the sum at the index \\(k = 0\\) instead of \\(k = 1\\). We could make the definition fit exactly by instead writing the series as \\(\\sum_{k=1}^\\infty q^{k-1}\\). I find it easier to just start counting at 0, though.\n\nExample 3.4 (Geometric series) Let \\(q\\) be a number such that \\(0 &lt; q &lt; 1\\). We want to show that \\[\\sum_{k=0}^\\infty q^k = \\frac{1}{1 - q}.\\] By the definition of a series, this entails showing that the sequence of partial sums, \\(\\{\\sum_{k=0}^n q^k\\}\\), is convergent with a limit of \\(\\frac{1}{1 - q}\\).\nThe key to the proof is that we can write each partial sum as a reasonably simple mathematical expression. To start off, we can show that \\((1 - q) \\sum_{k=0}^n q^k = 1 - q^{n+1}\\): \\[\n\\begin{aligned}\n(1 - q) \\sum_{k=0}^n q^k\n&= \\sum_{k=0}^n q^k - q \\sum_{k=0}^n q^k \\\\\n&= \\sum_{k=0}^n q^k - \\sum_{k=0}^n (q \\cdot q^k) \\\\\n&= \\underbrace{\\sum_{k=0}^n q^k}_{1 + q + q^2 + \\cdots + q^n} - \\underbrace{\\sum_{k=0}^n q^{k+1}}_{q + q^2 + \\cdots + q^n + q^{n+1}} \\\\\n&= 1 - q^{n+1}.\n\\end{aligned}\n\\] Dividing both sides by \\(1 - q\\), we get the following expression for the partial sum: \\[\\sum_{k=0}^n q^n = \\frac{1 - q^{n+1}}{1 - q}.\\]\nFrom here, we can calculate the value of the series using the properties of limits that we established in Proposition 3.8. We already showed in Example 3.2 that \\(\\lim_{n \\to \\infty} q^n = 0\\) when \\(0 &lt; q &lt; 1\\). Using this fact along with the properties of limits, we have \\[\n\\begin{aligned}\n\\sum_{k=0}^\\infty q^k\n&= \\lim_{n \\to \\infty} \\sum_{k=0}^n q^k \\\\\n&= \\lim_{n \\to \\infty} \\frac{1 - q^{n + 1}}{1 - q} \\\\\n&= \\frac{1}{1 - q} \\lim_{n \\to \\infty} \\left[1 - q^{n + 1}\\right] \\\\\n&= \\frac{1}{1 - q} \\left[1 - \\lim_{n \\to \\infty} q^{n + 1}\\right] \\\\\n&= \\frac{1}{1 - q} \\left[1 - q \\cdot \\underbrace{\\lim_{n \\to \\infty} q^n}_{=0}\\right] \\\\\n&= \\frac{1}{1 - q}.\n\\end{aligned}\n\\]\n\nThe geometric series also comes up in calculations involving “discounting,” an important concept in theories of decisions involving very long time horizons. As an example, what would you be willing to pay now for a lifetime-and-beyond annuity, which pays out $1,000 per year to you or your estate? In theory this promises an infinite amount of money, but that money gets less valuable every year with inflation. Suppose there is a constant inflation rate of \\(i\\) (e.g., 3% inflation means \\(i = 0.03\\)), so that $1,000 today is worth only $\\(\\frac{1{,}000}{1 + i}\\) tomorrow. Then the total value of the annuity in today’s dollars can be calculated with a geometric series: \\[\n\\begin{aligned}\n\\text{value}\n&= \\sum_{k=0}^\\infty 1000 \\left(\\frac{1}{1 + i}\\right)^k \\\\\n&= \\frac{1000}{1 - \\frac{1}{1 + i}} \\\\\n&= \\frac{1000}{\\frac{i}{1 + i}} \\\\\n&= 1000 \\left(1 + \\frac{1}{i}\\right).\n\\end{aligned}\n\\] At a 3% inflation rate (\\(i = 0.03\\)), the present value of our indefinite payment stream comes out to about $34,333. At 50% inflation (\\(i = 0.5\\)), it’s only worth $3,000.\n\n3.4.1 Calculating the expected term in office\nThe series in our motivating example is closely related to the geometric series, but a little bit different. Each term in the series does involve the probability of staying in office that long, namely \\(p^T (1 - p)\\). If all we needed to do was sum up the probabilities, we could indeed use the geometric series: \\[\n\\sum_{T=0}^\\infty p^T (1 - p) = (1 - p) \\sum_{T=0}^\\infty p^T = (1 - p) \\cdot \\frac{1}{1 - p} = 1.\n\\] This calculation does nicely confirm that we have a valid probability distribution (the probabilities of the respective events sum to 1), but it doesn’t give us the expected value we’re looking for. That calculation involves a weighted sum, where each probability is weighted by the term length in question: \\[\\sum_{T=0}^\\infty T p^T (1 - p).\\]\n\n\n\n\n\n\nAlgebra ahead\n\n\n\nTo solve our motivating example, we need a bit more old-school high-school-math-style equation manipulation than we’ve used in a lot of the notes up to this point. Real problems in statistics and formal theory are often like this — there are a couple of key mathematical insights at the heart of the result, but also a lot of moving terms around to get to the point where a reader can see or apply the insight in question.\nAs the density of equations increases here, I want to remind you to read actively. If you just scan through the equations on the page, your eyes will glaze over and you won’t retain much. You should read with paper and pen (or tablet and stylus) at hand, confirming that you can reconstruct each step on your own.\nIn fact, part of the reason there are so many equations is to facilitate your active reading — I’m skipping as few steps as possible in the chugging-through-algebra portions, to minimize the chance that you’ll get lost when working through it yourself.\n\n\nTo calculate this infinite sum, we will need to work with the sequence of partial sums. Remember that each partial sum is the addition up to the \\(n\\)’th term, so in this case it would be \\[\\sum_{T=0}^n T p^T (1 - p).\\] This is still pretty daunting to think about, if you start thinking about \\(n\\) on the order of a hundred or a billion or a googolplex. When faced with a daunting problem like this, I like to start by considering a simple-but-nontrivial case. For example, let’s look at the 3rd partial sum: \\[\n\\sum_{T=0}^3 T p^T (1 - p) = [0 p^0 + 1 p^1 + 2 p^2 + 3 p^3] (1 - p).\n\\] The first thing I notice here is that the \\(T = 0\\) case can be dropped, as it’s just always getting multiplied by 0. So we can simplify this sum a bit: \\[\n\\sum_{T=0}^3 T p^T (1 - p) = \\sum_{T=1}^3 T p^T (1 - p) = [1 p^1 + 2 p^2 + 3 p^3] (1 - p).\n\\] Next, I want to think about what we already know and how we can put it to use here. When working through the geometric series in Example 3.4, we derived a helpful expression for the \\(n\\)’th partial sum: \\[\\sum_{T=0}^n p^T = \\frac{1 - p^{n+1}}{1 - p}.\\] Can we put that fact to use here? Let’s play around with our example for the 3rd partial sum of our expected value series, trying to move things around until we end up only with partial sums of the geometric series. \\[\n\\begin{aligned}\n1 p^1 + 2 p^2 + 3 p^3\n&= [p^1 + p^2 + p^3] + [p^2 + p^3] + p^3.\n\\end{aligned}\n\\] These are almost like partial sums of the geometric series, except each of them is missing some terms at the front.\n\n\\(p^1 + p^2 + p^3\\) is missing \\(p^0\\).\n\\(p^2 + p^3\\) is missing \\(p^0\\) and \\(p^1\\).\n\\(p^3\\) is missing \\(p^0\\), \\(p^1\\), and \\(p^2\\).\n\nUsing \\(G_n\\) to denote the \\(n\\)’th partial sum of the geometric series (i.e., \\(G_n = \\sum_{T=0}^n p^T\\)), we have \\[\n\\begin{aligned}\n1 p^1 + 2 p^2 + 3 p^3\n&= [p^1 + p^2 + p^3] + [p^2 + p^3] + p^3 \\\\\n&= [G_3 - p^0] + [G_3 - p^0 - p^1] + [G_3 - p^0 - p^1 - p^2] \\\\\n&= [G_3 - G_0] + [G_3 - G_1] + [G_3 - G_2].\n\\end{aligned}\n\\] From here, we’ll use our helpful expression for the \\(n\\)’th partial sum of the geometric series, then keep simplifying until we hopefully end up with something manageable. \\[\n\\begin{aligned}\n1 p^1 + 2 p^2 + 3 p^3\n&= [G_3 - G_0] + [G_3 - G_1] + [G_3 - G_2] \\\\\n&= \\left[\\frac{1 - p^4}{1 - p} - \\frac{1 - p^1}{1 - p}\\right] + \\left[\\frac{1 - p^4}{1 - p} - \\frac{1 - p^2}{1 - p}\\right] + \\left[\\frac{1 - p^4}{1 - p} - \\frac{1 - p^3}{1 - p}\\right] \\\\\n&= \\frac{p^1 - p^4}{1 - p} + \\frac{p^2 - p^4}{1 - p} + \\frac{p^3 - p^4}{1 - p} \\\\\n&= \\frac{p}{1 - p} [p^0 + p^1 + p^2 - 3 p^3] \\\\\n&= \\frac{p}{1 - p} [G_2 - 3 p^3] \\\\\n&= \\frac{p}{1 - p} \\left[\\frac{1 - p^3}{1 - p} - 3 p^3\\right] \\\\\n&= \\frac{p}{1 - p} \\left[\\frac{1 - p^3}{1 - p} - \\frac{3 p^3 (1 - p)}{1 - p}\\right] \\\\\n&= \\frac{p}{1 - p} \\cdot \\frac{1 - p^3 - 3 p^3 + 3 p^4}{1 - p} \\\\\n&= \\frac{p - 4 p^3 + 3 p^4}{(1 - p)^2}.\n\\end{aligned}\n\\] And therefore, going back to the entire partial sum we were trying to calculate: \\[\n\\sum_{T=0}^3 T p^T (1 - p) = [1 p^1 + 2 p^2 + 3 p^3] (1 - p) = \\frac{p - 4 p^4 + 3 p^5}{1 - p}.\n\\]\nBecause \\(p\\) is a fraction between 0 and 1, the numbers \\(p^4\\) and \\(p^5\\) will be fairly small, much smaller than \\(p\\) itself. If we just use the (very rough!) approximations \\(p^4 \\approx 0\\) and \\(p^5 \\approx 0\\), we end up with a partial sum approximately equal to \\(\\frac{p}{1 - p}\\). In fact, going back to the \\(p = 0.75\\) example we plotted in Figure 3.3, we saw there that the expected term length appeared to be about 3, which also happens to be equal to 0.75/0.25. I’m starting to suspect that our expected value series adds up to \\(\\frac{p}{1 - p}\\).\n\nExercise 3.7 I calculated the partial sum for the \\(n = 3\\) case above. Repeat my method and/or use my result to calculate the partial sums for \\(n = 2\\) and \\(n = 4\\). What patterns do you notice in the partial sums?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFor the \\(n = 2\\) case, I think it’s easiest to just calculate the sum explicitly: \\[\n\\begin{aligned}\n\\sum_{T=0}^2 T p^T (1 - p)\n&= (0 p^0 + 1 p^1 + 2 p^2) (1 - p) \\\\\n&= (p + 2 p^2) (1 - p).\n\\end{aligned}\n\\] To make this look a bit more like our result for the \\(n = 3\\) case, we can multiply by \\(\\frac{1 - p}{1 - p}\\): \\[\n\\begin{aligned}\n\\sum_{T=0}^2 T p^T (1 - p)\n&= (p + 2 p^2) (1 - p) \\\\\n&= \\frac{(p + 2 p^2) (1 - p)^2}{1 - p} \\\\\n&= \\frac{(p + 2 p^2) (1 - 2 p + p^2)}{1 - p} \\\\\n&= \\frac{p + 2 p^2 - 2 p^2 - 4 p^3 + p^3 + 2 p^4}{1 - p} \\\\\n&= \\frac{p - 3 p^3 + 2 p^4}{1 - p}.\n\\end{aligned}\n\\]\nFor the \\(n = 4\\) case, I’ll start with our result from the \\(n = 3\\) case and then add the fourth term: \\[\n\\begin{aligned}\n\\sum_{T=0}^4 T p^T (1 - p)\n&= \\left[\\sum_{T=0}^3 T p^T (1 - p)\\right] + 4 p^4 (1 - p) \\\\\n&= \\frac{p - 4 p^4 + 3 p^5}{1 - p} + (4 p^4 - 4 p^5) \\\\\n&= \\frac{p - 4 p^4 + 3 p^5}{1 - p} + \\frac{(4 p^4 - 4 p^5) (1 - p)}{1 - p} \\\\\n&= \\frac{p - 4 p^4 + 3 p^5}{1 - p} + \\frac{4 p^4 - 4 p^5 - 4 p^5 + 4 p^6}{1 - p} \\\\\n&= \\frac{(p - 4 p^4 + 3 p^5) + (4 p^4 - 8 p^5 + 4 p^6)}{1 - p} \\\\\n&= \\frac{p - 5 p^5 + 4 p^6}{1 - p}.\n\\end{aligned}\n\\]\nNow to look for patterns, let’s line up the three partial sums that we’ve explicitly calculated so far: \\[\n\\begin{aligned}\n\\sum_{T=0}^2 T p^T (1 - p) &= \\frac{p - 3 p^3 + 2 p^4}{1 - p}; \\\\\n\\sum_{T=0}^3 T p^T (1 - p) &= \\frac{p - 4 p^4 + 3 p^5}{1 - p}; \\\\\n\\sum_{T=0}^4 T p^T (1 - p) &= \\frac{p - 5 p^5 + 4 p^6}{1 - p}.\n\\end{aligned}\n\\] Each of these has the same structure: \\[\n\\sum_{T=0}^n T p^T (1 - p) = \\frac{p - (n + 1) p^{n + 1} + n p^{n + 2}}{1 - p}.\n\\]\n\n\n\n\nAfter working through Exercise 3.7, you’ll see an apparent pattern in the first few partial sums, with each being equal to \\[\\frac{p - (n + 1) p^{n+1} + n p^{n + 2}}{1 - p}. \\tag{3.1}\\] A pattern is, of course, not a proof — but it’s a strong hint at what we should be looking for. So let’s try and prove that every partial sum indeed takes this form, and then let’s take its limit as \\(n \\to \\infty\\) to calculate our expected value series.\nThere are a couple of ways to prove that every partial sum works out to have the form in Equation 3.1. One way, following what we did for the \\(n = 3\\) case above, would be to rewrite the \\(n\\)’th partial sum of the expected value series in terms of the geometric series partial sums whose value we already know. Another way, following the lines of my answer for the \\(n = 4\\) case in Exercise 3.7, would be to use a proof by induction (see Section 1.2.4). For your fullest edification possible, I’ll present both methods.\n\nGeometric seriesInduction\n\n\nAgain I’ll use \\(G_n\\) to denote the \\(n\\)’th partial sum of the geometric series, meaning that \\[G_n = \\sum_{k=0}^n p^k = \\frac{1 - p^{n + 1}}{1 - p}.\\] We saw in the \\(n = 3\\) case that \\[1 p^1 + 2 p^2 + 3 p^3 = [G_3 - G_0] + [G_3 - G_1] + [G_3 - G_2].\\] Generalizing this, we have \\[\n\\begin{aligned}\n\\sum_{T=0}^n T p^T\n&= 0 p^0 + 1 p^1 + \\cdots + (n - 1) p^{n - 1} + n p^n \\\\\n&= [n - n] p^0 + [n - (n - 1)] p^1 + \\cdots + [n - 1] p^{n - 1} + [n - 0] p^n \\\\\n&= n [p^0 + p^1 + \\cdots + p^{n - 1} + p^n] - [p^0] - [p^0 + p^1] - \\cdots - [p^0 + p^1 + \\cdots + p^{n-1}] \\\\\n&= n G_n - \\sum_{k=0}^{n-1} G_k \\\\\n&= n G_n - \\sum_{k=0}^{n-1} \\frac{1 - p^{k+1}}{1 - p} \\\\\n&= n G_n - \\frac{n - \\sum_{k=0}^{n-1} p^{k+1}}{1 - p} \\\\\n&= n G_n - \\frac{n - \\sum_{k=1}^n p^k}{1 - p} \\\\\n&= n G_n - \\frac{n - [G_n - p^0]}{1 - p} \\\\\n&= n G_n - \\frac{n + 1 - G_n}{1 - p}\n\\end{aligned}\n\\] and therefore \\[\n\\begin{aligned}\n\\sum_{T=0}^n T p^T (1 - p)\n&= (1 - p) \\sum_{T=0}^n T p^T \\\\\n&= (1 - p) \\left[n G_n - \\frac{n + 1 - G_n}{1 - p}\\right] \\\\\n&= (1 - p) n G_n - (n + 1 - G_n) \\\\\n&= [1 + (1 - p) n] G_n - (n + 1) \\\\\n&= \\frac{[1 + (1 - p) n] (1 - p^{n+1})}{1 - p} - (n + 1) \\\\\n&= \\frac{1 - p^{n + 1} + (1 - p) n - (1 - p) n p^{n+1}}{1 - p} - (n + 1) \\\\\n&= \\frac{1 - p^{n + 1} + (1 - p) n - (1 - p) n p^{n+1} - (1 - p)(n + 1)}{1 - p} \\\\\n&= \\frac{1 - p^{n + 1} - (1 - p) - (1 - p) n p^{n+1}}{1 - p} \\\\\n&= \\frac{p - p^{n + 1} - (1 - p) n p^{n+1}}{1 - p} \\\\\n&= \\frac{p - p^{n + 1} - (n p^{n+1} - n p^{n+2})}{1 - p} \\\\\n&= \\frac{p - (n + 1) p^{n+1} + n p^{n+2}}{1 - p}.\n\\end{aligned}\n\\]\n\n\nRemember that a proof by induction consists of two steps:\n\nBase step: Show that the claim holds for the lowest case (here, \\(n = 0\\)).\nInduction step: Show that if the claim holds for \\(n = k\\), then it holds for \\(n = k + 1\\) as well.\n\nFor the base step here, we need to confirm that \\[\\sum_{T=0}^0 T p^T (1 - p) = \\frac{p - (0 + 1) p^{0 + 1} + 0 p^{0 + 2}}{1 - p}.\\] We know that the left-hand side here equals 0, so we just need to confirm that the right-hand side does as well: \\[\n\\begin{aligned}\n\\frac{p - (0 + 1) p^{0 + 1} + 0 p^{0 + 2}}{1 - p}\n&= \\frac{p - 1 p^1 + 0 p^2}{1 - p} \\\\\n&= \\frac{p - p}{1 - p} \\\\\n&= 0.\n\\end{aligned}\n\\] This concludes the base step.\nFor the induction step, assume that \\[\\sum_{T=0}^k T p^T (1 - p) = \\frac{p - (k + 1) p^{k+1} + k p^{k+2}}{1 - p}.\\] We need to show that this implies that \\[\\sum_{T=0}^{k+1} T p^T (1 - p) = \\frac{p - (k + 2) p^{k + 2} + (k + 1) p^{k+3}}{1 - p}.\\] We have \\[\n\\begin{aligned}\n\\sum_{T=0}^{k+1} T p^T (1 - p)\n&= \\left[\\sum_{T=0}^k T p^T (1 - p)\\right] + (k + 1) p^{k + 1} (1 - p) \\\\\n&= \\frac{p - (k + 1) p^{k+1} + k p^{k+2}}{1 - p} + (k + 1) (p^{k + 1} - p^{k + 2}) \\\\\n&= \\frac{p - (k + 1) p^{k+1} + k p^{k+2}}{1 - p} + \\frac{(k + 1) (p^{k + 1} - p^{k + 2}) (1 - p)}{1 - p} \\\\\n&= \\frac{p - (k + 1) p^{k+1} + k p^{k+2}}{1 - p} + \\frac{(k + 1) (p^{k + 1} - 2 p^{k+2} + p^{k+3})}{1 - p} \\\\\n&= \\frac{p + k p^{k+2} - 2 (k+1) p^{k+2} + (k + 1) p^{k+3}}{1 - p} \\\\\n&= \\frac{p + (k - 2k - 2) p^{k+2} + (k+1) p^{k+3}}{1 - p} \\\\\n&= \\frac{p - (k + 2) p^{k+2} + (k + 1) p^{k+3}}{1 - p},\n\\end{aligned}\n\\] which concludes the induction step.\n\n\n\nFinally, we are ready to obtain the result we have been working toward — the expected number of consecutive terms in office, as a function of the retention probability \\(p\\). We begin with restating the series as the limit of partial sums: \\[\n\\sum_{T=0}^\\infty T p^T (1 - p) = \\lim_{n \\to \\infty} \\sum_{T=0}^n T p^T (1 - p).\n\\] We then substitute the expression we found for the \\(n\\)’th partial sum, namely Equation 3.1. \\[\n\\begin{aligned}\n\\lim_{n \\to \\infty} \\sum_{T=0}^n T p^T (1 - p)\n&= \\lim_{n \\to \\infty} \\frac{p - (n + 1) p^{n+1} + n p^{n+2}}{1 - p}.\n\\end{aligned}\n\\] We break down this limit using the properties from Proposition 3.8: \\[\n\\begin{aligned}\n\\lim_{n \\to \\infty} \\frac{p - (n + 1) p^{n + 1} + n p^{n + 2}}{1 - p}\n&= \\lim_{n \\to \\infty} \\frac{p - n p^{n + 1} - p^{n + 1} + n p^{n + 2}}{1 - p} \\\\\n&= \\frac{\\lim_{n \\to \\infty} [p - n p^{n + 1} - p^{n + 1} + n p^{n + 2}]}{1 - p} \\\\\n&= \\frac{p - \\lim_{n \\to \\infty} n p^{n + 1} - \\lim_{n \\to \\infty} p^{n + 1} + \\lim_{n \\to \\infty} n p^{n + 2}}{1 - p} \\\\\n&= \\frac{p - p \\cdot \\lim_{n \\to \\infty} n p^{n} - p \\cdot \\lim_{n \\to \\infty} p^{n} + p^2 \\cdot \\lim_{n \\to \\infty} n p^{n}}{1 - p}.\n\\end{aligned}\n\\] Finally — finally! — we use the fact that \\(\\{p^n\\} \\to 0\\) (see Example 3.2) and \\(\\{n p^n\\} \\to 0\\) (see Example 3.3): \\[\n\\begin{aligned}\n\\frac{p - p \\cdot \\lim_{n \\to \\infty} n p^{n} - p \\cdot \\lim_{n \\to \\infty} p^{n} + p^2 \\cdot \\lim_{n \\to \\infty} n p^{n}}{1 - p}\n&= \\frac{p - p \\cdot 0 - p \\cdot 0 + p^2 \\cdot 0}{1 - p} \\\\\n&= \\frac{p}{1 - p}.\n\\end{aligned}\n\\] We conclude that \\[\\sum_{T=0}^\\infty T p^T (1 - p) = \\frac{p}{1 - p}.\\]\nNow we can just use this formula to calculate expected term length as a function of the retention probability, \\(p\\). You’ll notice in the graph below that the formula gives us an expected term length of 3 when \\(p = 0.75\\), just as we suspected from Figure 3.3.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sequences and Series</span>"
    ]
  },
  {
    "objectID": "sequences_series.html#concept-review",
    "href": "sequences_series.html#concept-review",
    "title": "3  Sequences and Series",
    "section": "3.5 Concept review",
    "text": "3.5 Concept review\n\nConceptual orderAlphabetical order\n\n\n\nSummation\n\nA concise way to denote adding up many terms. The notation \\(\\sum_{i=1}^n x_i\\) is shorthand for \\(x_1 + x_2 + \\cdots + x_n\\).\n\nLogarithm\n\nThe reverse of an exponent. In particular, for any numbers \\(a &gt; 0\\) and \\(b &gt; 0\\), if \\(a^x = b\\), then we say that \\(x = \\log_a b\\). In this example, \\(a\\) is called the base of the logarithm. For example, \\(\\log_{10} 1000 = 3\\) because \\(10^3 = 1000\\).\n\nNatural logarithm\n\nA logarithm whose base is Euler’s number, \\(e\\), the mathematical constant equal to roughly 2.718. Whenever you see \\(\\log\\) without an explicit base, you can assume it means a natural logarithm.\n\nSequence\n\nAn infinite, ordered list of numbers typically denoted \\(\\{x_n\\}\\).\n\nLimit\n\nA point that a sequence \\(\\{x_n\\}\\) approaches as \\(n\\) grows larger and larger. To denote \\(x\\) being the limit of \\(\\{x_n\\}\\), we may write \\(\\lim_{n \\to \\infty} x_n = x\\) or \\(\\{x_n\\} \\to x\\). Some sequences have no limit. See Definition 3.2 for a fully rigorous mathematical definition of a limit.\n\nConvergent sequence\n\nA sequence that has a finite limit.\n\nDivergent sequence\n\nA sequence that has no finite limit, either because it has an infinite limit or because it oscillates.\n\nBounded sequence\n\nA sequence for which there is a finite number \\(B\\) such that every \\(|x_n| \\leq B\\). Every convergent sequence is bounded, but not every bounded sequence is convergent.\n\nMonotone sequence\n\nA sequence whose values always increase (every \\(x_{n+1} \\geq x_n\\)) or always decrease (every \\(x_{n+1} \\leq x_n\\)).\n\nSeries\n\nA summation of infinitely many terms, written \\(\\sum_{k=1}^\\infty a_k\\). Its value is the limit of the sequence of partial sums, \\(\\lim_{n \\to \\infty} \\sum_{k=1}^n a_k\\), provided that this limit exists.\n\nPartial sum\n\nThe sum of all terms in a series up to a specified, finite index.\n\nConvergent series\n\nA series whose value exists and is finite.\n\nGeometric series\n\nA series of the form \\(\\sum_{k=0}^\\infty q^k = 1 + q + q^2 + \\cdots\\), where \\(0 &lt; q &lt; 1\\). A geometric series is convergent, with a value of \\(\\frac{1}{1 - q}\\).\n\n\n\n\n\nBounded sequence\n\nA sequence for which there is a finite number \\(B\\) such that every \\(|x_n| \\leq B\\). Every convergent sequence is bounded, but not every bounded sequence is convergent.\n\nConvergent sequence\n\nA sequence that has a finite limit.\n\nConvergent series\n\nA series whose value exists and is finite.\n\nDivergent sequence\n\nA sequence that has no finite limit, either because it has an infinite limit or because it oscillates.\n\nGeometric series\n\nA series of the form \\(\\sum_{k=0}^\\infty q^k = 1 + q + q^2 + \\cdots\\), where \\(0 &lt; q &lt; 1\\). A geometric series is convergent, with a value of \\(\\frac{1}{1 - q}\\).\n\nLimit\n\nA point that a sequence \\(\\{x_n\\}\\) approaches as \\(n\\) grows larger and larger. To denote \\(x\\) being the limit of \\(\\{x_n\\}\\), we may write \\(\\lim_{n \\to \\infty} x_n = x\\) or \\(\\{x_n\\} \\to x\\). Some sequences have no limit. See Definition 3.2 for a fully rigorous mathematical definition of a limit.\n\nLogarithm\n\nThe reverse of an exponent. In particular, for any numbers \\(a &gt; 0\\) and \\(b &gt; 0\\), if \\(a^x = b\\), then we say that \\(x = \\log_a b\\). In this example, \\(a\\) is called the base of the logarithm. For example, \\(\\log_{10} 1000 = 3\\) because \\(10^3 = 1000\\).\n\nMonotone sequence\n\nA sequence whose values always increase (every \\(x_{n+1} \\geq x_n\\)) or always decrease (every \\(x_{n+1} \\leq x_n\\)).\n\nNatural logarithm\n\nA logarithm whose base is Euler’s number, \\(e\\), the mathematical constant equal to roughly 2.718. Whenever you see \\(\\log\\) without an explicit base, you can assume it means a natural logarithm.\n\nPartial sum\n\nThe sum of all terms in a series up to a specified, finite index.\n\nSequence\n\nAn infinite, ordered list of numbers typically denoted \\(\\{x_n\\}\\).\n\nSeries\n\nA summation of infinitely many terms, written \\(\\sum_{k=1}^\\infty a_k\\). Its value is the limit of the sequence of partial sums, \\(\\lim_{n \\to \\infty} \\sum_{k=1}^n a_k\\), provided that this limit exists.\n\nSummation\n\nA concise way to denote adding up many terms. The notation \\(\\sum_{i=1}^n x_i\\) is shorthand for \\(x_1 + x_2 + \\cdots + x_n\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sequences and Series</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Black, Duncan. 1948. “On the Rationale of Group\nDecision-Making.” Journal of Political Economy 56 (1):\n23–34.\n\n\nPrzeworski, Adam. 2024. “Who Decides What Is Democratic?”\nJournal of Democracy 35 (3): 5–16.",
    "crumbs": [
      "References"
    ]
  }
]